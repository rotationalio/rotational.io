<!doctype html><html lang=en-us><head><meta charset=UTF-8><title>Rotational Labs | Teaching LLMs With Continuous Human Feedback</title>
<base href=https://rotational.io/ target=_self><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Generative AI requires continual human feedback to produce useful and consistent results. Here's how to collect human feedback at the source for model tuning."><meta name=keywords content="ai for companies,ai software,ai consulting,ai solutions,ai development,enterprise ai,ai services,ai platform,ai applications,ai for business,artificial intelligence solutions,artificial intelligence consulting"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Teaching LLMs With Continuous Human Feedback"><meta property="og:description" content="Generative AI requires continual human feedback to produce useful and consistent results. Here's how to collect human feedback at the source for model tuning."><meta property="og:image" content="https://rotational.io/img/blog/otter_teacher.webp"><meta property="og:url" content="https://rotational.io/blog/teaching-llms-with-human-feedback/"><meta property="og:type" content="website"><meta name=twitter:title content="Teaching LLMs With Continuous Human Feedback"><meta name=twitter:card content="summary"><meta name=twitter:description content="Generative AI requires continual human feedback to produce useful and consistent results. Here's how to collect human feedback at the source for model tuning."><meta name=twitter:image content="https://rotational.io/img/blog/otter_teacher.webp"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css><link rel=stylesheet href=https://rotational.io/output.css media=screen><script type=text/javascript id=hs-script-loader async defer src=//js.hs-scripts.com/24168101.js></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("consent","default",{ad_storage:"denied",ad_user_data:"denied",ad_personalization:"denied",analytics_storage:"denied",functionality_storage:"denied",personalization_storage:"denied"});const hspConsent=window._hsp=window._hsp||[];hspConsent.push(["addPrivacyConsentListener",function(e){const s=e&&(e.allowed||e.categories&&e.categories.analytics),t=e&&(e.allowed||e.categories&&e.categories.advertisement),n=e&&(e.allowed||e.categories&&e.categories.functionality);gtag("consent","update",{ad_storage:t?"granted":"denied",ad_user_data:t?"granted":"denied",ad_personalization:t?"granted":"denied",analytics_storage:s?"granted":"denied",functionality_storage:n?"granted":"denied",personalization_storage:n?"granted":"denied"})}])</script><script src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW" async defer></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script async defer src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script><script src></script></head><body><div class="relative bg-[#1D65A6]"><nav class="w-full max-w-7xl mx-auto px-4 sm:px-6 py-5" aria-label=Global><div class="relative max-w-7xl w-full flex flex-wrap lg:flex-nowrap items-center justify-between mx-auto"><a href=/><img src=/img/rototational-white-text-only_hu15583614935666962927.webp alt=Rotational class="h-6 w-auto">
</a><button data-collapse-toggle=navbar-dropdown type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls=navbar-dropdown aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="fa fa-bars text-xl text-white"></i></button><div class="hidden absolute z-[9999] lg:static top-16 w-[92%] md:w-[96%] lg:w-auto lg:block bg-white lg:bg-transparent text-[#192E5B] lg:text-[#F2F2F2] py-2 rounded-md" id=navbar-dropdown><ul class="flex flex-col lg:gap-2 xl:gap-4 md:flex-row font-semibold w-full md:justify-between"><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/about/>About</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><button id=dropdownNavbarLink data-dropdown-toggle=dropdownNavbar class="uppercase flex items-center justify-between gap-x-2 w-full px-3 rounded md:border-0 md:p-0 md:w-auto hover:text-black">
Services
<i class="fa fa-angle-down pt-1"></i></button><div id=dropdownNavbar class="z-10 hidden font-normal bg-[#192E5B] divide-y divide-[#192E5B] rounded-lg shadow w-44"><ul class="py-2 text-sm text-[#F2F2F2]" aria-labelledby=dropdownLargeButton><li><a href=/services/ai-assessments/ class="block px-3 py-2 hover:font-bold">AI Assessments</a></li><li><a href=/services/ai-product-development/ class="block px-3 py-2 hover:font-bold">AI Product Development</a></li><li><a href=/services/ai-ops-and-data-foundations/ class="block px-3 py-2 hover:font-bold">AI Ops & Data Foundations</a></li></ul></div></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/case-studies>Case Studies</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/blog/>Blog</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/learning/>Learning</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=https://rotational.ai>Product</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/contact/>Contact</a></li></ul></div></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=/img/blog/otter_teacher_hu4967109302164275801.webp alt="Teaching LLMs With Continuous Human Feedback" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Teaching LLMs With Continuous Human Feedback"><b class=text-[#1D65A6]>Teaching </b>LLMs With Continuous Human Feedback</h3><div class="flex flex-wrap justify-center items-center my-6"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span><a href=/authors/patrick-deziel>Patrick Deziel</a> | Friday, Sep 13, 2024 |&nbsp;
</span><span><a href=/tags/ai>AI</a>,&nbsp;
</span><a href=/tags/llms>LLMs</a>,&nbsp;
</span><a href=/tags/fine-tuning>Fine-tuning</a></span></div><article class="max-w-[800px] mx-auto prose mt-12"><p>If you&rsquo;ve worked with generative AI models you know they can be fickle and sometimes fail to meet the expectations of users. How can we move towards models users trust and see clear value in? Let&rsquo;s engineer a user-feedback loop!</p><h2 id=getting-models-in-front-of-users>Getting models in front of users</h2><p>A prerequisite for gaining user trust is to grant model access to the actual intended users. This might feel obvious but it really should be done as early as possible in development. End users will often have very different expectations than developers and engineers. For example, a model that allows users to &ldquo;chat with their data&rdquo; could be interpreted in many different ways. Exposing models to users exposes fundamental communication and expectations issues that you would rather know about early on in the collaboration process.</p><p>Usually, this means setting up a test environment to validate the model in a <em>user context</em>. A side benefit of this is that it forces you to think about deployment at an early stage and answer logistical questions (e.g. What GPU resources do I need to run this model?). For text generation, <a href=https://huggingface.co/docs/text-generation-inference/en/index>TGI</a> or <a href=https://github.com/oobabooga/text-generation-webui>text-generation-webui</a> are powerful backends that can serve transformer-based models. In the case of <code>text-generation-webui</code>, you also get a full-fledged UI that&rsquo;s targeted towards developers. If you just need a backend, TGI will get you there fairly quickly.</p><p>You can very easily build your own UI with <a href=https://streamlit.io/>streamlit</a> or <a href=https://www.gradio.app/>gradio</a>. For chat-based applications I prefer gradio because there&rsquo;s a very handy <code>ChatInterface</code> element you can use to implement a ChatGPT-style interaction. Here&rsquo;s a basic gradio template that connects to a text generation server hosted by HuggingFace for real-time interactivity.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> gradio <span style=color:#66d9ef>as</span> gr
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> huggingface_hub <span style=color:#f92672>import</span> AsyncInferenceClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Start the text generation client</span>
</span></span><span style=display:flex><span>client <span style=color:#f92672>=</span> AsyncInferenceClient(<span style=color:#e6db74>&#34;HuggingFaceH4/zephyr-7b-beta&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_response</span>(message, history):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Stream the response from the model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Invoke the inference API with the conversation history</span>
</span></span><span style=display:flex><span>    messages <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> user, assistant <span style=color:#f92672>in</span> history:
</span></span><span style=display:flex><span>        messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: user})
</span></span><span style=display:flex><span>        messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;assistant&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: assistant})
</span></span><span style=display:flex><span>    messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: message})
</span></span><span style=display:flex><span>    stream <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> client<span style=color:#f92672>.</span>chat_completion(
</span></span><span style=display:flex><span>        messages<span style=color:#f92672>=</span>messages, stream<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, max_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># Stream the response to the UI - this emulates ChatGPT-like behavior</span>
</span></span><span style=display:flex><span>    output <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>for</span> chunk <span style=color:#f92672>in</span> stream:
</span></span><span style=display:flex><span>        output <span style=color:#f92672>+=</span> chunk<span style=color:#f92672>.</span>choices[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>delta<span style=color:#f92672>.</span>content
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>yield</span> output
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configure the app</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> gr<span style=color:#f92672>.</span>Blocks() <span style=color:#66d9ef>as</span> app:
</span></span><span style=display:flex><span>    chatbot <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Chatbot(render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    textbox <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Textbox(placeholder<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Enter a message...&#34;</span>, render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    clear <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Button(<span style=color:#e6db74>&#34;🗑️  Clear&#34;</span>, render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>    interface <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>ChatInterface(
</span></span><span style=display:flex><span>        get_response,
</span></span><span style=display:flex><span>        chatbot<span style=color:#f92672>=</span>chatbot,
</span></span><span style=display:flex><span>        textbox<span style=color:#f92672>=</span>textbox,
</span></span><span style=display:flex><span>        retry_btn<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>        undo_btn<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>        clear_btn<span style=color:#f92672>=</span>clear,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>app<span style=color:#f92672>.</span>launch()
</span></span></code></pre></div><p><img alt="Simple Chatbot App with Gradio" src=/img/blog/2024-09-13-teaching-llms-with-human-feedback/simple_app.webp></p><h2 id=collecting-user-feedback>Collecting user feedback</h2><p>Having a model that users <em>and</em> developers can interact with is a good first step. It can make obvious which features or aspects of the model are not working and helps set expectations more accurately.</p><p>However, most tech teams struggle when it comes to gathering real-time user feedback. If our model is trained for a specific domain, only our end users know if the responses are actually helpful or correct. It&rsquo;s not enough for us as engineers to say, &ldquo;the response looks human so it&rsquo;s probably okay&rdquo;.</p><p>Since gradio apps are defined functionally it&rsquo;s fairly straightforward to add instrumentation code to capture human feedback. If we wanted to, we could capture all interactions that every user makes with the app. At the very least, we probably want to capture the user prompts, the generated responses, and a feedback indicator (like/dislike) and/or natural language feedback.</p><p>A good exercise is to create some data structures that will represent this data on the receiving end.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pydantic <span style=color:#f92672>import</span> BaseModel, Field
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Message</span>(BaseModel):
</span></span><span style=display:flex><span>    id: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The unique ID of the message.&#34;</span>)
</span></span><span style=display:flex><span>    conversation_id: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The unique ID of the conversation.&#34;</span>)
</span></span><span style=display:flex><span>    role: str <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>,
</span></span><span style=display:flex><span>        description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The role of the message sender (e.g. system, user, assistant).&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    content: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The text content of the message.&#34;</span>)
</span></span><span style=display:flex><span>    rating: str <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;</span>,
</span></span><span style=display:flex><span>        description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;User provided rating for the message, e.g. like/dislike or a numerical score.&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    feedback: str <span style=color:#f92672>=</span> Field(<span style=color:#e6db74>&#34;&#34;</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;User provided feedback for the message.&#34;</span>)
</span></span><span style=display:flex><span>    timestamp: str <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The timestamp of the message in ISO 8601 format.&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>LanguageModel</span>(BaseModel):
</span></span><span style=display:flex><span>    id: str <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>,
</span></span><span style=display:flex><span>        description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The ID of the language model (e.g. the model ID in Hugging Face).&#34;</span>,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    metadata: dict <span style=color:#f92672>=</span> Field({}, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Optional metadata for the language model.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Conversation</span>(BaseModel):
</span></span><span style=display:flex><span>    id: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The unique ID of the conversation.&#34;</span>)
</span></span><span style=display:flex><span>    model: LanguageModel <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The language model used in the conversation.&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    username: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The name of the user in the conversation.&#34;</span>)
</span></span><span style=display:flex><span>    messages: List[Message] <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>        [], description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;The list of messages in the conversation.&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span></code></pre></div><p>This allows us to capture each conversation users have with the model. Each message has feedback information associated with it so we know how to retrain the model. If we&rsquo;re using an event-based storage mechanism (e.g. <a href=https://rotational.app/>Ensign</a>), we can update this info <em>incrementally</em> as users are interacting with the app.</p><p>For example, we might define the following events for updating an existing conversation.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> os
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> ulid
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> gradio <span style=color:#66d9ef>as</span> gr
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> enum <span style=color:#f92672>import</span> Enum
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyensign.events <span style=color:#f92672>import</span> Event
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pyensign.ensign <span style=color:#f92672>import</span> Ensign
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> pydantic <span style=color:#f92672>import</span> BaseModel, Field
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> huggingface_hub <span style=color:#f92672>import</span> AsyncInferenceClient
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ModelChatApp</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, endpoint: str, feedback_topic: str <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>endpoint <span style=color:#f92672>=</span> endpoint
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>feedback_topic <span style=color:#f92672>=</span> feedback_topic
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>conversation <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>ensign <span style=color:#f92672>=</span> Ensign()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>client <span style=color:#f92672>=</span> AsyncInferenceClient(
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>endpoint,
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>model_info <span style=color:#f92672>=</span> LanguageModel(
</span></span><span style=display:flex><span>            id<span style=color:#f92672>=</span>endpoint,
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>publish_event</span>(self, event):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>ensign<span style=color:#f92672>.</span>publish(self<span style=color:#f92672>.</span>feedback_topic, event)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>index_to_id</span>(self, index):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Convert a message index (2-dimensional tuple with user/assistant messages) to a unique message ID.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> str(index[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> index[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>select_message</span>(self, data: gr<span style=color:#f92672>.</span>SelectData):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Handle the user selecting a message to provide feedback.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>index_to_id(data<span style=color:#f92672>.</span>index), data<span style=color:#f92672>.</span>value
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_response</span>(self, message, history):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Stream the response from the model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        messages <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> user, assistant <span style=color:#f92672>in</span> history:
</span></span><span style=display:flex><span>            messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: user})
</span></span><span style=display:flex><span>            messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;assistant&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: assistant})
</span></span><span style=display:flex><span>        messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: message})
</span></span><span style=display:flex><span>        stream <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>client<span style=color:#f92672>.</span>chat_completion(
</span></span><span style=display:flex><span>            messages<span style=color:#f92672>=</span>messages, stream<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, max_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> self<span style=color:#f92672>.</span>conversation:
</span></span><span style=display:flex><span>                <span style=color:#75715e># Create conversation if it doesn&#39;t exist</span>
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>conversation <span style=color:#f92672>=</span> Conversation(
</span></span><span style=display:flex><span>                    id<span style=color:#f92672>=</span>str(ulid<span style=color:#f92672>.</span>ULID()),
</span></span><span style=display:flex><span>                    model<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>model_info,
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                    self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                    mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                    schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>START_CONVERSATION,
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Add the user message to the conversation</span>
</span></span><span style=display:flex><span>            user_message <span style=color:#f92672>=</span> Message(
</span></span><span style=display:flex><span>                id<span style=color:#f92672>=</span>str(len(history) <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>),
</span></span><span style=display:flex><span>                conversation_id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>                role<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;user&#34;</span>,
</span></span><span style=display:flex><span>                content<span style=color:#f92672>=</span>message,
</span></span><span style=display:flex><span>                timestamp<span style=color:#f92672>=</span>time<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>T%H:%M:%S&#34;</span>),
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                user_message<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>ADD_MESSAGE,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Stream out the response</span>
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>for</span> chunk <span style=color:#f92672>in</span> stream:
</span></span><span style=display:flex><span>            output <span style=color:#f92672>+=</span> chunk<span style=color:#f92672>.</span>choices[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>delta<span style=color:#f92672>.</span>content
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> output
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Add the full response to the conversation</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic:
</span></span><span style=display:flex><span>            assistant_message <span style=color:#f92672>=</span> Message(
</span></span><span style=display:flex><span>                id<span style=color:#f92672>=</span>str(len(history) <span style=color:#f92672>*</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>                conversation_id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>                role<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;assistant&#34;</span>,
</span></span><span style=display:flex><span>                content<span style=color:#f92672>=</span>output,
</span></span><span style=display:flex><span>                timestamp<span style=color:#f92672>=</span>time<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#34;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>T%H:%M:%S&#34;</span>),
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                assistant_message<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>ADD_MESSAGE,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>vote</span>(self, data: gr<span style=color:#f92672>.</span>LikeData):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Handle user ratings of individual messages (like/dislike).
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic:
</span></span><span style=display:flex><span>            update <span style=color:#f92672>=</span> UpdateMessage(
</span></span><span style=display:flex><span>                id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>index_to_id(data<span style=color:#f92672>.</span>index),
</span></span><span style=display:flex><span>                conversation_id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>                rating<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;like&#34;</span> <span style=color:#66d9ef>if</span> data<span style=color:#f92672>.</span>liked <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#34;dislike&#34;</span>,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                update<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>UPDATE_MESSAGE,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>submit_feedback</span>(self, message_id, feedback):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Handle the user submitting natural language feedback for a message.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic <span style=color:#f92672>and</span> feedback<span style=color:#f92672>.</span>strip() <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#34;&#34;</span>:
</span></span><span style=display:flex><span>            update <span style=color:#f92672>=</span> UpdateMessage(
</span></span><span style=display:flex><span>                id<span style=color:#f92672>=</span>message_id,
</span></span><span style=display:flex><span>                conversation_id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>id,
</span></span><span style=display:flex><span>                feedback<span style=color:#f92672>=</span>feedback,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                update<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>UPDATE_MESSAGE,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>end_conversation</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        End the conversation, this happens when the user clears the chat.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>feedback_topic:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>conversation:
</span></span><span style=display:flex><span>                conversation <span style=color:#f92672>=</span> EndConversation(id<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>conversation<span style=color:#f92672>.</span>id)
</span></span><span style=display:flex><span>                event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                    conversation<span style=color:#f92672>.</span>model_dump_json()<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                    mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>,
</span></span><span style=display:flex><span>                    schema_name<span style=color:#f92672>=</span>EventType<span style=color:#f92672>.</span>END_CONVERSATION,
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>publish_event(event)
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>conversation <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>None</span>, <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Run the app and handle user interactions.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>with</span> gr<span style=color:#f92672>.</span>Blocks() <span style=color:#66d9ef>as</span> app:
</span></span><span style=display:flex><span>            <span style=color:#75715e># Chat interface</span>
</span></span><span style=display:flex><span>            chatbot <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Chatbot(render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>            chatbot<span style=color:#f92672>.</span>like(self<span style=color:#f92672>.</span>vote)
</span></span><span style=display:flex><span>            textbox <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Textbox(placeholder<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Enter a message...&#34;</span>, render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>            clear <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Button(<span style=color:#e6db74>&#34;🗑️  Clear&#34;</span>, render<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>            interface <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>ChatInterface(
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>get_response,
</span></span><span style=display:flex><span>                chatbot<span style=color:#f92672>=</span>chatbot,
</span></span><span style=display:flex><span>                textbox<span style=color:#f92672>=</span>textbox,
</span></span><span style=display:flex><span>                retry_btn<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>                undo_btn<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>                clear_btn<span style=color:#f92672>=</span>clear,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># Feedback interface</span>
</span></span><span style=display:flex><span>            selected_index <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>State()
</span></span><span style=display:flex><span>            feedback_area <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Textbox(
</span></span><span style=display:flex><span>                label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Model feedback&#34;</span>,
</span></span><span style=display:flex><span>                placeholder<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Click on a message to provide feedback&#34;</span>,
</span></span><span style=display:flex><span>                interactive<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            chatbot<span style=color:#f92672>.</span>select(
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>select_message,
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>None</span>,
</span></span><span style=display:flex><span>                [selected_index, feedback_area],
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            feedback_button <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Button(<span style=color:#e6db74>&#34;Submit feedback&#34;</span>)
</span></span><span style=display:flex><span>            feedback_button<span style=color:#f92672>.</span>click(
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>submit_feedback, [selected_index, feedback_area], feedback_area
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            clear<span style=color:#f92672>.</span>click(self<span style=color:#f92672>.</span>end_conversation, <span style=color:#66d9ef>None</span>, [selected_index, feedback_area])
</span></span><span style=display:flex><span>        app<span style=color:#f92672>.</span>launch()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># Load configuration variables from the environment</span>
</span></span><span style=display:flex><span>    endpoint <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>environ<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;MODEL_ENDPOINT&#34;</span>)
</span></span><span style=display:flex><span>    feedback_topic <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>environ<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#34;FEEDBACK_TOPIC&#34;</span>, <span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span>    app <span style=color:#f92672>=</span> ModelChatApp(endpoint, feedback_topic<span style=color:#f92672>=</span>feedback_topic)
</span></span><span style=display:flex><span>    app<span style=color:#f92672>.</span>run()
</span></span></code></pre></div><p><img alt="Chatbot with user feedback" src=/img/blog/2024-09-13-teaching-llms-with-human-feedback/app_with_feedback.webp></p><h2 id=ingesting-user-feedback-for-model-tuning>Ingesting user feedback for model tuning</h2><p>The advantage of event-based capturing is that we can reconstruct the conversations with user feedback at any point in time. Here&rsquo;s how to do it with <a href=https://github.com/rotationalio/pyensign>PyEnsign</a>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>ensign <span style=color:#f92672>=</span> Ensign()
</span></span><span style=display:flex><span>cursor <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> ensign<span style=color:#f92672>.</span>query(<span style=color:#e6db74>&#34;SELECT * FROM test-feedback OFFSET 239&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>for</span> event <span style=color:#f92672>in</span> cursor:
</span></span><span style=display:flex><span>    data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>loads(event<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>decode(<span style=color:#e6db74>&#34;utf-8&#34;</span>))
</span></span><span style=display:flex><span>    print(event<span style=color:#f92672>.</span>type, data)
</span></span></code></pre></div><pre tabindex=0><code>start_conversation v0.0.0 {&#39;id&#39;: &#39;01J7PTGBKBEYJHJAMZ9Q9EE9SD&#39;, &#39;model&#39;: {&#39;id&#39;: &#39;HuggingFaceH4/zephyr-7b-beta&#39;, &#39;metadata&#39;: {}}, &#39;messages&#39;: []}
add_message v0.0.0 {&#39;id&#39;: &#39;1&#39;, &#39;conversation_id&#39;: &#39;01J7PTGBKBEYJHJAMZ9Q9EE9SD&#39;, &#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#34;how many r&#39;s are in strawberry?&#34;, &#39;rating&#39;: &#39;&#39;, &#39;feedback&#39;: &#39;&#39;, &#39;timestamp&#39;: &#39;2024-09-13T18:11:48&#39;}
add_message v0.0.0 {&#39;id&#39;: &#39;2&#39;, &#39;conversation_id&#39;: &#39;01J7PTGBKBEYJHJAMZ9Q9EE9SD&#39;, &#39;role&#39;: &#39;assistant&#39;, &#39;content&#39;: &#39;There are eleven (11) &#34;r&#34; sounds in the word &#34;strawberry&#34; when pronounced in English (straw-ber-ry). The letter &#34;r&#34; appears three (3) times within the word.\n\nNote that the actual pronunciation of the word may vary depending on the accent&#39;, &#39;rating&#39;: &#39;&#39;, &#39;feedback&#39;: &#39;&#39;, &#39;timestamp&#39;: &#39;2024-09-13T18:11:48&#39;}
update_message v0.0.0 {&#39;id&#39;: &#39;2&#39;, &#39;conversation_id&#39;: &#39;01J7PTGBKBEYJHJAMZ9Q9EE9SD&#39;, &#39;rating&#39;: &#39;dislike&#39;, &#39;feedback&#39;: &#39;&#39;}
update_message v0.0.0 {&#39;id&#39;: &#39;2&#39;, &#39;conversation_id&#39;: &#39;01J7PTGBKBEYJHJAMZ9Q9EE9SD&#39;, &#39;rating&#39;: &#39;&#39;, &#39;feedback&#39;: &#34;There are three r&#39;s in strawberry&#34;}
</code></pre><h2 id=train-impactful-models>Train impactful models</h2><p>Training models that users <em>actually want to use</em> requires an infrastructure for capturing honest user feedback. Setting up these feedback mechanisms requires a bit of engineering work, but the result is the ability to train generative models that can be validated and improved by both developers and end users.</p><div class="border-t my-12"></div><p>AI Image Generated with Leonardo.ai</p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About </span>This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Generative AI requires continual human feedback to produce useful and consistent results. Here's how to collect human feedback at the source for model tuning.</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span class="flex flex-wrap"><a href=/authors/patrick-deziel class="lg:w-[20ch] mx-2">Patrick Deziel</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><div class="flex items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span class=text-[#1D65A6]>Recommended</span>
&nbsp;Rotations</h2></div><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><ul class="grid sm:grid-cols-2 lg:grid-cols-3 gap-6 sm:my-8"><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/pytorch-conference-2024/><img loading=lazy src=/img/blog/pytorch_2024_recap_hu14668264604118134000.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/fine-tuning>Fine-tuning</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/pytorch-conference-2024/ class=block>Recapping PyTorch: Key Takeaways from the 2024 Conference</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">I spent last week in San Francisco meeting up with the Rotational team to attend <a href=https://events.linuxfoundation.org/pytorch-conference/>PyTorch Conference</a>. If you&rsquo;re an LLM developer and didn&rsquo;t make it this year, here are some of my key highlights and takeaways.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/rebecca-bilbro_hu805534418946307216.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/rebecca-bilbro>Rebecca Bilbro</a></li></ul></div><div class=font-extralight>Sep 24, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/starting-simple-with-ai/><img loading=lazy src=/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-2/cover-photo_hu3708469912556123294.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/starting-simple-with-ai/ class=block>To LLM or Not to LLM (Part 2): Starting Simple</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">Sick of hearing about hyped up AI solutions that sound like hot air? 🧐 Let&rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/butterfly_hu14572934016300068338.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 20, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/responsible-innovation/><img loading=lazy src=/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-1/elena-mozhvilo-unsplash_hu7164420345709980639.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/responsible-innovation/ class=block>To LLM or Not to LLM: Tips for Responsible Innovation</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">We&rsquo;re seeing a proliferation of Large Language Models (LLMs) as companies seek to replicate OpenAI&rsquo;s success. In this post, two AI engineers respond to LLM FAQs and offer tips for responsible innovation.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/butterfly_hu14572934016300068338.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 8, 2024</div></div></div></li></ul></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-8 px-12 md:px-16 text-white md:rounded-lg"><input type=hidden id=newsletterFormID value=8aeeb77b-a5e0-4772-b726-44e1fc2eb6e1><form action=newsletter method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><div class="bg-teal-100 border-t-4 border-teal-500 mt-3 rounded-b text-teal-900 p-4 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for joining the Rotational Labs newsletter!</p></div></div></div><div id=newsletter-error class="hidden mt-3 bg-red-200 border-t-4 border-red-600 text-red-900 rounded-b p-4 shadow-md" role=alert><div><p class=text-sm>Your request did not go through, please try again. If you need immediate assistance, please email support@rotational.io.</p></div></div><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start gap-x-2"><input type=checkbox id=checkbox required name=consent class="mt-1 w-4 h-4 block border-0">
<label for=checkbox><span id=consentText>I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="flex justify-center"><button id=newsletter-bttn type=submit data-sitekey=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk data-action=newsletter class="bg-[#192E5B] px-10 py-3 mt-8 rounded-lg text-sm text-white uppercase md:text-base hover:bg-[#192E5B]/80">
Submit</button></div></form></div></main><footer class="relative mt-40 md:mt-56 bg-[#192E5B]"><div class="relative w-full pt-36 md:pt-16 lg:pt-24 2xl:pt-20 font-extralight text-white"><div class="-mt-52 w-full mx-auto max-w-screen-xl px-4"><section class="bg-[#72A2C0] w-full p-6 md:py-20 md:px-16"><h2 class="my-4 text-2xl sm:text-3xl md:text-5xl text-white font-extrabold">LET'S ENVISION & BUILD THE FUTURE TOGETHER.</h2><div class=py-6><a href=/contact class="p-3 md:p-4 md:px-6 bg-[#2F4858] font-bold md:text-lg text-white text-center hover:bg-[#2F4858]/80">CONTACT US</a></div></section></div><div class="max-w-7xl mx-auto px-6"><div class="mt-12 flex flex-col md:flex-row lg:justify-between gap-x-8"><div class="my-4 max-w-xs"><h5 class="mb-3 font-extrabold">OUR PRESENCE</h5><p>We share because we care, about topics, tools, and technologies that we believe impact the AI economy.</p><div class=py-4><ul class="flex justify-between items-center gap-x-8"><li><a href=https://twitter.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-x-twitter"></i><p class=sr-only>Twitter</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-linkedin"></i><p class=sr-only>LinkedIn</p></a></li><li><a href=https://github.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-github"></i><p class=sr-only>GitHub</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-youtube"></i><p class=sr-only>YouTube</p></a></li><li><a href=https://www.twitch.tv/rotationallabs target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-twitch"></i><p class=sr-only>Twitch</p></a></li></ul></div></div><div class=my-4><h5 class="mb-3 font-extrabold">COMPANY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/about>About Us</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/case-studies>Case Studies</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=https://rotational.ai>Endeavor</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/blog>Blog</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">COMMUNITY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/learning>Learning</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/opensource>Open Source</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">CONTACT US</h5><ul><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-map-marker-alt text-[#757575]"></i>
St. Paul, MN & Washington, DC</li><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-envelope text-[#757575]"></i>
info@rotational.io</li></ul><div class=py-8><a href=/contact class="p-3 bg-[#ECF6FF] font-bold text-black text-center hover:bg-[#ECF6FF]/80">CONTACT US</a></div></div></div><div class="sm:flex justify-between py-6 border-t mt-4"><p>Copyright © Rotational Labs, Inc. 2021–2025 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex gap-x-8"><li><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li><li><button id=hs_show_banner_button type=button onclick='(()=>{const e=window._hsp=window._hsp||[];e.push(["showBanner"])})()'>
Manage Cookies</button></li></ul></div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.js></script><script src=https://rotational.io/js/blogSingle.js></script><script type=module src=https://rotational.io/js/newsletterForm.js></script></body></html>