<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | Building an AI Text Detector - Lessons Learned</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta name=keywords content="Rotational Labs,Ensign,Cloud-native,Real-time data streaming platform,Data collaboration,Data automation,Rapid prototyping,Real-time machine learning,Real-time data analytics,Real-time applications,Data streams,Event streams,Event-sourcing databaseEvent log"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Building an AI Text Detector - Lessons Learned"><meta property="og:description" content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta property="og:image" content="https://rotational.io/img/blog/circuit_brain.jpg"><meta property="og:url" content="https://rotational.io/blog/building-an-ai-text-detector/"><meta property="og:type" content="website"><meta name=twitter:title content="Building an AI Text Detector - Lessons Learned"><meta name=twitter:card content="summary"><meta name=twitter:description content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta name=twitter:image content="https://rotational.io/img/blog/circuit_brain.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.css><link rel=stylesheet href=https://unpkg.com/@highlightjs/cdn-assets/styles/default.min.css><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script async src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://kit.fontawesome.com/2c36e9b7b1.js crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr/lunr.js></script></head><body class="bg-hexagon bg-center bg-contain"><div class="relative bg-[#1D65A6]"><nav class="relative max-w-7xl mx-auto flex items-center justify-between text-white px-4 sm:px-6 z-[9999] py-5" aria-label=Global><a href=/><img src=img/logo.png alt="Rotational Lab logo" class="h-14 w-auto sm:h-14"></a><ul class=topnav id=myTopnav><li><a href=/services/>Services</a></li><li><a href=/products/>Products</a></li><li><a href=/blog/>Blog</a></li><li><a href=/about/>About</a></li><li><a href=/contact/>Contact Us</a></li><a class=icon onclick=openMobNav()><i class="fa fa-bars"></i></a></ul></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/circuit_brain.jpg alt="Building an AI Text Detector - Lessons Learned" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Building an AI Text Detector - Lessons Learned"><b class=text-[#1D65A6]>Building</b>
an AI Text Detector - Lessons Learned</h3><div class="flex flex-wrap justify-center items-center my-4"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span><a href=/authors/patrick-deziel>Patrick Deziel</a> | Wednesday, May 15, 2024 |&nbsp;</span>
<span><a href=/tags/ai>AI</a>,&nbsp;</span>
<a href=/tags/python>Python</a>,&nbsp;</span>
<a href=/tags/text-generation>Text Generation</a></span></div><article class="max-w-[800px] mx-auto prose"><p>The LLMs boom has made differentiating text written by a person vs. generated by AI a highly desired technology. In this post, I&rsquo;ll attempt to build an AI text detector from scratch!</p><h2 id=previous-work>Previous Work</h2><p>Since ChatGPT was released there&rsquo;s been a lot of interest in being able to distinguish human written text from text generated by large language models (LLMs), primarily among teachers and educators. So far there has been limited success actually implementing these tools. OpenAI themselves released an <a href=https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text/>AI classifier</a> which was pulled only a few months later due to low accuracy. On their website they claim:</p><p><em>Our classifier is not fully reliable. In our evaluations on a “challenge set” of English texts, our classifier correctly identifies 26% of AI-written text (true positives) as “likely AI-written,” while incorrectly labeling human-written text as AI-written 9% of the time (false positives).</em></p><p>The currently most successful AI text detector is <a href=https://gptzero.me/>GPTZero</a> which utilizes a deep learning model in addition to several heuristic methods such as analyzing the writing consistency and an internet text search.</p><h2 id=approaching-the-problem>Approaching the Problem</h2><p>One of the reasons why generalized AI text detection is so difficult is that the domain is gigantic. GPTZero required massive text corpora from the internet in addition to synthetic data sets they generated themselves to train their deep learning model. If you&rsquo;re looking into building a proprietary AI detection model, identifying a specific use case (e.g. rating student essays) in a domain you have specific knowledge and expertise in will increase your chances of success.</p><p>But what if you don&rsquo;t have the data to build a robust machine learning model? Are there more cost-effective approaches to AI text detection?</p><p>Some recent research suggests that there are particular signals in AI-generated text that can be detected. For example, a <a href=https://arxiv.org/html/2404.01268v1>Stanford paper</a> published in April identified a word frequency shift in scientific papers dating back to when ChatGPT was released. Words such as &ldquo;pivotal&rdquo;, &ldquo;intricate&rdquo;, &ldquo;realm&rdquo;, and &ldquo;showcasing&rdquo; are reportedly used more often by LLMs than humans. Unfortunately, using these sorts of words to produce rule-based solutions (e.g. filters) to detect AI text have a clear weakness — human language is highly contextual (in domains like gaming, people use the word &ldquo;realm&rdquo; all the time!). Human language is also always changing — new words enter our collective vocabularies, or become more or less common. This means that machine learning is likely required for detecting AI generated text.</p><p>I wanted to try building a text detector to take advantage of this signal. My approach was to mask out a certain percentage of tokens in the text, use a generative model to predict the tokens that were masked, and compare the predictions to the original tokens. In theory, human-written text is more varied than LLM-generated text so the more accurate the predictions were, the more likely it is that the text is AI-generated. This approach is very similar to the &ldquo;perplexity&rdquo; measure used by <a href=https://gptzero.me/technology>GPTZero</a>.</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/workflow.png alt="&ldquo;Computing Perplexity&rdquo;"></p><h2 id=the-code>The Code</h2><p>The tricky part to the implementation is selecting the tokens to mask and stitching the sequence back together for the LLM. One thing I quickly realized was the mask selection will greatly impact the perplexity score (e.g. prepositions like &ldquo;a&rdquo; and &ldquo;the&rdquo; are easier to predict than proper nouns). My implementation filters out obvious stopwords before token selection. Because the masking is random, a better approach might be to take an average of multiple masking rounds or use a shifting window so the generative model uses local context for its predictions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> nltk
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> pipeline
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> nltk.tokenize <span style=color:#f92672>import</span> word_tokenize
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>AIOrHumanScorer</span>():
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Score text that may have been produced by a generative model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, model: object, mask_filler<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bert-base-uncased&#34;</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>model <span style=color:#f92672>=</span> model
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>mask_fill <span style=color:#f92672>=</span> pipeline(<span style=color:#e6db74>&#34;fill-mask&#34;</span>, model<span style=color:#f92672>=</span>mask_filler)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>labels <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;human&#34;</span>, <span style=color:#e6db74>&#34;auto&#34;</span>]
</span></span><span style=display:flex><span>        nltk<span style=color:#f92672>.</span>download(<span style=color:#e6db74>&#34;punkt&#34;</span>)
</span></span><span style=display:flex><span>        nltk<span style=color:#f92672>.</span>download(<span style=color:#e6db74>&#34;stopwords&#34;</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>stop_words <span style=color:#f92672>=</span> set(nltk<span style=color:#f92672>.</span>corpus<span style=color:#f92672>.</span>stopwords<span style=color:#f92672>.</span>words(<span style=color:#e6db74>&#34;english&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_mask_fill</span>(self, text: str, mask_ratio<span style=color:#f92672>=</span><span style=color:#ae81ff>0.15</span>, max_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>) <span style=color:#f92672>-&gt;</span> tuple:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        This function computes a mask fill score for a text sample. This score is
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        computed by randomly masking words in the text and checking how well a mask
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        fill model can predict the masked words. Returns a tuple of
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        (true_tokens, pred_tokens).
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Truncate to ensure the text is within the token limit</span>
</span></span><span style=display:flex><span>        tokens <span style=color:#f92672>=</span> word_tokenize(text)[:max_tokens]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Randomly select words to mask, ignoring stopwords</span>
</span></span><span style=display:flex><span>        random<span style=color:#f92672>.</span>seed(random_state)
</span></span><span style=display:flex><span>        candidates <span style=color:#f92672>=</span> [(i, t) <span style=color:#66d9ef>for</span> i, t <span style=color:#f92672>in</span> enumerate(tokens) <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>lower() <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>stop_words <span style=color:#f92672>and</span> t<span style=color:#f92672>.</span>isalnum() <span style=color:#f92672>and</span> len(t<span style=color:#f92672>.</span>strip()) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> len(candidates) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;No valid tokens after stopword removal.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        n_mask <span style=color:#f92672>=</span> int(len(candidates) <span style=color:#f92672>*</span> mask_ratio)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> n_mask <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            n_mask <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Mask the target words</span>
</span></span><span style=display:flex><span>        targets <span style=color:#f92672>=</span> sorted(random<span style=color:#f92672>.</span>sample(candidates, n_mask), key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: x[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>        masked_tokens <span style=color:#f92672>=</span> [t[<span style=color:#ae81ff>1</span>] <span style=color:#66d9ef>for</span> t <span style=color:#f92672>in</span> targets]
</span></span><span style=display:flex><span>        masked_text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i, token <span style=color:#f92672>in</span> enumerate(tokens):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> len(targets) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>and</span> token <span style=color:#f92672>==</span> targets[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>1</span>]:
</span></span><span style=display:flex><span>                masked_text <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39;[MASK] &#39;</span>
</span></span><span style=display:flex><span>                targets<span style=color:#f92672>.</span>pop(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                masked_text <span style=color:#f92672>+=</span> token <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Get the mask fill predictions</span>
</span></span><span style=display:flex><span>        fill_preds <span style=color:#f92672>=</span> [f[<span style=color:#e6db74>&#39;token_str&#39;</span>] <span style=color:#66d9ef>for</span> f <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>mask_fill(masked_text, tokenizer_kwargs<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;truncation&#39;</span>: <span style=color:#66d9ef>True</span>})[<span style=color:#ae81ff>0</span>]]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> masked_tokens, fill_preds
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>score</span>(self, text: str, mask_fill_threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>) <span style=color:#f92672>-&gt;</span> float:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Return a dict of scores that represents how likely the text was produced by a
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        generative model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute the mask fill score</span>
</span></span><span style=display:flex><span>        true_tokens, pred_tokens <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_mask_fill(text)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> sum([<span style=color:#ae81ff>1</span> <span style=color:#66d9ef>for</span> t, p <span style=color:#f92672>in</span> zip(true_tokens, pred_tokens) <span style=color:#66d9ef>if</span> t <span style=color:#f92672>==</span> p]) <span style=color:#f92672>/</span> len(true_tokens)
</span></span></code></pre></div><p>This code uses the <a href=https://huggingface.co/google-bert/bert-base-uncased>bert-base-uncased</a> model from HuggingFace. Since different models will produce different results, it would be interesting to try different models to determine <em>which</em> class of models generated the text (e.g. LLaMA, Mistral, GPT, etc.).</p><h2 id=evaluation>Evaluation</h2><p>To test the performance of the approach, I used a dataset of labeled human-written and AI-written essays from <a href=https://www.kaggle.com/datasets/jdragonxherrera/augmented-data-for-llm-detect-ai-generated-text>kaggle</a>. Since the <code>score</code> method outputs a value in the range [0, 1], I did some quick parameter tuning to select the binary classification threshold that maximizes the area under the ROC curve (AUC).</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/threshold.png alt="&ldquo;AUC vs. Threshold&rdquo;"></p><p>The results against the evaluation set show that the accuracy is a bit better than random guessing, but I certainly wouldn&rsquo;t stake any academic integrity on it!</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/results.png alt=&ldquo;Results&rdquo;></p><h2 id=future-work>Future Work</h2><p>In order to combat the AI-ification of the internet we will need to have models and tools to detect AI-generated context. Using heuristics like perplexity and writing consistency seem to have some promise but relying on an all-in-one solution is unlikely to sufficient. In the future we will need the ability to develop domain-specific models that are tuned to particular detection tasks. These models will also need to be flexible and capable of evolving, because natural language is highly contextual, and continuously changing over time.</p><h2 id=bonus>Bonus</h2><p>I did not use AI in the creation of this post - but for fun here&rsquo;s what GPTZero says.</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/gptzero.png alt="&ldquo;GPTZero output&rdquo;"></p><div class="border-t my-12"></div><p>Photo by <a href="https://unsplash.com/@steve_j?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Steve Johnson</a> on <a href="https://unsplash.com/photos/a-computer-circuit-board-with-a-brain-on-it-_0iV9LmPDn0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">I built an AI text detector from scratch. Here's what went right and what went wrong.</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class="flex flex-wrap"><a href=/authors/patrick-deziel class="lg:w-[20ch] mx-2">Patrick Deziel</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span><b class=text-[#1D65A6]>Recent</b>
Rotations</span>
<img src=img/butterfly.png alt=butterfly class="ml-4 h-6 sm:h-8 relative top-1"></h2><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="grid lg:grid-cols-2 xl:grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/building-an-ai-text-detector/><img src=https://rotational.io/img/blog/circuit_brain.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/text-generation>Text Generation</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/building-an-ai-text-detector/>Building an AI Text Detector - Lessons Learned</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">The LLMs boom has made differentiating text written by a person vs. generated by AI a highly desired technology. In this post, I&rsquo;ll attempt to build an AI text detector from scratch!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><a href=/authors/patrick-deziel class="flex items-center"><img src=img/team/patrick-deziel.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Patrick Deziel</span></a></div><div class=font-extralight>May 15, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/responsible-innovation/><img src=https://rotational.io/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-1/elena-mozhvilo-unsplash.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/responsible-innovation/>To LLM or Not to LLM: Tips for Responsible Innovation</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">We&rsquo;re seeing a proliferation of Large Language Models (LLMs) as companies seek to replicate OpenAI&rsquo;s success. In this post, two AI engineers respond to LLM FAQs and offer tips for responsible innovation.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 8, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/5-javascript-libraries-to-use-for-machine-learning/><img src=https://rotational.io/img/blog/2024-03-11-javascript-libraries-to-use-for-machine-learning/5-javascript-libraries-to-use-for-machine-learning.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/nlp>NLP</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/neural-networks>Neural Networks</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/javascript>JavaScript</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/5-javascript-libraries-to-use-for-machine-learning/>5 Javascript Libraries to Use for Machine Learning</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">Over the years, several JavaScript libraries have been created for machine learning. Let&rsquo;s sort through the ones that can help you get started quickly, even if you don&rsquo;t have much experience with machine learning or data …</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><a href=/authors/danielle-maxwell class="flex items-center"><img src=img/team/danielle-maxwell.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Danielle Maxwell</span></a></div><div class=font-extralight>Mar 11, 2024</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start"><input type=checkbox id=checkbox required class="w-6 h-6 block border-0">
<label for=checkbox><span class="ml-2 text-left">I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><div id=footerBackground><footer class="bg-hero-footer bg-cover"><div class="pt-[350px] font-extralight text-white"><div class="max-w-7xl mx-auto px-6"><div class="max-[650px]:text-center sm:grid grid-cols-3"><div class="my-10 sm:my-0"><h5 class=mb-3>PRODUCT</h5><ul><li class=pb-3><a href=https://rotational.app target=_blank class=font-bold>Ensign</a></li><li class=pb-3><a href=/ensign-pricing target=_blank class=font-bold>Pricing</a></li><li class=pb-3><a href=https://ensign.rotational.dev/getting-started/ target=_blank class=font-bold>Docs</a></li><li class=pb-3><a href=https://ensign.rotational.dev/sdk/ target=_blank class=font-bold>SDKs</a></li><li class=pb-3><a href=https://status.rotational.dev/ target=_blank class=font-bold>Status</a></li></ul></div><div class="mb-10 sm:mb-0"><h5 class=mb-3>COMPANY</h5><ul><li class=pb-3><a href=/services class=font-bold>Services</a></li><li class=pb-3><a href=/blog class=font-bold>Blog</a></li><li class=pb-3><a href=/about class=font-bold>About</a></li></ul></div><div><h5 class=mb-3>COMMUNITY</h5><ul><li class=pb-3><a href=/ensign-u class=font-bold>Ensign U</a></li><li class=pb-3><a href=/data-playground class=font-bold>Data Playground</a></li><li class=pb-3><a href=/opensource class=font-bold>Open Source</a></li><li class=pb-3><a href=/resources class=font-bold>Resources</a></li></ul></div></div><div class="max-w-7xl sm:flex justify-center border-t py-6 mt-12 sm:mt-32"><div class="mx-auto xl:ml-5"><div><ul class="grid gap-8 sm:flex justify-center lg:gap-28 xl:gap-36"><li><a href=https://twitter.com/rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-twitter"></i><p>Twitter</p></a></li><li><a href=https://github.com/rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-github"></i><p>GitHub</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-linkedin"></i><p>LinkedIn</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-youtube"></i><p>YouTube</p></a></li><li><a href=mailto:info@rotational.io target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa fa-envelope"></i><p>Email</p></a></li></ul></div></div></div><div class="sm:flex justify-between py-6"><p>Copyright © Rotational Labs, Inc. 2021–2024 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex"><li class="border-r pr-4 mr-4"><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></div></footer></div><script src=https://rotational.io/js/app.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.js></script>
<script src=https://unpkg.com/@highlightjs/cdn-assets/highlight.min.js></script></body></html>