<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | Building an AI Text Detector - Lessons Learned</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta name=keywords content="Rotational Labs,Ensign,Cloud-native,Real-time data streaming platform,Data collaboration,Data automation,Rapid prototyping,Real-time machine learning,Real-time data analytics,Real-time applications,Data streams,Event streams,Event-sourcing databaseEvent log"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Building an AI Text Detector - Lessons Learned"><meta property="og:description" content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta property="og:image" content="https://rotational.io/img/blog/circuit_brain.jpg"><meta property="og:url" content="https://rotational.io/blog/building-an-ai-text-detector/"><meta property="og:type" content="website"><meta name=twitter:title content="Building an AI Text Detector - Lessons Learned"><meta name=twitter:card content="summary"><meta name=twitter:description content="I built an AI text detector from scratch. Here's what went right and what went wrong."><meta name=twitter:image content="https://rotational.io/img/blog/circuit_brain.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.css><link rel=stylesheet href=https://unpkg.com/@highlightjs/cdn-assets/styles/default.min.css><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script async src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://unpkg.com/lunr/lunr.js></script></head><body><div class="relative bg-[#1D65A6]"><nav class="w-full max-w-7xl mx-auto px-4 sm:px-6 py-5" aria-label=Global><div class="relative max-w-7xl w-full flex flex-wrap lg:flex-nowrap items-center justify-between mx-auto p-4"><a href=/><img src=img/rototational-white-text-only.png alt=Rotational class="h-6 w-auto"></a>
<button data-collapse-toggle=navbar-dropdown type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls=navbar-dropdown aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="fa fa-bars text-xl text-white"></i></button><div class="hidden absolute z-[9999] lg:static top-16 w-[92%] md:w-[96%] lg:w-auto lg:block bg-white lg:bg-transparent text-[#192E5B] lg:text-[#F2F2F2] py-4 rounded-md" id=navbar-dropdown><ul class="flex flex-col gap-4 md:flex-row font-semibold w-full md:justify-between"><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-4 py-3.5 hover:text-black" href=/about/>About</a></li><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><button id=dropdownNavbarLink data-dropdown-toggle=dropdownNavbar class="uppercase flex items-center justify-between gap-x-2 w-full py-2 px-3 rounded md:border-0 md:p-0 md:w-auto hover:text-black">
Services
<i class="fa fa-angle-down pt-1"></i></button><div id=dropdownNavbar class="z-10 hidden font-normal bg-[#192E5B] divide-y divide-[#192E5B] rounded-lg shadow w-44"><ul class="py-2 text-sm text-[#F2F2F2]" aria-labelledby=dropdownLargeButton><li><a href=/services/ai-assessments/ class="block px-4 py-2 hover:font-bold">AI Assessments</a></li><li><a href=/services/ai-product-development/ class="block px-4 py-2 hover:font-bold">AI Product Development</a></li><li><a href=/services/ai-ops-and-data-foundations/ class="block px-4 py-2 hover:font-bold">AI Ops & Data Foundations</a></li></ul></div></li><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-4 py-3.5 hover:text-black" href=/case-studies>Case Studies</a></li><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-4 py-3.5 hover:text-black" href=/blog/>Blog</a></li><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-4 py-3.5 hover:text-black" href=/resources>Learning</a></li><li class="uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-4 py-3.5 hover:text-black" href=/products/>Product</a></li></ul></div></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/circuit_brain.jpg alt="Building an AI Text Detector - Lessons Learned" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Building an AI Text Detector - Lessons Learned"><b class=text-[#1D65A6]>Building</b>
an AI Text Detector - Lessons Learned</h3><div class="flex flex-wrap justify-center items-center my-4"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span><a href=/authors/patrick-deziel>Patrick Deziel</a> | Wednesday, May 15, 2024 |&nbsp;</span>
<span><a href=/tags/ai>AI</a>,&nbsp;</span>
<a href=/tags/python>Python</a>,&nbsp;</span>
<a href=/tags/text-generation>Text Generation</a></span></div><article class="max-w-[800px] mx-auto prose"><p>The LLMs boom has made differentiating text written by a person vs. generated by AI a highly desired technology. In this post, I&rsquo;ll attempt to build an AI text detector from scratch!</p><h2 id=previous-work>Previous Work</h2><p>Since ChatGPT was released there&rsquo;s been a lot of interest in being able to distinguish human written text from text generated by large language models (LLMs), primarily among teachers and educators. So far there has been limited success actually implementing these tools. OpenAI themselves released an <a href=https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text/>AI classifier</a> which was pulled only a few months later due to low accuracy. On their website they claim:</p><p><em>Our classifier is not fully reliable. In our evaluations on a “challenge set” of English texts, our classifier correctly identifies 26% of AI-written text (true positives) as “likely AI-written,” while incorrectly labeling human-written text as AI-written 9% of the time (false positives).</em></p><p>The currently most successful AI text detector is <a href=https://gptzero.me/>GPTZero</a> which utilizes a deep learning model in addition to several heuristic methods such as analyzing the writing consistency and an internet text search.</p><h2 id=approaching-the-problem>Approaching the Problem</h2><p>One of the reasons why generalized AI text detection is so difficult is that the domain is gigantic. GPTZero required massive text corpora from the internet in addition to synthetic data sets they generated themselves to train their deep learning model. If you&rsquo;re looking into building a proprietary AI detection model, identifying a specific use case (e.g. rating student essays) in a domain you have specific knowledge and expertise in will increase your chances of success.</p><p>But what if you don&rsquo;t have the data to build a robust machine learning model? Are there more cost-effective approaches to AI text detection?</p><p>Some recent research suggests that there are particular signals in AI-generated text that can be detected. For example, a <a href=https://arxiv.org/html/2404.01268v1>Stanford paper</a> published in April identified a word frequency shift in scientific papers dating back to when ChatGPT was released. Words such as &ldquo;pivotal&rdquo;, &ldquo;intricate&rdquo;, &ldquo;realm&rdquo;, and &ldquo;showcasing&rdquo; are reportedly used more often by LLMs than humans. Unfortunately, using these sorts of words to produce rule-based solutions (e.g. filters) to detect AI text have a clear weakness — human language is highly contextual (in domains like gaming, people use the word &ldquo;realm&rdquo; all the time!). Human language is also always changing — new words enter our collective vocabularies, or become more or less common. This means that machine learning is likely required for detecting AI generated text.</p><p>I wanted to try building a text detector to take advantage of this signal. My approach was to mask out a certain percentage of tokens in the text, use a generative model to predict the tokens that were masked, and compare the predictions to the original tokens. In theory, human-written text is more varied than LLM-generated text so the more accurate the predictions were, the more likely it is that the text is AI-generated. This approach is very similar to the &ldquo;perplexity&rdquo; measure used by <a href=https://gptzero.me/technology>GPTZero</a>.</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/workflow.png alt="&ldquo;Computing Perplexity&rdquo;"></p><h2 id=the-code>The Code</h2><p>The tricky part to the implementation is selecting the tokens to mask and stitching the sequence back together for the LLM. One thing I quickly realized was the mask selection will greatly impact the perplexity score (e.g. prepositions like &ldquo;a&rdquo; and &ldquo;the&rdquo; are easier to predict than proper nouns). My implementation filters out obvious stopwords before token selection. Because the masking is random, a better approach might be to take an average of multiple masking rounds or use a shifting window so the generative model uses local context for its predictions.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> nltk
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> pipeline
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> nltk.tokenize <span style=color:#f92672>import</span> word_tokenize
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>AIOrHumanScorer</span>():
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Score text that may have been produced by a generative model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, model: object, mask_filler<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;bert-base-uncased&#34;</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>model <span style=color:#f92672>=</span> model
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>mask_fill <span style=color:#f92672>=</span> pipeline(<span style=color:#e6db74>&#34;fill-mask&#34;</span>, model<span style=color:#f92672>=</span>mask_filler)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>labels <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;human&#34;</span>, <span style=color:#e6db74>&#34;auto&#34;</span>]
</span></span><span style=display:flex><span>        nltk<span style=color:#f92672>.</span>download(<span style=color:#e6db74>&#34;punkt&#34;</span>)
</span></span><span style=display:flex><span>        nltk<span style=color:#f92672>.</span>download(<span style=color:#e6db74>&#34;stopwords&#34;</span>)
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>stop_words <span style=color:#f92672>=</span> set(nltk<span style=color:#f92672>.</span>corpus<span style=color:#f92672>.</span>stopwords<span style=color:#f92672>.</span>words(<span style=color:#e6db74>&#34;english&#34;</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_mask_fill</span>(self, text: str, mask_ratio<span style=color:#f92672>=</span><span style=color:#ae81ff>0.15</span>, max_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>, random_state<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>) <span style=color:#f92672>-&gt;</span> tuple:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        This function computes a mask fill score for a text sample. This score is
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        computed by randomly masking words in the text and checking how well a mask
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        fill model can predict the masked words. Returns a tuple of
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        (true_tokens, pred_tokens).
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Truncate to ensure the text is within the token limit</span>
</span></span><span style=display:flex><span>        tokens <span style=color:#f92672>=</span> word_tokenize(text)[:max_tokens]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Randomly select words to mask, ignoring stopwords</span>
</span></span><span style=display:flex><span>        random<span style=color:#f92672>.</span>seed(random_state)
</span></span><span style=display:flex><span>        candidates <span style=color:#f92672>=</span> [(i, t) <span style=color:#66d9ef>for</span> i, t <span style=color:#f92672>in</span> enumerate(tokens) <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>lower() <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>stop_words <span style=color:#f92672>and</span> t<span style=color:#f92672>.</span>isalnum() <span style=color:#f92672>and</span> len(t<span style=color:#f92672>.</span>strip()) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> len(candidates) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>raise</span> <span style=color:#a6e22e>ValueError</span>(<span style=color:#e6db74>&#34;No valid tokens after stopword removal.&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        n_mask <span style=color:#f92672>=</span> int(len(candidates) <span style=color:#f92672>*</span> mask_ratio)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> n_mask <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>            n_mask <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Mask the target words</span>
</span></span><span style=display:flex><span>        targets <span style=color:#f92672>=</span> sorted(random<span style=color:#f92672>.</span>sample(candidates, n_mask), key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> x: x[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span>        masked_tokens <span style=color:#f92672>=</span> [t[<span style=color:#ae81ff>1</span>] <span style=color:#66d9ef>for</span> t <span style=color:#f92672>in</span> targets]
</span></span><span style=display:flex><span>        masked_text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> i, token <span style=color:#f92672>in</span> enumerate(tokens):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> len(targets) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>and</span> token <span style=color:#f92672>==</span> targets[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>1</span>]:
</span></span><span style=display:flex><span>                masked_text <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39;[MASK] &#39;</span>
</span></span><span style=display:flex><span>                targets<span style=color:#f92672>.</span>pop(<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                masked_text <span style=color:#f92672>+=</span> token <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Get the mask fill predictions</span>
</span></span><span style=display:flex><span>        fill_preds <span style=color:#f92672>=</span> [f[<span style=color:#e6db74>&#39;token_str&#39;</span>] <span style=color:#66d9ef>for</span> f <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>mask_fill(masked_text, tokenizer_kwargs<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;truncation&#39;</span>: <span style=color:#66d9ef>True</span>})[<span style=color:#ae81ff>0</span>]]
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> masked_tokens, fill_preds
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>score</span>(self, text: str, mask_fill_threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.4</span>) <span style=color:#f92672>-&gt;</span> float:
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        Return a dict of scores that represents how likely the text was produced by a
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        generative model.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># Compute the mask fill score</span>
</span></span><span style=display:flex><span>        true_tokens, pred_tokens <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_mask_fill(text)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> sum([<span style=color:#ae81ff>1</span> <span style=color:#66d9ef>for</span> t, p <span style=color:#f92672>in</span> zip(true_tokens, pred_tokens) <span style=color:#66d9ef>if</span> t <span style=color:#f92672>==</span> p]) <span style=color:#f92672>/</span> len(true_tokens)
</span></span></code></pre></div><p>This code uses the <a href=https://huggingface.co/google-bert/bert-base-uncased>bert-base-uncased</a> model from HuggingFace. Since different models will produce different results, it would be interesting to try different models to determine <em>which</em> class of models generated the text (e.g. LLaMA, Mistral, GPT, etc.).</p><h2 id=evaluation>Evaluation</h2><p>To test the performance of the approach, I used a dataset of labeled human-written and AI-written essays from <a href=https://www.kaggle.com/datasets/jdragonxherrera/augmented-data-for-llm-detect-ai-generated-text>kaggle</a>. Since the <code>score</code> method outputs a value in the range [0, 1], I did some quick parameter tuning to select the binary classification threshold that maximizes the area under the ROC curve (AUC).</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/threshold.png alt="&ldquo;AUC vs. Threshold&rdquo;"></p><p>The results against the evaluation set show that the accuracy is a bit better than random guessing, but I certainly wouldn&rsquo;t stake any academic integrity on it!</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/results.png alt=&ldquo;Results&rdquo;></p><h2 id=future-work>Future Work</h2><p>In order to combat the AI-ification of the internet we will need to have models and tools to detect AI-generated context. Using heuristics like perplexity and writing consistency seem to have some promise but relying on an all-in-one solution is unlikely to sufficient. In the future we will need the ability to develop domain-specific models that are tuned to particular detection tasks. These models will also need to be flexible and capable of evolving, because natural language is highly contextual, and continuously changing over time.</p><h2 id=bonus>Bonus</h2><p>I did not use AI in the creation of this post - but for fun here&rsquo;s what GPTZero says.</p><p><img src=/img/blog/2024-05-10-building-an-ai-text-detector/gptzero.png alt="&ldquo;GPTZero output&rdquo;"></p><div class="border-t my-12"></div><p>Photo by <a href="https://unsplash.com/@steve_j?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Steve Johnson</a> on <a href="https://unsplash.com/photos/a-computer-circuit-board-with-a-brain-on-it-_0iV9LmPDn0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">I built an AI text detector from scratch. Here's what went right and what went wrong.</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class="flex flex-wrap"><a href=/authors/patrick-deziel class="lg:w-[20ch] mx-2">Patrick Deziel</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><div class="flex items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span class=text-[#1D65A6]>Recommended</span>
&nbsp;Rotations</h2><img src=img/butterfly.png alt=butterfly class="ml-4 h-6 sm:h-8"></div><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="grid lg:grid-cols-2 xl:grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/text-to-sql-llm-app/><img src=https://rotational.io/img/blog/2024-06-07-text-to-sql-llm-app/dashboard.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llm>LLM</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/text-to-sql-llm-app/>How to build a text-to-sql LLM application</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">As industry races for use cases of Large Language Models, software devs have emerged as early adopters. Can LLMs help us translate between tech and talk? Let&rsquo;s build a text-to-SQL application with Vanna and Streamlit!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img src=img/team/prema-roman.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>Jun 7, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/starting-simple-with-ai/><img src=https://rotational.io/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-2/cover-photo.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/starting-simple-with-ai/>To LLM or Not to LLM (Part 2): Starting Simple</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">Sick of hearing about hyped up AI solutions that sound like hot air? 🧐 Let&rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 20, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/reinforcement-learning-automation-and-tetris/><img src=https://rotational.io/img/blog/gameboy.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/reinforcement-learning>Reinforcement Learning</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/reinforcement-learning-automation-and-tetris/>Reinforcement Learning, Automation... and Tetris</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">Every time I&rsquo;m writing complex rules in my code, I remember there&rsquo;s a machine learning technique for this: Reinforcement Learning. RL models are able to learn the optimal rules given predefined rewards. Read on to learn how!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img src=img/team/patrick-deziel.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/patrick-deziel>Patrick Deziel</a></li></ul></div><div class=font-extralight>Nov 2, 2023</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start gap-x-2"><input type=checkbox id=checkbox required class="mt-1 w-4 h-4 block border-0">
<label for=checkbox><span>I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><footer class="relative mt-40 md:mt-56 bg-[#192E5B]"><div class="relative w-full pt-36 md:pt-16 lg:pt-24 2xl:pt-20 font-extralight text-white"><div class="-mt-52 w-full mx-auto max-w-screen-xl px-4"><section class="bg-[#72A2C0] w-full p-6 md:py-20 md:px-16"><h2 class="my-4 text-2xl sm:text-3xl md:text-5xl text-white font-extrabold">LET'S ENVISION & BUILD THE FUTURE TOGETHER.</h2><div class=py-6><a href=mailto:hello@rotational.ai class="p-3 md:p-4 md:px-6 bg-[#2F4858] font-bold md:text-lg text-white text-center hover:bg-[#2F4858]/80">CONTACT US</a></div></section></div><div class="max-w-7xl mx-auto px-6"><div class="mt-12 flex flex-col md:flex-row lg:justify-between gap-x-8"><div class="my-4 max-w-xs"><h5 class="mb-3 font-extrabold">OUR PRESENCE</h5><p>We share because we care, about topics, tools, and technologies that we believe impact the AI economy.</p><div class=py-4><ul class="flex justify-between items-center gap-x-8"><li><a href=https://twitter.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-x-twitter"></i><p class=sr-only>Twitter</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-linkedin"></i><p class=sr-only>LinkedIn</p></a></li><li><a href=https://github.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-github"></i><p class=sr-only>GitHub</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-youtube"></i><p class=sr-only>YouTube</p></a></li><li><a href=https://www.twitch.tv/rotationallabs target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-twitch"></i><p class=sr-only>Twitch</p></a></li></ul></div></div><div class=my-4><h5 class="mb-3 font-extrabold">COMPANY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/about>About Us</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/services>Services</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/case-studies>Case Studies</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/products>Product</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/blog>Blog</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">COMMUNITY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/resources>Learning</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/opensource>Open Source</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/ensign-u>Ensign U</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">CONTACT US</h5><ul><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-map-marker-alt text-[#757575]"></i>
St. Paul, MN & Washington, DC</li><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-envelope text-[#757575]"></i>
hello@rotational.ai</li></ul><div class=py-8><a href=mailto:hello@rotational.ai class="p-3 bg-[#ECF6FF] font-bold text-black text-center hover:bg-[#ECF6FF]/80">CONTACT US</a></div></div></div><div class="sm:flex justify-between py-6 border-t mt-4"><p>Copyright © Rotational Labs, Inc. 2021–2024 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex gap-x-8"><li><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></footer><script src=https://unpkg.com/embla-carousel/embla-carousel.umd.js></script>
<script src=https://rotational.io/js/app.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.js></script>
<script src=https://unpkg.com/@highlightjs/cdn-assets/highlight.min.js></script></body></html>