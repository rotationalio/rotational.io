<!doctype html><html lang=en-us><head><meta charset=UTF-8><title>Rotational Labs | Let The Right One In: Model Selection for the AI Era</title>
<base href=https://rotational.io/ target=_self><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="There's no such thing as a best AI model, but the fastest path to alignment is the Model Selection Triple methodology."><meta name=keywords content="ai for companies,ai software,ai consulting,ai solutions,ai development,enterprise ai,ai services,ai platform,ai applications,ai for business,artificial intelligence solutions,artificial intelligence consulting"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Let The Right One In: Model Selection for the AI Era"><meta property="og:description" content="There's no such thing as a best AI model, but the fastest path to alignment is the Model Selection Triple methodology."><meta property="og:image" content="https://rotational.io/img/blog/2025-05-05-pick-the-best-ai/mst-stress-otter-v2-md.png"><meta property="og:url" content="https://rotational.io/blog/pick-the-best-ai/"><meta property="og:type" content="website"><meta name=twitter:title content="Let The Right One In: Model Selection for the AI Era"><meta name=twitter:card content="summary"><meta name=twitter:description content="There's no such thing as a best AI model, but the fastest path to alignment is the Model Selection Triple methodology."><meta name=twitter:image content="https://rotational.io/img/blog/2025-05-05-pick-the-best-ai/mst-stress-otter-v2-md.png"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script type=text/javascript id=hs-script-loader async defer src=//js.hs-scripts.com/24168101.js></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("consent","default",{ad_storage:"denied",ad_user_data:"denied",ad_personalization:"denied",analytics_storage:"denied",functionality_storage:"denied",personalization_storage:"denied"});const hspConsent=window._hsp=window._hsp||[];hspConsent.push(["addPrivacyConsentListener",function(e){const s=e&&(e.allowed||e.categories&&e.categories.analytics),t=e&&(e.allowed||e.categories&&e.categories.advertisement),n=e&&(e.allowed||e.categories&&e.categories.functionality);gtag("consent","update",{ad_storage:t?"granted":"denied",ad_user_data:t?"granted":"denied",ad_personalization:t?"granted":"denied",analytics_storage:s?"granted":"denied",functionality_storage:n?"granted":"denied",personalization_storage:n?"granted":"denied"})}])</script><script src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW" async defer></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script async defer src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script><script src=https://kit.fontawesome.com/fea17a4e21.js crossorigin=anonymous></script></head><body><div class="relative bg-[#1D65A6]"><nav class="w-full max-w-7xl mx-auto px-4 sm:px-6 py-5" aria-label=Global><div class="relative max-w-7xl w-full flex flex-wrap lg:flex-nowrap items-center justify-between mx-auto"><a href=/><img src=/img/rototational-white-text-only_hu15583614935666962927.webp alt=Rotational class="h-6 w-auto">
</a><button data-collapse-toggle=navbar-dropdown type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls=navbar-dropdown aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="fa fa-bars text-xl text-white"></i></button><div class="hidden absolute z-[9999] lg:static top-16 w-[92%] md:w-[96%] lg:w-auto lg:block bg-white lg:bg-transparent text-[#192E5B] lg:text-[#F2F2F2] py-2 rounded-md" id=navbar-dropdown><ul class="flex flex-col lg:gap-2 xl:gap-4 md:flex-row font-semibold w-full md:justify-between"><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/about/>About</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><button id=dropdownNavbarLink data-dropdown-toggle=dropdownNavbar class="uppercase flex items-center justify-between gap-x-2 w-full px-3 rounded md:border-0 md:p-0 md:w-auto hover:text-black">
Services
<i class="fa fa-angle-down pt-1"></i></button><div id=dropdownNavbar class="z-10 hidden font-normal bg-[#192E5B] divide-y divide-[#192E5B] rounded-lg shadow w-44"><ul class="py-2 text-sm text-[#F2F2F2]" aria-labelledby=dropdownLargeButton><li><a href=/services/ai-assessments/ class="block px-3 py-2 hover:font-bold">AI Assessments</a></li><li><a href=/services/ai-product-development/ class="block px-3 py-2 hover:font-bold">AI Product Development</a></li><li><a href=/services/ai-ops-and-data-foundations/ class="block px-3 py-2 hover:font-bold">AI Ops & Data Foundations</a></li></ul></div></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/case-studies>Case Studies</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/blog/>Blog</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/learning/>Learning</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/endeavor/>Product</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/contact/>Contact</a></li></ul></div></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=/img/blog/2025-05-05-pick-the-best-ai/mst-stress-otter-v2-md_hu9940043740852190193.webp alt="Let The Right One In: Model Selection for the AI Era" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Let The Right One In: Model Selection for the AI Era"><b class=text-[#1D65A6]>Let </b>The Right One In: Model Selection for the AI Era</h3><div class="flex flex-wrap justify-center items-center my-6"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span><a href=/authors/rebecca-bilbro>Rebecca Bilbro</a> | Monday, May 5, 2025 |&nbsp;
</span><span><a href=/tags/ai>AI</a>,&nbsp;
</span><a href=/tags/data-science>Data Science</a>,&nbsp;
</span><a href=/tags/llms>LLMs</a></span></div><article class="max-w-[800px] mx-auto prose mt-12"><p>There&rsquo;s no &ldquo;best AI model for all use cases.&rdquo; You have to do the science each time. If you&rsquo;re new to experimental design for AI/ML, here&rsquo;s a quick and dirty intro to the <strong>Model Selection Triple</strong> methodology.</p><h2 id=what-is-the-model-selection-triple>What is the Model Selection Triple?</h2><p>One of the most influential ideas in my early career and one that continues to guide how I think about building AI systems today comes from a 10-year-old paper published by an ancient (in tech years) ACM special interest group focused on large-scale data management problems and databases. That was probably not your first guess. Most people would probably guess it was the <a href=https://arxiv.org/abs/1706.03762>attention paper</a> or the <a href=https://web.stanford.edu/~jurafsky/slp3/>purple book</a> or maybe the <a href=https://arxiv.org/abs/1309.0238>original proposal for scikit-learn</a>.</p><p>But the paper that lives rent-free in my head is <a href=https://cseweb.ucsd.edu/~arunkk/vision/SIGMODRecord15.pdf>&ldquo;Model selection management systems:
The next frontier of advanced analytics,&rdquo;</a> by a group of researchers from the University of Wisconsin-Madison and Microsoft:</p><blockquote><p>Model selection is iterative and exploratory because the space of [model selection triples] is usually infinite, and it is generally impossible for analysts to know a priori which [triple] will yield satisfactory accuracy and/or insights.</p><ul><li>Arun Kumar, Robert McCann, Jeffery Naughton and Jignesh Patel</li></ul></blockquote><p>This <em>one line</em> from this <em>one paper</em> is responsible for inspiring 80% of the <a href=https://www.scikit-yb.org/en/latest/tutorial.html>Yellowbrick API</a>. In order to understand the impact it had my career and the careers of tens of thousands of data scientists, and learn why it&rsquo;s <em>more relevant than ever</em> in the age of AI, let&rsquo;s first go back 10 years.</p><h3 id=more-informed-machine-learning>More Informed Machine Learning</h3><p>I gave <a href=https://us.pycon.org/2016/schedule/presentation/1616/>my first big machine learning talk</a> at PyCon 2016. I stood in front of an audience of hundreds of Python programmers and told them, voice shaking, that machine learning was getting easy but that it sucks to feel like you&rsquo;re just taking shots in the dark when you&rsquo;re using machine learning to do mission critical stuff. It hit a nerve.</p><iframe width=560 height=315 src="https://www.youtube.com/embed/c5DaaGZWQqY?si=TTTsmJKb3Z-IAxQc&amp;start=377" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy=strict-origin-when-cross-origin allowfullscreen></iframe><p>Many people responded that they also felt like they were throwing spaghetti at a wall. As data scientists, the decision space before us was indeed, as Kumar et al describe in their paper, <strong>infinite</strong>. There were simply an infinite number of possible experiments that one could run.</p><blockquote><p><em>&ldquo;What&rsquo;s your default <code>alpha</code> for that model?&rdquo; &ldquo;How many trees did you use to get that F1 score?&rdquo; &ldquo;Oh I only use XGBoost.&rdquo; &ldquo;Can we do a dimensionality reduction to shrink the decision space?&rdquo;</em></p></blockquote><p>The big compute companies started offering SaaS tools for machine learning that allowed you to exhaustively and expensively grid search your hyperparameter space.</p><p>It felt like there must be a better, more methodical way for us as data scientists to traverse the decision space of the model selection process. And suddenly like an answer in the dark, Kumar et al&rsquo;s paper was there to define our workflow in terms of <strong>model selection triples</strong>, meaning:</p><ul><li><strong>algorithms</strong> (i.e. model architecture like SVM, random forest, neural net)</li><li><strong>features</strong> (i.e. data attributes extracted via your etl, wrangling, selection and engineering pipeline)</li><li><strong>hyperparameters</strong> (e.g. alphas, num_trees, learning rates, decision thresholds, etc)</li></ul><p><img alt="The original model selection triple" src=/img/blog/2025-05-05-pick-the-best-ai/mst-original.png></p><p>This abstraction seems obvious now. It wasn&rsquo;t then.</p><p>We took those ideas and put them into <a href=https://github.com/DistrictDataLabs/yellowbrick><code>yellowbrick</code></a> — an open source machine learning API that grouped machine learning diagnostic tools into sensible categories: tools that help you with <a href=https://www.scikit-yb.org/en/latest/api/classifier/index.html>algorithm comparison</a>, tools that help you with <a href=https://www.scikit-yb.org/en/latest/api/features/index.html>feature selection</a>, and tools that help you with <a href=https://www.scikit-yb.org/en/latest/api/model_selection/index.html>hyperparameter tuning</a>.</p><p>Quickly it started to feel like all of Data Science as a field was on the same page that the fastest path to the most optimal model for the problem you are trying to solve is to construct experiments where you would only vary one of {features, algo, params} at a time, and inspect the outcomes of those experiments so that you could be sure that you were trending towards accending the accuracy gradient (or descending the error gradient).</p><p><img alt="The traditional ML workflow" src=/img/blog/2025-05-05-pick-the-best-ai/workflow-2015.png></p><p>It really took off (and I guess <a href=https://pypistats.org/packages/yellowbrick>some people still like it,</a> nbd). <em>(Note: Yellowbrick is now an Elder Data Science package and is not really being actively developed anymore.)</em></p><h2 id=the-model-selection-triple-still-matters>The Model Selection Triple Still Matters</h2><p>In the age of AI, I sense we have lost the plot on principled experimentation a bit. I am watching people running around testing LLMs like proverbial beheaded chickens. This seems like a path to chaos and waste, not to mention a lot of unsatisfying experiments.</p><p>We still need methodology around AI implementation and instrumentation. In fact, you wouldn&rsquo;t have a hard time convincing me that the original principles of machine learning are <em>even more necessary</em> than they were a decade ago when our models were stupider but easy to run on cheap compute.</p><p><img alt="Re-envisioning the MST for AI" src=/img/blog/2025-05-05-pick-the-best-ai/mst-now.png></p><p>I believe the <strong>model selection triple</strong> (with a few minor refurbishments) can be extended to serve as an efficient and effective methodology for sciencing AI, i.e. for arriving at the best combination of {LLM, prompts, hyperparameters} to solve your specific problem as efficiently as possible. Let me attempt to convince you&mldr;</p><h3 id=prompts-are-the-new-features>Prompts are the New Features</h3><p>In classical machine learning, feature engineering is the layer where human insight is encoded into structured form to help models make sense of input. Think extracting n-grams, normalizing Unicode chars, stripping HTML, parsing timestamps, writing regex for phone numbers and mailing addresses. It is well-known in ML circles that this is where wrangling effort is most likely to be rewarded with real model lift.</p><p>In LLM development, prompts serve a similar role. They furnish context and shape how the model interprets the task. Prompt design in the new feature engineering. And just like traditional features, small variations (e.g. word order in an instruction, the addition of an example or a rubric) can yield different outputs.</p><p>Prompts need the same rigor as feature pipelines: they should be structured, versioned, tested, and refined.</p><h3 id=temperature-top-p-context-length--new-hyperparameters>Temperature, top-p, context length = new hyperparameters</h3><p>Classical ML models have hyperparameters like max_depth, alpha, or num_trees that control how the model learns. With LLMs it&rsquo;s similar; you can tune for creativity (or tune it out) using temperature and top-p, and toggle verbose mode using max tokens. These dials help with things like tone, completeness, factuality, stability, and other knobs of alignment.</p><p>Unfortunately hyperparameters don’t generalize well between tasks. A temperature that works for marketing copy might produce dangerously non-deterministic alerts for a cybersecurity workflow. You always have to tune, test, and interpret in context.</p><p>Also, keep in mind that you have access to more hyperparameters the closer you are to the source code. If you&rsquo;re constructing LLM experiments via your cloud provider or using an OpenAI wrapper, you may get only the basic options. If you work directly with open weights (e.g., via HuggingFace), you can go deeper and adjust beam width, repetition penalty, presence frequency, and sampling strategies.</p><h3 id=a-well-structured-llm-experiment>A Well-Structured LLM Experiment</h3><p>A well-structured LLM experiment varies one factor at a time (prompt, model, or parameter) while holding the others constant. This allows you to isolate the effect of each change and add steering your AI experimentation workflows.</p><p>Here&rsquo;s an example of a <strong>bad experiment</strong>:</p><p>You rewrite your System Prompt to be more formal and switch from GPT-3.5 to GPT-4. The model seems to improve. But which change helped?</p><p>Here&rsquo;s a <strong>good experiment</strong>:</p><p>You run the same prompt and parameters across GPT-3.5 and GPT-4, log your observations, compare results, and prove that the cheaper model performs just as well.</p><p>To do well-defined experimentation you also need a stable reference to measure progress. This means investing in creating a fixed, versioned, and representative set of realistic inputs and their expected outputs (i.e. ideally in collaboration with SMEs at your organization). This lets you compare model behavior consistently across iterations. Even if the expected output isn’t deterministic, a well-curated test set helps you anchor decisions, identify regressions, and avoid cherry-picked outputs or lucky completions.</p><h4 id=llm-experiment-checklist>LLM Experiment Checklist</h4><p>Here&rsquo;s a short checklist of some of the key things that need to be in place for me to be confident in the validity of an LLM experiement:</p><ul><li><input disabled type=checkbox> There is a clear problem statement</li><li><input disabled type=checkbox> We have an explicit hypothesis that records what we expect to happen and why</li><li><input disabled type=checkbox> There is one controlled variable (model, prompt, or parameter)</li><li><input disabled type=checkbox> We have a fixed test set for evaluation (inputs and expected outputs)</li><li><input disabled type=checkbox> We have defined success criteria (the more specific the better)</li><li><input disabled type=checkbox> We have consistent logging and versioning (prompt, model, parameters, output, metadata)</li><li><input disabled type=checkbox> We have documented the methods for reproducing the experiment (how would someone else re-run it?)</li><li><input disabled type=checkbox> We have evaluated the results using the test set to determine what has changed and what has stayed the same</li></ul><p><img alt="Towards a more disciplined approach to AI implementation" src=/img/blog/2025-05-05-pick-the-best-ai/workflow-now.png></p><h2 id=conclusion>Conclusion</h2><p>LLM experimentation is still model selection, just with slightly different knobs. You need test cases. Prompt engineering needs to be methodical. Teams should track what they change in an AI pipeline and why. Evaluation needs to be treated objectively. Model performance should not be gauged with your gut. Work to come up with objective measures of what “good” looks like for your use case. Anchor each experiment with a clear hypothesis.</p><p>Rigor isn’t the enemy of speed. It’s how you avoid wasting time and money. Rushing leads to wasted compute, ambiguous results, and inconsistent outcomes. If you want to win at AI, treat experimentation as a science, not a gold rush.</p><p><em>My team specializes in bringing structure and velocity to AI experimentation. If you’re building something high-stakes and proprietary, I’d love to talk.</em></p><div class="border-t my-12"></div><p>Photo generated using GPT-4o and some creative human prompting.</p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About </span>This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">There's no such thing as a best AI model, but the fastest path to alignment is the Model Selection Triple methodology.</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span class="flex flex-wrap"><a href=/authors/rebecca-bilbro class="lg:w-[20ch] mx-2">Rebecca Bilbro</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><div class="flex items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span class=text-[#1D65A6]>Recommended</span>
&nbsp;Rotations</h2></div><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><ul class="grid sm:grid-cols-2 lg:grid-cols-3 gap-6 sm:my-8"><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/pytorch-conference-2024/><img loading=lazy src=/img/blog/pytorch_2024_recap_hu14668264604118134000.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/fine-tuning>Fine-tuning</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/pytorch-conference-2024/ class=block>Recapping PyTorch: Key Takeaways from the 2024 Conference</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">I spent last week in San Francisco meeting up with the Rotational team to attend <a href=https://events.linuxfoundation.org/pytorch-conference/>PyTorch Conference</a>. If you&rsquo;re an LLM developer and didn&rsquo;t make it this year, here are some of my key highlights and takeaways.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/rebecca-bilbro_hu805534418946307216.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/rebecca-bilbro>Rebecca Bilbro</a></li></ul></div><div class=font-extralight>Sep 24, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/teaching-llms-with-human-feedback/><img loading=lazy src=/img/blog/otter_teacher_hu4967109302164275801.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/fine-tuning>Fine-tuning</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/teaching-llms-with-human-feedback/ class=block>Teaching LLMs With Continuous Human Feedback</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">If you&rsquo;ve worked with generative AI models you know they can be fickle and sometimes fail to meet the expectations of users. How can we move towards models users trust and see clear value in? Let&rsquo;s engineer a user-feedback loop!</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/patrick-deziel_hu8906543757154920962.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/patrick-deziel>Patrick Deziel</a></li></ul></div><div class=font-extralight>Sep 13, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/starting-simple-with-ai/><img loading=lazy src=/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-2/cover-photo_hu3708469912556123294.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/starting-simple-with-ai/ class=block>To LLM or Not to LLM (Part 2): Starting Simple</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">Sick of hearing about hyped up AI solutions that sound like hot air? 🧐 Let&rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/butterfly_hu14572934016300068338.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 20, 2024</div></div></div></li></ul></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-8 px-12 md:px-16 text-white md:rounded-lg"><input type=hidden id=newsletterFormID value=8aeeb77b-a5e0-4772-b726-44e1fc2eb6e1><form action=newsletter method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><div class="bg-teal-100 border-t-4 border-teal-500 mt-3 rounded-b text-teal-900 p-4 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for joining the Rotational Labs newsletter!</p></div></div></div><div id=newsletter-error class="hidden mt-3 bg-red-200 border-t-4 border-red-600 text-red-900 rounded-b p-4 shadow-md" role=alert><div><p class=text-sm>Your request did not go through, please try again. If you need immediate assistance, please email support@rotational.io.</p></div></div><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start gap-x-2"><input type=checkbox id=checkbox required name=consent class="mt-1 w-4 h-4 block border-0">
<label for=checkbox><span id=consentText>I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="flex justify-center"><button id=newsletter-bttn type=submit data-sitekey=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk data-action=newsletter class="bg-[#192E5B] px-10 py-3 mt-8 rounded-lg text-sm text-white uppercase md:text-base hover:bg-[#192E5B]/80">
Submit</button></div></form></div></main><footer class="relative mt-40 md:mt-56 bg-[#192E5B]"><div class="relative w-full pt-36 md:pt-16 lg:pt-24 2xl:pt-20 font-extralight text-white"><div class="-mt-52 w-full mx-auto max-w-screen-xl px-4"><section class="bg-[#72A2C0] w-full p-6 md:py-20 md:px-16"><h2 class="my-4 text-2xl sm:text-3xl md:text-5xl text-white font-extrabold">LET'S ENVISION & BUILD THE FUTURE TOGETHER.</h2><div class=py-6><a href=/contact class="p-3 md:p-4 md:px-6 bg-[#2F4858] font-bold md:text-lg text-white text-center hover:bg-[#2F4858]/80">CONTACT US</a></div></section></div><div class="max-w-7xl mx-auto px-6"><div class="mt-12 flex flex-col md:flex-row lg:justify-between gap-x-8"><div class="my-4 max-w-xs"><h5 class="mb-3 font-extrabold">OUR PRESENCE</h5><p>We share because we care, about topics, tools, and technologies that we believe impact the AI economy.</p><div class=py-4><ul class="flex justify-between items-center gap-x-8"><li><a href=https://twitter.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-x-twitter"></i><p class=sr-only>Twitter</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-linkedin"></i><p class=sr-only>LinkedIn</p></a></li><li><a href=https://github.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-github"></i><p class=sr-only>GitHub</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-youtube"></i><p class=sr-only>YouTube</p></a></li><li><a href=https://www.twitch.tv/rotationallabs target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-twitch"></i><p class=sr-only>Twitch</p></a></li></ul></div></div><div class=my-4><h5 class="mb-3 font-extrabold">COMPANY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/about>About Us</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/case-studies>Case Studies</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/endeavor>Endeavor</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/blog>Blog</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">COMMUNITY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/learning>Learning</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/opensource>Open Source</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">CONTACT US</h5><ul><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-map-marker-alt text-[#757575]"></i>
St. Paul, MN & Washington, DC</li><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-envelope text-[#757575]"></i>
info@rotational.io</li></ul><div class=py-8><a href=/contact class="p-3 bg-[#ECF6FF] font-bold text-black text-center hover:bg-[#ECF6FF]/80">CONTACT US</a></div></div></div><div class="sm:flex justify-between py-6 border-t mt-4"><p>Copyright © Rotational Labs, Inc. 2021–2025 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex gap-x-8"><li><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li><li><button id=hs_show_banner_button type=button onclick='(()=>{const e=window._hsp=window._hsp||[];e.push(["showBanner"])})()'>
Manage Cookies</button></li></ul></div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.js></script><script src=https://rotational.io/js/blogSingle.js></script><script type=module src=https://rotational.io/js/newsletterForm.js></script></body></html>