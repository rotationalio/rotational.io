<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | Streaming NLP Analytics Made Easy With HuggingFace LLMs and Ensign</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Walk through the end-to-end process of building a streaming sentiment analysis application using a HuggingFace LLM and Ensign for real time predictions."><meta name=keywords content="Rotational Labs,Ensign,Cloud-native,Real-time data streaming platform,Data collaboration,Data automation,Rapid prototyping,Real-time machine learning,Real-time data analytics,Real-time applications,Data streams,Event streams,Event-sourcing databaseEvent log"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Streaming NLP Analytics Made Easy With HuggingFace LLMs and Ensign"><meta property="og:description" content="Walk through the end-to-end process of building a streaming sentiment analysis application using a HuggingFace LLM and Ensign for real time predictions."><meta property="og:image" content="https://rotational.io/img/blog/egret-and-buffalo.jpg"><meta property="og:url" content="https://rotational.io/blog/streaming-nlp-with-llms-and-ensign/"><meta property="og:type" content="website"><meta name=twitter:title content="Streaming NLP Analytics Made Easy With HuggingFace LLMs and Ensign"><meta name=twitter:card content="summary"><meta name=twitter:description content="Walk through the end-to-end process of building a streaming sentiment analysis application using a HuggingFace LLM and Ensign for real time predictions."><meta name=twitter:image content="https://rotational.io/img/blog/egret-and-buffalo.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.css><link rel=stylesheet href=https://unpkg.com/@highlightjs/cdn-assets/styles/default.min.css><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script async src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://kit.fontawesome.com/2c36e9b7b1.js crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr/lunr.js></script></head><body class="bg-hexagon bg-center bg-contain"><div class="relative bg-[#1D65A6]"><nav class="relative max-w-7xl mx-auto flex items-center justify-between text-white px-4 sm:px-6 z-[9999] py-5" aria-label=Global><a href=/><img src=img/logo.png alt="Rotational Lab logo" class="h-14 w-auto sm:h-14"></a><div class=topnav id=myTopnav><a href=/ensign/>Ensign</a>
<a href=/blog/>Blog</a>
<a href=/about/>About</a>
<a href=/contact/>Request a Demo</a>
<a href=https://rotational.app/register>Get Ensign Free</a>
<a class=icon onclick=openMobNav()><i class="fa fa-bars"></i></a></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/egret-and-buffalo.jpg alt="Streaming NLP Analytics Made Easy With HuggingFace LLMs and Ensign" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Streaming NLP Analytics Made Easy With HuggingFace LLMs and Ensign"><b class=text-[#1D65A6]>Streaming</b>
NLP Analytics Made Easy With HuggingFace LLMs and Ensign</h3><div class="flex flex-wrap justify-center items-center my-4"><img src=img/butterfly.png alt class="border-4 border-white rounded-full h-11 drop-shadow-lg">
<span class="ml-3 blog-date"><a href=/authors/rotational-labs>Rotational Labs</a> | Tuesday, Aug 1, 2023 |&nbsp;</span><ul class="flex whitespace-nowrap"><li class=blog-tag><a href=/tags/mlops>MLOps</a></li><li class=blog-tag><a href=/tags/eventing>Eventing</a></li><li class=blog-tag><a href=/tags/ai>AI</a></li><li class=blog-tag><a href=/tags/ml>ML</a></li></ul></div><article class="max-w-[800px] mx-auto prose"><p>Thinking about using a large language model (LLM) at your organization? Check out this tutorial to see how to bootstrap an MVP using an open source pre-trained model from <a href=https://huggingface.co/>HuggingFace</a> and a <a href=https://rotational.app/register/>free Ensign account</a>.</p><p><em>&ldquo;How can I build my own LLM? ChatGPT is a black box; I canâ€™t customize it.&rdquo; &ldquo;Donâ€™t LLMs need trillions of samples? We donâ€™t have enough data.&rdquo; &ldquo;LLMs are too complicated - I donâ€™t even know where to begin.&rdquo;</em></p><p>Sound familiar? This is for anyone out there who knows they have a good use case for LLMs but has found themselves stymied. Trust us. You can totally do this. In this post, we will walk through an end-to-end solution for bootstrapping an LLM and deploying it for real time classification.</p><iframe width=560 height=315 src="https://www.youtube.com/embed/7hXMpwS86Ro?start=331" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><p>ðŸŽ¥ You can also watch an <a href="https://www.youtube.com/watch?v=7hXMpwS86Ro&amp;t=331s">on-demand recording of this tutorial</a>, delivered by Rotational Labs Distributed Systems Engineer, <a href=https://rotational.io/authors/prema-roman/>Prema Roman</a>.</p><p>ðŸ˜Ž Just here for Prema&rsquo;s code? <a href=https://github.com/rotationalio/huggingface-example>Here&rsquo;s the repo</a>!</p><h2 id=a-very-relatable-use-case-sentiment-classification>A Very Relatable Use Case (Sentiment Classification)</h2><p>Imagine you work in the Customer Success Department at a large seafood chain restaurant. Customer complaints are being addressed way too slowly, sometimes a week or two after the fact. Serious complaints need to be flagged for Legal because they require mitigation to avoid lawsuits and negative public opinion. But your restaurant serves 85M customers every year and the helpdesk is drowning in complaints that come through phone and email&mldr; not to mention those that are posted on social media.</p><p>Yikes.</p><p>But then you realize you can use an LLM to analyze the social media posts and bucket them into positive and negative reviews and automatically triage them much faster!</p><h2 id=designing-the-solution>Designing the Solution</h2><p>When designing data science applications, it&rsquo;s important to remember that 87% of data science projects <a href=https://venturebeat.com/ai/why-do-87-of-data-science-projects-never-make-it-into-production/>never make it to production</a>. Teams that are new to operationalizing ML have a tendency to make premature decisions that fail to foster organizational buy-in, cause scaling/operations problems later on, or make deployment unnecessarily challenging.</p><p>So when it&rsquo;s time to build a data science application, it&rsquo;s important to take a step back and consider the specific use case and organizational context at hand. If you/your team are new to applications development, it&rsquo;s worth it to cultivate allies from the Engineering team who can help advise you. Application design is not something that most of us learn in data science or machine learning education (from our experience, it&rsquo;s not something that&rsquo;s typically taught even in computer science programs). Design is hard, because it depends on having some intuition about things that can go wrong in an application, which gets easier the more experience you have.</p><p>How else can you prevent your project from being one of the 87% of unsuccessful ones?</p><ul><li>Keep the end goal in mind and prioritize the success of that objective over ancillary ambitions</li><li>Donâ€™t strive for perfection, iterate (take a cue from Engineering projects)</li><li>Feedback loops are important! This helps you with iterating your solution. Feedback can mean both automated feedback (e.g. continuous monitoring and evaluation), and human feedback (i.e. from the people who are the customers of the solution)</li><li>Communication is key. Understand the objectives and pain points of the other teams you work with</li><li>Work with engineering and platform teams to build good development practices to ensure that you have maintainable code and processes</li></ul><h2 id=data-annotation--architecture>Data Annotation & Architecture</h2><p>So we collaborate with our friend from Engineering to sketch out an Application Overview (left side of the below image). Now let&rsquo;s take a crack at architecting the NLP internals and modeling component of our solution.</p><p><img src=img/blog/designing-the-solution.png alt="A proposed solution with LLMs and Ensign"></p><p>This is the basic blueprint for our streaming analytics/inference application.</p><p>As with all classification problems, the first step is to get labeled data. For this hypothetical use cases, let&rsquo;s say you team up with some colleagues from the Customer Service team, gather all of the relevant the social media posts you can find, and work together to label them as positive or negative. That will give you a label which the application can use to train the supervised model. Each model you train you will then store together with model metric metadata in your chosen storage tool.</p><p>Next, you can start to set up a routine ingestion process to ingest social media posts <em>as soon as</em> the customer posts something on social media. Data ingestion is managed using the pub/sub design pattern, so that we can read in new data (customer reviews) and generate predictions immediately. Predictions will enable automated labeling of reviews as positive and negative, and all negative reviews will get triaged for dispute resolution and positive reviews will get routed to the customer engagement team.</p><h2 id=leveraging-open-source>Leveraging Open Source</h2><p>There are many open source tools available to get you started. In this tutorial, we&rsquo;ll focus on two:</p><ul><li><a href=https://huggingface.co/>HuggingFace</a> has a large selection of pre-trained models, including ones from Google, Microsoft, and Meta, that you can choose from for your specific task. You can also further customize these pre-trained models by feeding your own data, a process called <strong>transfer learning</strong>, and use your domain knowledge and data science intuition to tune the knobs of these models to achieve the outcomes you are looking for.</li><li><a href=https://ensign.rotational.dev/>Ensign</a> is a distributed eventing system. It stores chronological changes to all objects, which you can query with SQL to get change vectors in addition to static snapshots. It can be used to help with ingestion, training, deployment, and continuous evaluation. For this example, we&rsquo;ll use Ensign&rsquo;s <a href=https://github.com/rotationalio/pyensign>Python SDK</a> to deploy the pretrained HuggingFace model on a stream to transform it into a <strong>real time prediction generator</strong>.</li></ul><h2 id=bootstrapping-the-llm>Bootstrapping the LLM</h2><p>The sentiment analysis application will use the DistilBERT model from HuggingFace. The components of the HuggingFace training process include the <code>TrainingArguments</code> (parameters to pass to the <code>Trainer</code> class), and the <code>Trainer</code>.</p><p>The first step for bootstrapping our LLM is to prepare our <code>TrainingArguments</code>. This will allow us to take the pre-trained model and augment it with whatever labeled training data we have been able to acquire/annotate (it takes less than you might think).</p><p>The <code>TrainingArguments</code> is a essentially a dictionary with a huge list of learning parameters. We&rsquo;ll pass these params as well as the directory where we want to save the models to after each run.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>self<span style=color:#f92672>.</span>train_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;trained_models&#34;</span>
</span></span><span style=display:flex><span>params<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;learning_rate&#34;</span>: <span style=color:#ae81ff>2e-5</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;per_device_train_batch_size&#34;</span>: <span style=color:#ae81ff>4</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;per_device_eval_batch_size&#34;</span>: <span style=color:#ae81ff>4</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;num_train_epochs&#34;</span>: <span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;optim&#34;</span>: <span style=color:#e6db74>&#34;adamw_torch&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;weight_decay&#34;</span>: <span style=color:#ae81ff>0.01</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;save_strategy&#34;</span>: <span style=color:#e6db74>&#34;epoch&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;evaluation_strategy&#34;</span>: <span style=color:#e6db74>&#34;epoch&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;metric_for_best_model&#34;</span>: <span style=color:#e6db74>&#34;f1_true&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;load_best_model_at_end&#34;</span>: <span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;push_to_hub&#34;</span>: <span style=color:#66d9ef>False</span>,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>training_args <span style=color:#f92672>=</span> TrainingArguments(<span style=color:#f92672>**</span>params,output_dir<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>train_dir)
</span></span></code></pre></div><p>Next, we initialize the pre-trained model and tokenizer using the DistilBert model assets available from HuggingFace. <em>Note: If you were to want to use a different tokenizer or a different model, all you have to do is change this name.</em></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>self<span style=color:#f92672>.</span>tokenizer<span style=color:#f92672>=</span>DistilBertTokenizer<span style=color:#f92672>.</span>from_pretrained(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;distilbert-base-uncased-finetuned-sst-2-english&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>model <span style=color:#f92672>=</span> AutoModelForSequenceClassification<span style=color:#f92672>.</span>from_pretrained(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;Distilbert-base-uncased-finetuned-sst-2-english&#34;</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Now we want to tokenize this data set before we feed it to the model. In this case, imagine we have a Pandas dataframe in this in this case, so we&rsquo;re going to convert it to a <code>Dataset</code> object, which is a HuggingFace class. We will apply this pre-processing function to both the train and the test data.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>preprocess_function</span>(self, instances):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>tokenizer(
</span></span><span style=display:flex><span>        instances[<span style=color:#e6db74>&#34;text&#34;</span>], truncation<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, padding<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;max_length&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span><span style=color:#75715e># convert from pandas dataframe to a Dataset object</span>
</span></span><span style=display:flex><span>train_dataset <span style=color:#f92672>=</span> Dataset<span style=color:#f92672>.</span>from_pandas(train_df)
</span></span><span style=display:flex><span>test_dataset <span style=color:#f92672>=</span> Dataset<span style=color:#f92672>.</span>from_pandas(test_df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Use the preprocess_function to tokenize the data</span>
</span></span><span style=display:flex><span>tokenized_train <span style=color:#f92672>=</span> train_dataset<span style=color:#f92672>.</span>map(
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>preprocess_function, batched<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>tokenized_test <span style=color:#f92672>=</span> test_dataset<span style=color:#f92672>.</span>map(self<span style=color:#f92672>.</span>preprocess_function, batched<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><p><em>Note: By setting <code>batched=True</code>, we can ensure that this pre-processing happens in batches.</em></p><p>Next, we set up the <code>Trainer</code> class and run the training process:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>trainer <span style=color:#f92672>=</span> Trainer(
</span></span><span style=display:flex><span>    model<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>model,
</span></span><span style=display:flex><span>    args<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>training_args,
</span></span><span style=display:flex><span>    train_dataset<span style=color:#f92672>=</span>tokenized_train,
</span></span><span style=display:flex><span>    eval_dataset<span style=color:#f92672>=</span>tokenized_test,
</span></span><span style=display:flex><span>    tokenizer<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>tokenizer,
</span></span><span style=display:flex><span>    compute_metrics<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>generate_metrics,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>trainer<span style=color:#f92672>.</span>train()
</span></span><span style=display:flex><span>metrics <span style=color:#f92672>=</span> trainer<span style=color:#f92672>.</span>evaluate()
</span></span><span style=display:flex><span>print(metrics)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># save the best model based on evaluation metrics</span>
</span></span><span style=display:flex><span>trainer<span style=color:#f92672>.</span>save_model(self<span style=color:#f92672>.</span>model_dir)
</span></span></code></pre></div><p>Congratulations! You have officially bootstrapped your own LLM!</p><h2 id=enabling-real-time-predictions>Enabling Real Time Predictions</h2><p>Now it&rsquo;s time to enable real time predictions. We need to set up a stream so that data can flow into and out of the model we bootstrapped in the previous section.</p><p>For this we will use the concept of <code>Publishers</code> and <code>Subscribers</code> from <a href=https://ensign.rotational.dev/><code>Ensign</code></a>, an open source eventing platform for data scientists:</p><p>Our <code>ScoreDataPublisher</code> will send data to our model:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>ScoreDataPublisher</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, topic<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;yelp_data&#34;</span>, interval<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>topic <span style=color:#f92672>=</span> topic
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>ensign <span style=color:#f92672>=</span> Ensign()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>interval <span style=color:#f92672>=</span> interval
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
</span></span><span style=display:flex><span>        asyncio<span style=color:#f92672>.</span>get_event_loop()<span style=color:#f92672>.</span>run_until_complete(self<span style=color:#f92672>.</span>publish())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>publish</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>ensign<span style=color:#f92672>.</span>ensure_topic_exists(self<span style=color:#f92672>.</span>topic)
</span></span><span style=display:flex><span>        score_df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_csv(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(<span style=color:#e6db74>&#34;data&#34;</span>, <span style=color:#e6db74>&#34;yelp_score.csv&#34;</span>))
</span></span><span style=display:flex><span>        score_dict <span style=color:#f92672>=</span> score_df<span style=color:#f92672>.</span>to_dict(<span style=color:#e6db74>&#34;records&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> record <span style=color:#f92672>in</span> score_dict:
</span></span><span style=display:flex><span>            event <span style=color:#f92672>=</span> Event(
</span></span><span style=display:flex><span>                json<span style=color:#f92672>.</span>dumps(record)<span style=color:#f92672>.</span>encode(<span style=color:#e6db74>&#34;utf-8&#34;</span>),
</span></span><span style=display:flex><span>                mimetype<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;application/json&#34;</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>ensign<span style=color:#f92672>.</span>publish(
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>topic,
</span></span><span style=display:flex><span>                event,
</span></span><span style=display:flex><span>                on_ack<span style=color:#f92672>=</span>print_ack,
</span></span><span style=display:flex><span>                on_nack<span style=color:#f92672>=</span>print_nack
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> asyncio<span style=color:#f92672>.</span>sleep(self<span style=color:#f92672>.</span>interval)
</span></span></code></pre></div><p>Next, we&rsquo;ll build our predictor, the <code>HuggingFaceScorer</code>, which will allow our application to subscribe to the <code>yelp_data</code> topic and asynchronously generate predictions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>HuggingFaceScorer</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, topic<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;yelp_data&#34;</span>, model_dir<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;final_model&#34;</span>):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>topic <span style=color:#f92672>=</span> topic
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>model_dir <span style=color:#f92672>=</span> model_dir
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>ensign <span style=color:#f92672>=</span> Ensign()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>load_model()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self):
</span></span><span style=display:flex><span>        asyncio<span style=color:#f92672>.</span>get_event_loop()<span style=color:#f92672>.</span>run_until_complete(self<span style=color:#f92672>.</span>subscribe())
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>load_model</span>(self):
</span></span><span style=display:flex><span>        tokenizer <span style=color:#f92672>=</span> DistilBertTokenizer<span style=color:#f92672>.</span>from_pretrained(
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;distilbert-base-uncased-finetuned-sst-2-english&#34;</span>
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        model <span style=color:#f92672>=</span> AutoModelForSequenceClassification<span style=color:#f92672>.</span>from_pretrained(
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>model_dir
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>classifier <span style=color:#f92672>=</span> pipeline(
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;sentiment-analysis&#34;</span>,
</span></span><span style=display:flex><span>            model<span style=color:#f92672>=</span>model,
</span></span><span style=display:flex><span>            tokenizer<span style=color:#f92672>=</span>tokenizer
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate_predictions</span>(self, data):
</span></span><span style=display:flex><span>        text_list <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>        text <span style=color:#f92672>=</span> data[<span style=color:#e6db74>&#34;text&#34;</span>]
</span></span><span style=display:flex><span>        text_list<span style=color:#f92672>.</span>append(text)
</span></span><span style=display:flex><span>        pred_info <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>classifier(text_list)
</span></span><span style=display:flex><span>        pred <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#34;NEGATIVE&#34;</span> <span style=color:#f92672>in</span> pred_info[<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#34;label&#34;</span>] <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        pred_score <span style=color:#f92672>=</span> pred_info[<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#34;score&#34;</span>]
</span></span><span style=display:flex><span>        label <span style=color:#f92672>=</span> data[<span style=color:#e6db74>&#34;labels&#34;</span>]
</span></span><span style=display:flex><span>        print(text)
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;prediction: </span><span style=color:#e6db74>{</span>pred<span style=color:#e6db74>}</span><span style=color:#e6db74>, prediction_score: </span><span style=color:#e6db74>{</span>pred_score<span style=color:#e6db74>}</span><span style=color:#e6db74>, label: </span><span style=color:#e6db74>{</span>label<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>subscribe</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>ensign<span style=color:#f92672>.</span>ensure_topic_exists(self<span style=color:#f92672>.</span>topic)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>for</span> event <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>ensign<span style=color:#f92672>.</span>subscribe(self<span style=color:#f92672>.</span>topic):
</span></span><span style=display:flex><span>            data <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>decode(event)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>await</span> self<span style=color:#f92672>.</span>generate_predictions(data)
</span></span></code></pre></div><p>To test drive your real time sentiment classification application, run your <code>HuggingFaceScorer</code> in one terminal, and your <code>ScoreDataPublisher</code> in a separate terminal.</p><p>That&rsquo;s it! You can watch the video <a href="https://www.youtube.com/watch?v=7hXMpwS86Ro&amp;t=331s">here</a> and find all the code <a href=https://github.com/rotationalio/huggingface-example>here</a>.</p><h2 id=conclusion>Conclusion</h2><p>As you&rsquo;ve seen in this post, you can start incrementally delivering insights to your organization without needing to resort to purchasing a pricey proprietary solution, or waiting to accumulate a trillion rows of data. Using the bootstrapping pattern and open source, Python-friendly resources like HuggingFace and Ensign, you can empower your roadmap â€” youâ€™re set up to implement your own custom LLM by simply swapping out the data and model (no tech debt required).</p><p>Ready to take the next step? <a href=https://us06web.zoom.us/webinar/register/3016915923116/WN_wipD3P6PSj24FQDvfP2XhA>Sign up for MLOps 201: Data Flows for Real Time Model Inferencing (webinar)</a>.</p><p>Ready to experiment with data streams and change data capture? Check out <a href=https://rotational.io/data-playground/>The Data Playground</a> and set up your own <a href=https://rotational.app/register/>free Ensign account</a>.</p><hr><p>Photo by <a href=https://www.flickr.com/photos/francesco_veronesi/>Francesco Veronesi</a> on <a href=https://flic.kr/p/2ne6M5j>Flickr Commons</a>.</p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Walk through the end-to-end process of building a streaming sentiment analysis application using a HuggingFace LLM and Ensign for real time predictions.</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class="lg:w-1/2 text-center"><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center justify-center"><img src=img/butterfly.png alt class="border-4 border-white rounded-full drop-shadow-lg w-14 h-14">
<span class="lg:w-[20ch] mx-2">[Rotational Labs]</span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span><b class=text-[#1D65A6]>Recent</b>
Rotations</span>
<img src=img/butterfly.png alt=butterfly class="ml-4 h-6 sm:h-8 relative top-1"></h2><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="sm:grid grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/uchicago-hackathon/><img src=https://rotational.io/img/blog/autumn_leaves.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/hackathon>Hackathon</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/data-science>Data Science</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-24" href=https://rotational.io/blog/uchicago-hackathon/>Rotational Announces Partnership, Hackathon with the University of Chicago Data Science Institute</a></h3><div class=art-s><p class="mt-8 text-base font-extralight"><p>Rotational Labs is excited to announce our partnership with the <a href=https://datascience.uchicago.edu/>University of Chicago Data Science Institute</a>, including co-hosting a hackathon to help students learn to apply real-time data science techniques to real-world problems.</p></p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><img src=img/team/edwin-schmierer.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight"><a href=/authors/edwin-schmierer>Edwin Schmierer</a></span></div><div class=font-extralight>Sep 27, 2023</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/how-to-dockerize-data-science-processes/><img src=https://rotational.io/img/blog/2023-09-14-dockerize-data-science/container.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/docker>Docker</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/data-science>Data Science</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-24" href=https://rotational.io/blog/how-to-dockerize-data-science-processes/>How to Dockerize Python Data Science Processes</a></h3><div class=art-s><p class="mt-8 text-base font-extralight"><p>Docker is great, but most tutorials are geared toward devOps users, not data scientists. If you&rsquo;re building long-running processes for NLP, ML, or generative AI, here&rsquo;s a blueprint for Python Docker containers for data science!</p></p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><img src=img/team/benjamin-bengfort.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight"><a href=/authors/benjamin-bengfort>Benjamin Bengfort</a></span></div><div class=font-extralight>Sep 14, 2023</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/year-one-lessons/><img src=https://rotational.io/img/blog/2023-09-01-year-one-lessons/fireworks.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/programming>Programming</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/career>Career</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-24" href=https://rotational.io/blog/year-one-lessons/>My First Year as a Junior Developer at Rotational Labs</a></h3><div class=art-s><p class="mt-8 text-base font-extralight"><p>ðŸŽ‰ I just celebrated my first year as a junior developer. In this post, I&rsquo;ll share some of the things I&rsquo;ve learned and techniques I&rsquo;ve grown to value over the last twelve months.</p></p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><img src=img/team/danielle-maxwell.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight"><a href=/authors/danielle-maxwell>Danielle Maxwell</a></span></div><div class=font-extralight>Sep 1, 2023</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start"><input type=checkbox id=checkbox required class="w-6 h-6 block border-0">
<label for=checkbox><span class="ml-2 text-left">I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><div id=footerBackground><footer class="bg-hero-footer bg-cover"><div class="pt-[350px] font-extralight text-white"><div class="max-w-7xl mx-auto px-6"><div class="max-[650px]:text-center sm:grid grid-cols-3"><div class="my-10 sm:my-0"><h5 class=mb-3>PRODUCT</h5><ul><li class=pb-3><a href=https://rotational.app target=_blank class=font-bold>Ensign</a></li><li class=pb-3><a href=https://ensign.rotational.dev/getting-started/ target=_blank class=font-bold>Documentation</a></li><li class=pb-3><a href=https://ensign.rotational.dev/sdk/ target=_blank class=font-bold>SDKs</a></li></ul></div><div class="mb-10 sm:mb-0"><h5 class=mb-3>COMPANY</h5><ul><li class=pb-3><a href=/services class=font-bold>Services</a></li><li class=pb-3><a href=/blog class=font-bold>Blog</a></li><li class=pb-3><a href=/about class=font-bold>About</a></li></ul></div><div><h5 class=mb-3>COMMUNITY</h5><ul><li class=pb-3><a href=/data-playground class=font-bold>Data Playground</a></li><li class=pb-3><a href=/opensource class=font-bold>Open Source</a></li></ul></div></div><div class="max-w-7xl sm:flex justify-between border-t py-6 mt-12 sm:mt-32"><div class="mx-auto xl:ml-5 sm:mt-0 mt-8"><div><ul class="mx-auto grid grid-cols-2 gap-x-20 md:gap-x-32 lg:grid-cols-4"><li class="pb-8 mt-1"><a href=https://twitter.com/rotationalio class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/twitter.svg alt class=scale-75>
<span class=ml-4>Twitter</span></a></li><li class="pb-8 mt-1"><a href=https://github.com/rotationalio class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/github.svg alt class=scale-[.8]>
<span class=ml-4>GitHub</span></a></li><li class=pb-8><a href=https://www.linkedin.com/company/rotational class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/linkedin.svg alt class=scale-75>
<span class="mt-2 ml-4">LinkedIn</span></a></li><li class="pb-8 mt-2"><a href=mailto:info@rotational.io class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/email.svg alt class=scale-[.8]>
<span class=ml-4>Email</span></a></li></ul></div></div></div><div class="sm:flex justify-between py-6"><p>Copyright Â© Rotational Labs, Inc. 2021â€“2023 Â· All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex"><li class="border-r pr-4 mr-4"><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></div></footer></div><script src=https://rotational.io/js/app.js></script>
<script src=https://rotational.io/js/playground-search.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.js></script>
<script src=https://unpkg.com/@highlightjs/cdn-assets/highlight.min.js></script></body></html>