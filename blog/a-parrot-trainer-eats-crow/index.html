<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | A Parrot Trainer Eats Crow</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta name=keywords content="Rotational Labs,Ensign,Cloud-native,Real-time data streaming platform,Data collaboration,Data automation,Rapid prototyping,Real-time machine learning,Real-time data analytics,Real-time applications,Data streams,Event streams,Event-sourcing databaseEvent log"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="A Parrot Trainer Eats Crow"><meta property="og:description" content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta property="og:image" content="https://rotational.io/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots.jpg"><meta property="og:url" content="https://rotational.io/blog/a-parrot-trainer-eats-crow/"><meta property="og:type" content="website"><meta name=twitter:title content="A Parrot Trainer Eats Crow"><meta name=twitter:card content="summary"><meta name=twitter:description content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta name=twitter:image content="https://rotational.io/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.css><link rel=stylesheet href=https://unpkg.com/@highlightjs/cdn-assets/styles/default.min.css><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script async src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://kit.fontawesome.com/2c36e9b7b1.js crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr/lunr.js></script></head><body class="bg-hexagon bg-center bg-contain"><div class="relative bg-[#1D65A6]"><nav class="relative max-w-7xl mx-auto flex items-center justify-between text-white px-4 sm:px-6 z-[9999] py-5" aria-label=Global><a href=/><img src=img/logo.png alt="Rotational Lab logo" class="h-14 w-auto sm:h-14"></a><ul class=topnav id=myTopnav><li><span><div class=ensign-menu>Ensign
<button type=button onclick=showEnsignMenu() id=open-ensign-menu-bttn>
<i class="fa fa-caret-down" aria-hidden=true></i>
<span class=sr-only>Open menu</span></button>
<button type=button onclick=hideEnsignMenu() id=close-ensign-menu-bttn>
<i class="fa fa-caret-up" aria-hidden=true></i>
<span class=sr-only>Close menu</span></button></div></span><ul id=ensign-dropdown-menu><li><a href=/ensign/>- Ensign for Data Teams</a></li><li><a href=/ensign-enterprise/>- Ensign for Enterprise</a></li><li><a href=/ensign-pricing/>- Pricing</a></li></ul></li><li><a href=/services/>Services</a></li><li><a href=/blog/>Blog</a></li><li><a href=/about/>About</a></li><li><a href=/contact/>Request a Demo</a></li><li><a href=https://rotational.app/register>Get Ensign Free</a></li><a class=icon onclick=openMobNav()><i class="fa fa-bars"></i></a></ul></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots.jpg alt="A Parrot Trainer Eats Crow" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="A Parrot Trainer Eats Crow"><b class=text-[#1D65A6]>A</b>
Parrot Trainer Eats Crow</h3><div class="flex flex-wrap justify-center items-center my-4"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class=blog-date><a href=/authors/rebecca-bilbro class=single-multi-author>Rebecca Bilbro</a> | Friday, Mar 19, 2021 |&nbsp;</span>
<span><a href=/tags/ai class=blog-tag>AI</a></span>
<a href=/tags/ml class=blog-tag>ML</a></span></div><article class="max-w-[800px] mx-auto prose"><p>In this post, we&rsquo;ll consider how it is that models trained on massive datasets using millions of parameters can be both &ldquo;low bias&rdquo; and also <em>very biased</em>, and begin to think through what we in the ML community might be able to do about it.</p><h2 id=birds-on-a-wire>Birds on a Wire</h2><p>In the machine learning community, we are trained to think of <a href=http://scott.fortmann-roe.com/docs/BiasVariance.html>size as inversely proportional to bias</a>. We associate small datasets with the problem of underfit, which is to say high bias. We learn that in the face of unfamiliar data, underfit models make poor assumptions that lead to inaccuracies. Likewise, we call models with smaller sets of hyperparameters &ldquo;weak learners&rdquo; because their limited complexity limits our ability to reduce bias even as our dataset size grows.</p><p>This intuition has driven the ML community towards ever larger datasets and increasingly complex model architectures, and to be sure, towards ever better accuracy scores. Unfortunately (and not unironically), this progression has driven a wedge between the ML definition<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> of &ldquo;bias&rdquo; and the more colloquial sense of the word.</p><h2 id=migration-patterns>Migration Patterns</h2><p>To understand our situation, it may help to trace back through the pattern of our collective migration towards these more complex models.</p><blockquote><p>&ldquo;Is deep learning really necessary to solve most machine learning problems?&rdquo;</p></blockquote><p>This question has come to me more times than I can count over the years, both at work and with my students. It often comes laced with some underlying anxiety. Sometimes it means &ldquo;These deep learning hyperparameters are really tedious to tune, are you sure it&rsquo;s worth my time to learn them?&rdquo;. Sometimes it means &ldquo;does your solution actually use neural networks, or is this just a marketing layer on top of a Logistic Regression?&rdquo;.</p><p>To be fair, I find this kind of skepticism totally healthy. We even gave the skeptics a little shout-out in <a href=https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/>our book&rsquo;s</a> chapter on deep learning, writing,</p><blockquote><p>As application developers, we tend to be cautiously optimistic about the kinds of bleeding-edge technologies that sound good on paper but can lead to headaches when it comes to operationalization.</p></blockquote><p>My own views about the value and practicality of deep learning are always changing, and my answers to askers of this question have shifted over time. While I almost always bring up what I see as the two main tradeoffs between traditional models and deep learning, namely model complexity (multi-layer neural models are more complicated, harder to tune, easier to mess up) and speed (multi-layer neural models tend to take longer to train and can impede rapid prototyping and iteration), I am much more encouraging about the use cases for deep learning these days than I used to be.</p><p>The reality is that deep neural models are getting more practical to use all the time, and even if they require us to grapple with more complexity, the rewards of being able to scale complexity are hard to ignore. Given enough data, deep neural models are likely to always outperform more traditional machine learning algorithms, simply because they don&rsquo;t ever have to stop learning.</p><h2 id=training-parrots>Training Parrots</h2><p>Industry&rsquo;s shift towards deep learning in earnest has become particularly evident to me in the last 5 or 6 years of building commercial NLP applications. Five years ago, we were all using software designed out of the computational linguistics tradition — models that took into account things like part-of-speech tags, n-grams, and syntactic parsers (e.g. <a href=https://www.nltk.org/>NLTK</a>). Three years ago, the community had begun to shift towards software that leveraged a hybrid of computational linguistics and neural network-trained distributed representations (e.g. <a href=https://spacy.io/>SpaCy</a>, <a href=https://radimrehurek.com/gensim/>Gensim</a>). These new hybrid libraries abstracted away much of the grammar-based feature extraction work that we previously had to do ourselves. Now, in the first half of 2021, many folks go directly to projects like <a href=https://huggingface.co/transformers/>HuggingFace&rsquo;s Transformers library</a>, leveraging pre-trained language models that require no feature extraction at all beyond transformation from arrays into tensors.</p><p>The progression over the last few years has been amazing to watch. There have never been more excellent open source resources for people who do what I do. It has never been easier to <a href=https://rebeccabilbro.github.io/tailored-learning/>bootstrap a domain-specific language model</a>, even if <a href=https://rebeccabilbro.github.io/small-data-delegated-literacy/>you don&rsquo;t have much data to start with</a>. But it&rsquo;s also true that we have never been more removed from our data than we are today, or less in touch with its underlying patterns, themes, and biases.</p><p>This problem is at the heart of the recent paper <a href=https://dl.acm.org/doi/pdf/10.1145/3442188.3445922>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</a> The paper itself is at the heart of a controversy about Google&rsquo;s <a href=https://www.bbc.com/news/technology-56135817>abrupt dismissal</a> of two of the authors, Dr. Timnit Gibru and Dr. Margaret Mitchell, who helped found and lead Google&rsquo;s AI Ethics team.</p><p>The Parrots paper discusses a range of concerns with large language models (like the ones Google makes), including the dangers of &ldquo;ersatz fluency&rdquo; and the environmental costs of training such models. Indeed, we seem to be entering a new phase in which machine models are only distinguishable from humans by the absence of legal and ethical responsibilities for their words and actions. Moreover, as with cryptocurrencies and <a href=https://everestpipkin.medium.com/but-the-environmental-issues-with-cryptoart-1128ef72e6a3>cryptoart like NFTs</a>, it is becoming clear that the costs are disproportionately paid by people unlikely to realize much of their benefits.</p><p>The paper is, however, primarily a warning about the challenge of responsibly building deep learning models that require a volume of data that exceeds human capacity to effectively curate. And as an NLP developer, this was the part of the paper that triggered that uneasy feeling in the pit of my stomach. This is something that <del>we</del> I need to take responsibility for and help fix. But how?</p><h2 id=eating-crow>Eating Crow</h2><p>Presumably the first step is admitting you have a problem. OpenAI <a href=https://github.com/openai/gpt-3/blob/master/model-card.md#limitations>has acknowledged</a> that GPT-3 exhibits concerning NLG properties, which they attribute to the training data:</p><blockquote><p>GPT-3, like all large language models trained on internet corpora, will generate stereotyped or prejudiced content. The model has the propensity to retain and magnify biases it inherited from any part of its training, from the datasets we selected to the training techniques we chose. This is concerning, since model bias could harm people in the relevant groups in different ways by entrenching existing stereotypes and producing demeaning portrayals amongst other potential harms.</p></blockquote><p>In his article, &ldquo;For Some Reason I’m Covered in Blood&rdquo;, <a href=https://onezero.medium.com/for-some-reason-im-covered-in-blood-gpt-3-contains-disturbing-bias-against-muslims-693d275552bf>Dave Gershgorn</a> writes about GPT-3&rsquo;s problem with Islam:</p><blockquote><p>This bias is most evident when GPT-3 is given a phrase containing the word “Muslim” and asked to complete a sentence with the words that it thinks should come next. In more than 60% of cases documented by researchers, GPT-3 created sentences associating Muslims with shooting, bombs, murder, and violence.</p></blockquote><p>So, yes, as an NLP developer, I <em>am</em> concerned that leveraging pretrained LMs in my consumer-facing products could manifest in bias that might alienate my Muslim, my women, my LGBTQ+ users. However, I am <em>also</em> concerned about how my commercialization of such LMs could serve to further normalize and entrench racist, sexist, anti-Islamic, homophobic, transphobic, and white supremist beliefs for everyone else.</p><p>As developers, when we build data products, we help produce the training data that will be used for the next generations of machine learning models. When we build atop models like GPT-3, that has the effect of ensuring that bias and hate speech remain in the collective conversation online, indefinitely.</p><p>How can we do a better job of dataset curation for large language models to avoid the problem of poisonous training data? In the Parrots paper, Dr. Gibru et al. discuss some of the approaches that were used to filter the training data for models like GPT-3 and BERT:</p><blockquote><p>The Colossal Clean Crawled Corpus&mldr;is cleaned, <em>inter alia</em>, by discarding any page containing one of a list of about 400 “Dirty, Naughty, Obscene or Otherwise Bad Words". This list is overwhelmingly words related to sex, with a handful of racial slurs and words related to white supremacy (e.g. swastika, white power) included. While possibly effective at removing documents containing pornography (and the associated problematic stereotypes encoded in the language of such sites) and certain kinds of hate speech, this approach will also undoubtedly attenuate, by suppressing such words as <em>twink</em>, the influence of online spaces built by and for LGBTQ people. If we filter out the discourse of marginalized populations, we fail to provide training data that reclaims slurs and otherwise describes marginalized identities in a positive light.</p></blockquote><p>In other words, the data cleaning mechanisms in place are crude at best, and perhaps overly aggressive in filtering out marginalized conversations that may be punctuated by reclaimed &ldquo;bad&rdquo; words. And yet&mldr;any solution I can think of that would manage to include marginalized conversations might also produce language models prone to using those reclaimed words.</p><p>This leads us to the question of whether it would <em>ever</em> be ok for a LM to use a word like &ldquo;twink&rdquo;. Knowing who can use and who should refrain from using such reclaimed words is something that humans — despite our access to education, historical context about oppression, and discussions about systemic racism, sexism, and homophobia — <a href=https://www.yahoo.com/lifestyle/papa-johns-founder-says-hes-211500691.html>still routinely screw up</a>.</p><h2 id=beyond-the-gilded-cage>Beyond the Gilded Cage</h2><p>My sense is that an awareness of appropriate use for things like reclaimed words, code switching, and patois involve a degree of complexity that we cannot reasonably expect of any global model. Instead, perhaps the answer is to decolonize our language models.</p><p><a href=https://arxiv.org/pdf/2007.04068.pdf>Mohamed, et al.</a> summarize three strategies for the decolonisation of artificial intelligence: the decentering view, the additive-inclusive view, and the engagement view. It is interesting to think about how these methods might be used to inform the model development, training, and evaluation processes. For instance, for the decentering view, this could mean training models on non-white, non-male, non-Western, non-Judeo Christian conversations, rather than applying zero-shot learning techniques to tack additional training onto pretrained LMs that have already encoded the white, male, Western, Judeo Christian viewpoint.</p><p>Reading the Parrots paper also got me thinking and reading up on indigenous language models (e.g. <a href=https://aiforgood.itu.int/events/indigenous-knowledge-and-ai/>this workshop</a>, <a href=https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96>this article</a>, and <a href=http://blog.shakirm.com/2018/10/decolonising-artificial-intelligence/>this blog</a>). My research led me to find a very interesting piece called the <a href=https://spectrum.library.concordia.ca/986506/>Indigenous Protocol and Artificial Intelligence Position Paper</a> that was recently published by a consortium of indigenous researchers, with the following passage:</p><blockquote><p>Indigenous ways of knowing are rooted in distinct, sovereign territories across the planet. These extremely diverse landscapes and histories have influenced different communities and their discrete cultural protocols over time. A single ‘Indigenous perspective’ does not exist, as epistemologies are motivated and shaped by the grounding of specific communities in particular territories. Historically, scholarly traditions that homogenize diverse Indigenous cultural practices have resulted in ontological and epistemological violence, and a flattening of the rich texture and variability of Indigenous thought. Our aim is to articulate a multiplicity of Indigenous knowledge systems and technological practices that can and should be brought to bear on the ‘question of AI.’</p></blockquote><p>Perhaps the time has come to move away from monolith language models that reduce the rich variations and complexities of our conversations to a simple argmax on the output layer, and instead embrace a new generation of language model architectures that are just as organic and diverse as the data they seek to encode.</p><h2 id=references>References</h2><ul><li>Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <a href=https://dl.acm.org/doi/pdf/10.1145/3442188.3445922>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</a></li><li>Shakir Mohamed. 2018. <a href=http://blog.shakirm.com/2018/10/decolonising-artificial-intelligence/>Decolonising Artificial Intelligence</a></li><li>Shakir Mohamed, Marie-Therese Png, William Isaac. 2020. <a href=https://arxiv.org/pdf/2007.04068.pdf>Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence</a></li><li>Paz Peña and Joana Varon. 2020. <a href=https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96>Decolonising AI: A transfeminist approach to data and social justice</a></li><li>Davar Ardalan, Burr Settles, Chamisa Edmo, Tracy Monteith, Wolfgang Victor Yarlott, and Alva Lim. 2020. <a href=https://aiforgood.itu.int/events/indigenous-knowledge-and-ai/>Indigenous Knowledge and AI</a></li><li>Geoff McMaster. 2020. <a href=https://www.ualberta.ca/folio/2020/10/creating-ethical-ai-from-indigenous-perspectives.html>Creating ethical AI from Indigenous perspectives</a></li><li>Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman, Ashley Cordes, Joel Davison, Kūpono Duncan, Sergio Garzon, D. Fox Harrell, Peter-Lucas Jones, Kekuhi Kealiikanakaoleohaililani, Megan Kelleher, Suzanne Kite, Olin Lagon, Jason Leigh, Maroussia Levesque, Keoni Mahelona, Caleb Moses, Isaac (&lsquo;Ika&rsquo;aka) Nahuewai, Kari Noe, Danielle Olson, &lsquo;Ōiwi Parker Jones, Caroline Running Wolf, Michael Running Wolf, Marlee Silva, Skawennati Fragnito and Hēmi Whaanga. 2020. <a href=https://spectrum.library.concordia.ca/986506/>Indigenous Protocol and Artificial Intelligence Position Paper</a></li><li>Ashwin Rodrigues. 2016. <a href=https://www.vice.com/en/article/jpgpey/a-history-of-smarterchild>A History of SmarterChild</a></li><li>Frank Schilder. 2020. <a href=https://towardsdatascience.com/gpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66>GPT-3: The good, the bad and the ugly</a></li><li>Liz O&rsquo;Sullivan and John Dickerson. 2020. <a href=https://techcrunch.com/2020/08/07/here-are-a-few-ways-gpt-3-can-go-wrong/>Here are a few ways GPT-2 can go wrong</a></li><li>Tristan Greene. 2020. <a href=https://thenextweb.com/neural/2020/09/24/gpt-3s-bigotry-is-exactly-why-devs-shouldnt-use-the-internet-to-train-ai/>GPT-3&rsquo;s bigotry is exactly why devs shouldn&rsquo;t use the internet to train AI</a></li><li>Will Douglas Heaven. 2020. <a href=https://www.technologyreview.com/2020/10/23/1011116/chatbot-gpt3-openai-facebook-google-safety-fix-racist-sexist-language-ai/>How to make a chatbot that isn&rsquo;t racist or sexist</a></li><li>Dave Gershgorn. 2020. <a href=https://onezero.medium.com/for-some-reason-im-covered-in-blood-gpt-3-contains-disturbing-bias-against-muslims-693d275552bf>‘For Some Reason I’m Covered in Blood’: GPT-3 Contains Disturbing Bias Against Muslims</a></li><li>Jonathan Vanian. 2020. <a href=https://fortune.com/2020/09/29/artificial-intelligence-openai-gpt3-toxic/>Your favorite A.I. language tool is toxic</a></li><li>Eliza Strickland. 2021. <a href=https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/open-ais-powerful-text-generating-tool-is-ready-for-business>OpenAI&rsquo;s GPT-3 Speaks! (Kindly Disregard Toxic Language)</a></li><li>Benjamin Bengfort, Rebecca Bilbro, Tony Ojeda. 2018. <a href=https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/>Applied Text Analysis with Python: Building Language-Aware Data Products</a></li></ul><h2 id=footnotes>Footnotes</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>In machine learning, bias is an error from erroneous assumptions in the learning algorithm.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class="flex flex-wrap"><a href=/authors/rebecca-bilbro class="single-multi-author lg:w-[20ch] mx-2">Rebecca Bilbro</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span><b class=text-[#1D65A6]>Recent</b>
Rotations</span>
<img src=img/butterfly.png alt=butterfly class="ml-4 h-6 sm:h-8 relative top-1"></h2><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="grid md:grid-cols-2 xl:grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/practical-ai-strategies-for-2024/><img src=https://rotational.io/img/blog/2024-01-15-practical-ai-strategies-for-2024/shipping.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/ai/ml>AI/ML</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/strategy>Strategy</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-auto md:h-24" href=https://rotational.io/blog/practical-ai-strategies-for-2024/>Practical AI Strategies for 2024</a></h3><div class='h-auto md:h-36'><p class="mt-3 md:mt-8 text-base">Coming off the 2023 &ldquo;AI hype cycle&rdquo;, how should business leaders approach 2024? Learn 5 practical AI strategies every business should consider.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><a href=/authors/edwin-schmerer class="flex items-center"><img src=img/team/edwin-schmierer.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Edwin Schmerer</span></a></div><div class=font-extralight>Jan 15, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/real-time-flight-delays/><img src=https://rotational.io/img/blog/2024-01-09-real-time-flight-delays/nasa-virtual-airport.jpg alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/hackathon>Hackathon</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/data-science>Data Science</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/ensign>Ensign</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-auto md:h-24" href=https://rotational.io/blog/real-time-flight-delays/>How to Build a Real-Time Model to Predict Flight Delays</a></h3><div class='h-auto md:h-36'><p class="mt-3 md:mt-8 text-base">Have you ever tried to build a model that can handle new data in real time? We set out to do just that, and discovered that there aren&rsquo;t a lot of tutorials about training real-time machine learning models, so we made this one!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><img src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class="list-multi-author font-extralight"><a href=/authors/jason-chandra>Jason Chandra</a></li><li class="list-multi-author font-extralight"><a href=/authors/kevin-sianto>Kevin Sianto</a></li><li class="list-multi-author font-extralight"><a href=/authors/toby-chiu>Toby Chiu</a></li></ul></div><div class=font-extralight>Jan 9, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/pubsub-101---querying-topics/><img src=https://rotational.io/img/blog/otter_investigator.png alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex whitespace-nowrap"><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/ensign>Ensign</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/ensql>enSQL</a></li><li class="blog-tag text-base font-bold text-[#1D65A6]"><a href=/tags/pubsub-101>PubSub 101</a></li></ul><h3 class="text-xl font-extrabold mt-3 pb-2"><a class="block h-auto md:h-24" href=https://rotational.io/blog/pubsub-101---querying-topics/>PubSub 101 - Querying Topics with SQL</a></h3><div class='h-auto md:h-36'><p class="mt-3 md:mt-8 text-base">Real-time data streams are powerful, but sometimes you need to convert the stream into a batch or replay parts of the stream. Here&rsquo;s how to write customized SQL to more deeply understand and interact with your historic data.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6"><div class="flex items-center"><a href=/authors/patrick-deziel class="flex items-center"><img src=img/team/patrick-deziel.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Patrick Deziel</span></a></div><div class=font-extralight>Dec 8, 2023</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start"><input type=checkbox id=checkbox required class="w-6 h-6 block border-0">
<label for=checkbox><span class="ml-2 text-left">I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><div id=footerBackground><footer class="bg-hero-footer bg-cover"><div class="pt-[350px] font-extralight text-white"><div class="max-w-7xl mx-auto px-6"><div class="max-[650px]:text-center sm:grid grid-cols-3"><div class="my-10 sm:my-0"><h5 class=mb-3>PRODUCT</h5><ul><li class=pb-3><a href=https://rotational.app target=_blank class=font-bold>Ensign</a></li><li class=pb-3><a href=/ensign-pricing target=_blank class=font-bold>Pricing</a></li><li class=pb-3><a href=https://ensign.rotational.dev/getting-started/ target=_blank class=font-bold>Docs</a></li><li class=pb-3><a href=https://ensign.rotational.dev/sdk/ target=_blank class=font-bold>SDKs</a></li><li class=pb-3><a href=https://status.rotational.dev/ target=_blank class=font-bold>Status</a></li></ul></div><div class="mb-10 sm:mb-0"><h5 class=mb-3>COMPANY</h5><ul><li class=pb-3><a href=/services class=font-bold>Services</a></li><li class=pb-3><a href=/blog class=font-bold>Blog</a></li><li class=pb-3><a href=/about class=font-bold>About</a></li></ul></div><div><h5 class=mb-3>COMMUNITY</h5><ul><li class=pb-3><a href=/ensign-u class=font-bold>Ensign U</a></li><li class=pb-3><a href=/data-playground class=font-bold>Data Playground</a></li><li class=pb-3><a href=/opensource class=font-bold>Open Source</a></li><li class=pb-3><a href=/resources class=font-bold>Resources</a></li></ul></div></div><div class="max-w-7xl sm:flex justify-between border-t py-6 mt-12 sm:mt-32"><div class="mx-auto xl:ml-5 sm:mt-0 mt-8"><div><ul class="mx-auto grid grid-cols-2 gap-x-20 md:gap-x-32 lg:grid-cols-4"><li class="pb-8 mt-1"><a href=https://twitter.com/rotationalio class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/twitter.svg alt class=scale-75>
<span class=ml-4>Twitter</span></a></li><li class="pb-8 mt-1"><a href=https://github.com/rotationalio class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/github.svg alt class=scale-[.8]>
<span class=ml-4>GitHub</span></a></li><li class=pb-8><a href=https://www.linkedin.com/company/rotational class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/linkedin.svg alt class=scale-75>
<span class="mt-2 ml-4">LinkedIn</span></a></li><li class="pb-8 mt-2"><a href=mailto:info@rotational.io class="flex items-center p-2 hover:rounded-full hover:bg-icon-hover" target=_blank><img src=img/footer/email.svg alt class=scale-[.8]>
<span class=ml-4>Email</span></a></li></ul></div></div></div><div class="sm:flex justify-between py-6"><p>Copyright © Rotational Labs, Inc. 2021–2024 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex"><li class="border-r pr-4 mr-4"><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></div></footer></div><script src=https://rotational.io/js/app.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.js></script>
<script src=https://unpkg.com/@highlightjs/cdn-assets/highlight.min.js></script></body></html>