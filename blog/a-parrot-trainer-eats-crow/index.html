<!doctype html><html lang=en-us><head><meta charset=UTF-8><title>Rotational Labs | A Parrot Trainer Eats Crow</title>
<base href=https://rotational.io/ target=_self><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta name=keywords content="ai for companies,ai software,ai consulting,ai solutions,ai development,enterprise ai,ai services,ai platform,ai applications,ai for business,artificial intelligence solutions,artificial intelligence consulting"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="A Parrot Trainer Eats Crow"><meta property="og:description" content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta property="og:image" content="https://rotational.io/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots.jpg"><meta property="og:url" content="https://rotational.io/blog/a-parrot-trainer-eats-crow/"><meta property="og:type" content="website"><meta name=twitter:title content="A Parrot Trainer Eats Crow"><meta name=twitter:card content="summary"><meta name=twitter:description content="Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?"><meta name=twitter:image content="https://rotational.io/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script type=text/javascript id=hs-script-loader async defer src=//js.hs-scripts.com/24168101.js></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("consent","default",{ad_storage:"denied",ad_user_data:"denied",ad_personalization:"denied",analytics_storage:"denied",functionality_storage:"denied",personalization_storage:"denied"});const hspConsent=window._hsp=window._hsp||[];hspConsent.push(["addPrivacyConsentListener",function(e){const s=e&&(e.allowed||e.categories&&e.categories.analytics),t=e&&(e.allowed||e.categories&&e.categories.advertisement),n=e&&(e.allowed||e.categories&&e.categories.functionality);gtag("consent","update",{ad_storage:t?"granted":"denied",ad_user_data:t?"granted":"denied",ad_personalization:t?"granted":"denied",analytics_storage:s?"granted":"denied",functionality_storage:n?"granted":"denied",personalization_storage:n?"granted":"denied"})}])</script><script src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW" async defer></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script async defer src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script><script src=https://kit.fontawesome.com/fea17a4e21.js crossorigin=anonymous></script></head><body><div class="relative bg-[#1D65A6]"><nav class="w-full max-w-7xl mx-auto px-4 sm:px-6 py-5" aria-label=Global><div class="relative max-w-7xl w-full flex flex-wrap lg:flex-nowrap items-center justify-between mx-auto"><a href=/><img src=/img/rototational-white-text-only_hu15583614935666962927.webp alt=Rotational class="h-6 w-auto">
</a><button data-collapse-toggle=navbar-dropdown type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls=navbar-dropdown aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="fa fa-bars text-xl text-white"></i></button><div class="hidden absolute z-[9999] lg:static top-16 w-[92%] md:w-[96%] lg:w-auto lg:block bg-white lg:bg-transparent text-[#192E5B] lg:text-[#F2F2F2] py-2 rounded-md" id=navbar-dropdown><ul class="flex flex-col lg:gap-2 xl:gap-4 md:flex-row font-semibold w-full md:justify-between"><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/about/>About</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><button id=dropdownNavbarLink data-dropdown-toggle=dropdownNavbar class="uppercase flex items-center justify-between gap-x-2 w-full px-3 rounded md:border-0 md:p-0 md:w-auto hover:text-black">
Services
<i class="fa fa-angle-down pt-1"></i></button><div id=dropdownNavbar class="z-10 hidden font-normal bg-[#192E5B] divide-y divide-[#192E5B] rounded-lg shadow w-44"><ul class="py-2 text-sm text-[#F2F2F2]" aria-labelledby=dropdownLargeButton><li><a href=/services/ai-assessments/ class="block px-3 py-2 hover:font-bold">AI Assessments</a></li><li><a href=/services/ai-product-development/ class="block px-3 py-2 hover:font-bold">AI Product Development</a></li><li><a href=/services/ai-ops-and-data-foundations/ class="block px-3 py-2 hover:font-bold">AI Ops & Data Foundations</a></li></ul></div></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/case-studies>Case Studies</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/blog/>Blog</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/learning/>Learning</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/endeavor/>Product</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/contact/>Contact</a></li></ul></div></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=/img/blog/2021-03-19-a-parrot-trainer-eats-crow/parrots_hu11881571149099812428.webp alt="A Parrot Trainer Eats Crow" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="A Parrot Trainer Eats Crow"><b class=text-[#1D65A6]>A </b>Parrot Trainer Eats Crow</h3><div class="flex flex-wrap justify-center items-center my-6"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span><a href=/authors/rebecca-bilbro>Rebecca Bilbro</a> | Friday, Mar 19, 2021 |&nbsp;
</span><span><a href=/tags/ai>AI</a>,&nbsp;
</span><a href=/tags/ml>ML</a></span></div><article class="max-w-[800px] mx-auto prose mt-12"><p>In this post, we&rsquo;ll consider how it is that models trained on massive datasets using millions of parameters can be both &ldquo;low bias&rdquo; and also <em>very biased</em>, and begin to think through what we in the ML community might be able to do about it.</p><h2 id=birds-on-a-wire>Birds on a Wire</h2><p>In the machine learning community, we are trained to think of <a href=http://scott.fortmann-roe.com/docs/BiasVariance.html>size as inversely proportional to bias</a>. We associate small datasets with the problem of underfit, which is to say high bias. We learn that in the face of unfamiliar data, underfit models make poor assumptions that lead to inaccuracies. Likewise, we call models with smaller sets of hyperparameters &ldquo;weak learners&rdquo; because their limited complexity limits our ability to reduce bias even as our dataset size grows.</p><p>This intuition has driven the ML community towards ever larger datasets and increasingly complex model architectures, and to be sure, towards ever better accuracy scores. Unfortunately (and not unironically), this progression has driven a wedge between the ML definition<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> of &ldquo;bias&rdquo; and the more colloquial sense of the word.</p><h2 id=migration-patterns>Migration Patterns</h2><p>To understand our situation, it may help to trace back through the pattern of our collective migration towards these more complex models.</p><blockquote><p>&ldquo;Is deep learning really necessary to solve most machine learning problems?&rdquo;</p></blockquote><p>This question has come to me more times than I can count over the years, both at work and with my students. It often comes laced with some underlying anxiety. Sometimes it means &ldquo;These deep learning hyperparameters are really tedious to tune, are you sure it&rsquo;s worth my time to learn them?&rdquo;. Sometimes it means &ldquo;does your solution actually use neural networks, or is this just a marketing layer on top of a Logistic Regression?&rdquo;.</p><p>To be fair, I find this kind of skepticism totally healthy. We even gave the skeptics a little shout-out in <a href=https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/>our book&rsquo;s</a> chapter on deep learning, writing,</p><blockquote><p>As application developers, we tend to be cautiously optimistic about the kinds of bleeding-edge technologies that sound good on paper but can lead to headaches when it comes to operationalization.</p></blockquote><p>My own views about the value and practicality of deep learning are always changing, and my answers to askers of this question have shifted over time. While I almost always bring up what I see as the two main tradeoffs between traditional models and deep learning, namely model complexity (multi-layer neural models are more complicated, harder to tune, easier to mess up) and speed (multi-layer neural models tend to take longer to train and can impede rapid prototyping and iteration), I am much more encouraging about the use cases for deep learning these days than I used to be.</p><p>The reality is that deep neural models are getting more practical to use all the time, and even if they require us to grapple with more complexity, the rewards of being able to scale complexity are hard to ignore. Given enough data, deep neural models are likely to always outperform more traditional machine learning algorithms, simply because they don&rsquo;t ever have to stop learning.</p><h2 id=training-parrots>Training Parrots</h2><p>Industry&rsquo;s shift towards deep learning in earnest has become particularly evident to me in the last 5 or 6 years of building commercial NLP applications. Five years ago, we were all using software designed out of the computational linguistics tradition — models that took into account things like part-of-speech tags, n-grams, and syntactic parsers (e.g. <a href=https://www.nltk.org/>NLTK</a>). Three years ago, the community had begun to shift towards software that leveraged a hybrid of computational linguistics and neural network-trained distributed representations (e.g. <a href=https://spacy.io/>SpaCy</a>, <a href=https://radimrehurek.com/gensim/>Gensim</a>). These new hybrid libraries abstracted away much of the grammar-based feature extraction work that we previously had to do ourselves. Now, in the first half of 2021, many folks go directly to projects like <a href=https://huggingface.co/transformers/>HuggingFace&rsquo;s Transformers library</a>, leveraging pre-trained language models that require no feature extraction at all beyond transformation from arrays into tensors.</p><p>The progression over the last few years has been amazing to watch. There have never been more excellent open source resources for people who do what I do. It has never been easier to <a href=https://rebeccabilbro.github.io/tailored-learning/>bootstrap a domain-specific language model</a>, even if <a href=https://rebeccabilbro.github.io/small-data-delegated-literacy/>you don&rsquo;t have much data to start with</a>. But it&rsquo;s also true that we have never been more removed from our data than we are today, or less in touch with its underlying patterns, themes, and biases.</p><p>This problem is at the heart of the recent paper <a href=https://dl.acm.org/doi/pdf/10.1145/3442188.3445922>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</a> The paper itself is at the heart of a controversy about Google&rsquo;s <a href=https://www.bbc.com/news/technology-56135817>abrupt dismissal</a> of two of the authors, Dr. Timnit Gibru and Dr. Margaret Mitchell, who helped found and lead Google&rsquo;s AI Ethics team.</p><p>The Parrots paper discusses a range of concerns with large language models (like the ones Google makes), including the dangers of &ldquo;ersatz fluency&rdquo; and the environmental costs of training such models. Indeed, we seem to be entering a new phase in which machine models are only distinguishable from humans by the absence of legal and ethical responsibilities for their words and actions. Moreover, as with cryptocurrencies and <a href=https://everestpipkin.medium.com/but-the-environmental-issues-with-cryptoart-1128ef72e6a3>cryptoart like NFTs</a>, it is becoming clear that the costs are disproportionately paid by people unlikely to realize much of their benefits.</p><p>The paper is, however, primarily a warning about the challenge of responsibly building deep learning models that require a volume of data that exceeds human capacity to effectively curate. And as an NLP developer, this was the part of the paper that triggered that uneasy feeling in the pit of my stomach. This is something that <del>we</del> I need to take responsibility for and help fix. But how?</p><h2 id=eating-crow>Eating Crow</h2><p>Presumably the first step is admitting you have a problem. OpenAI <a href=https://github.com/openai/gpt-3/blob/master/model-card.md#limitations>has acknowledged</a> that GPT-3 exhibits concerning NLG properties, which they attribute to the training data:</p><blockquote><p>GPT-3, like all large language models trained on internet corpora, will generate stereotyped or prejudiced content. The model has the propensity to retain and magnify biases it inherited from any part of its training, from the datasets we selected to the training techniques we chose. This is concerning, since model bias could harm people in the relevant groups in different ways by entrenching existing stereotypes and producing demeaning portrayals amongst other potential harms.</p></blockquote><p>In his article, &ldquo;For Some Reason I’m Covered in Blood&rdquo;, <a href=https://onezero.medium.com/for-some-reason-im-covered-in-blood-gpt-3-contains-disturbing-bias-against-muslims-693d275552bf>Dave Gershgorn</a> writes about GPT-3&rsquo;s problem with Islam:</p><blockquote><p>This bias is most evident when GPT-3 is given a phrase containing the word “Muslim” and asked to complete a sentence with the words that it thinks should come next. In more than 60% of cases documented by researchers, GPT-3 created sentences associating Muslims with shooting, bombs, murder, and violence.</p></blockquote><p>So, yes, as an NLP developer, I <em>am</em> concerned that leveraging pretrained LMs in my consumer-facing products could manifest in bias that might alienate my Muslim, my women, my LGBTQ+ users. However, I am <em>also</em> concerned about how my commercialization of such LMs could serve to further normalize and entrench racist, sexist, anti-Islamic, homophobic, transphobic, and white supremist beliefs for everyone else.</p><p>As developers, when we build data products, we help produce the training data that will be used for the next generations of machine learning models. When we build atop models like GPT-3, that has the effect of ensuring that bias and hate speech remain in the collective conversation online, indefinitely.</p><p>How can we do a better job of dataset curation for large language models to avoid the problem of poisonous training data? In the Parrots paper, Dr. Gibru et al. discuss some of the approaches that were used to filter the training data for models like GPT-3 and BERT:</p><blockquote><p>The Colossal Clean Crawled Corpus&mldr;is cleaned, <em>inter alia</em>, by discarding any page containing one of a list of about 400 “Dirty, Naughty, Obscene or Otherwise Bad Words". This list is overwhelmingly words related to sex, with a handful of racial slurs and words related to white supremacy (e.g. swastika, white power) included. While possibly effective at removing documents containing pornography (and the associated problematic stereotypes encoded in the language of such sites) and certain kinds of hate speech, this approach will also undoubtedly attenuate, by suppressing such words as <em>twink</em>, the influence of online spaces built by and for LGBTQ people. If we filter out the discourse of marginalized populations, we fail to provide training data that reclaims slurs and otherwise describes marginalized identities in a positive light.</p></blockquote><p>In other words, the data cleaning mechanisms in place are crude at best, and perhaps overly aggressive in filtering out marginalized conversations that may be punctuated by reclaimed &ldquo;bad&rdquo; words. And yet&mldr;any solution I can think of that would manage to include marginalized conversations might also produce language models prone to using those reclaimed words.</p><p>This leads us to the question of whether it would <em>ever</em> be ok for a LM to use a word like &ldquo;twink&rdquo;. Knowing who can use and who should refrain from using such reclaimed words is something that humans — despite our access to education, historical context about oppression, and discussions about systemic racism, sexism, and homophobia — <a href=https://www.yahoo.com/lifestyle/papa-johns-founder-says-hes-211500691.html>still routinely screw up</a>.</p><h2 id=beyond-the-gilded-cage>Beyond the Gilded Cage</h2><p>My sense is that an awareness of appropriate use for things like reclaimed words, code switching, and patois involve a degree of complexity that we cannot reasonably expect of any global model. Instead, perhaps the answer is to decolonize our language models.</p><p><a href=https://arxiv.org/pdf/2007.04068.pdf>Mohamed, et al.</a> summarize three strategies for the decolonisation of artificial intelligence: the decentering view, the additive-inclusive view, and the engagement view. It is interesting to think about how these methods might be used to inform the model development, training, and evaluation processes. For instance, for the decentering view, this could mean training models on non-white, non-male, non-Western, non-Judeo Christian conversations, rather than applying zero-shot learning techniques to tack additional training onto pretrained LMs that have already encoded the white, male, Western, Judeo Christian viewpoint.</p><p>Reading the Parrots paper also got me thinking and reading up on indigenous language models (e.g. <a href=https://aiforgood.itu.int/events/indigenous-knowledge-and-ai/>this workshop</a>, <a href=https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96>this article</a>, and <a href=http://blog.shakirm.com/2018/10/decolonising-artificial-intelligence/>this blog</a>). My research led me to find a very interesting piece called the <a href=https://spectrum.library.concordia.ca/986506/>Indigenous Protocol and Artificial Intelligence Position Paper</a> that was recently published by a consortium of indigenous researchers, with the following passage:</p><blockquote><p>Indigenous ways of knowing are rooted in distinct, sovereign territories across the planet. These extremely diverse landscapes and histories have influenced different communities and their discrete cultural protocols over time. A single ‘Indigenous perspective’ does not exist, as epistemologies are motivated and shaped by the grounding of specific communities in particular territories. Historically, scholarly traditions that homogenize diverse Indigenous cultural practices have resulted in ontological and epistemological violence, and a flattening of the rich texture and variability of Indigenous thought. Our aim is to articulate a multiplicity of Indigenous knowledge systems and technological practices that can and should be brought to bear on the ‘question of AI.’</p></blockquote><p>Perhaps the time has come to move away from monolith language models that reduce the rich variations and complexities of our conversations to a simple argmax on the output layer, and instead embrace a new generation of language model architectures that are just as organic and diverse as the data they seek to encode.</p><h2 id=references>References</h2><ul><li>Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. <a href=https://dl.acm.org/doi/pdf/10.1145/3442188.3445922>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</a></li><li>Shakir Mohamed. 2018. <a href=http://blog.shakirm.com/2018/10/decolonising-artificial-intelligence/>Decolonising Artificial Intelligence</a></li><li>Shakir Mohamed, Marie-Therese Png, William Isaac. 2020. <a href=https://arxiv.org/pdf/2007.04068.pdf>Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence</a></li><li>Paz Peña and Joana Varon. 2020. <a href=https://medium.com/codingrights/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice-a5e52ac72a96>Decolonising AI: A transfeminist approach to data and social justice</a></li><li>Davar Ardalan, Burr Settles, Chamisa Edmo, Tracy Monteith, Wolfgang Victor Yarlott, and Alva Lim. 2020. <a href=https://aiforgood.itu.int/events/indigenous-knowledge-and-ai/>Indigenous Knowledge and AI</a></li><li>Geoff McMaster. 2020. <a href=https://www.ualberta.ca/folio/2020/10/creating-ethical-ai-from-indigenous-perspectives.html>Creating ethical AI from Indigenous perspectives</a></li><li>Jason Edward Lewis, Angie Abdilla, Noelani Arista, Kaipulaumakaniolono Baker, Scott Benesiinaabandan, Michelle Brown, Melanie Cheung, Meredith Coleman, Ashley Cordes, Joel Davison, Kūpono Duncan, Sergio Garzon, D. Fox Harrell, Peter-Lucas Jones, Kekuhi Kealiikanakaoleohaililani, Megan Kelleher, Suzanne Kite, Olin Lagon, Jason Leigh, Maroussia Levesque, Keoni Mahelona, Caleb Moses, Isaac (&lsquo;Ika&rsquo;aka) Nahuewai, Kari Noe, Danielle Olson, &lsquo;Ōiwi Parker Jones, Caroline Running Wolf, Michael Running Wolf, Marlee Silva, Skawennati Fragnito and Hēmi Whaanga. 2020. <a href=https://spectrum.library.concordia.ca/986506/>Indigenous Protocol and Artificial Intelligence Position Paper</a></li><li>Ashwin Rodrigues. 2016. <a href=https://www.vice.com/en/article/jpgpey/a-history-of-smarterchild>A History of SmarterChild</a></li><li>Frank Schilder. 2020. <a href=https://towardsdatascience.com/gpt-3-the-good-the-bad-and-the-ugly-5e2e5b7f0f66>GPT-3: The good, the bad and the ugly</a></li><li>Liz O&rsquo;Sullivan and John Dickerson. 2020. <a href=https://techcrunch.com/2020/08/07/here-are-a-few-ways-gpt-3-can-go-wrong/>Here are a few ways GPT-2 can go wrong</a></li><li>Tristan Greene. 2020. <a href=https://thenextweb.com/neural/2020/09/24/gpt-3s-bigotry-is-exactly-why-devs-shouldnt-use-the-internet-to-train-ai/>GPT-3&rsquo;s bigotry is exactly why devs shouldn&rsquo;t use the internet to train AI</a></li><li>Will Douglas Heaven. 2020. <a href=https://www.technologyreview.com/2020/10/23/1011116/chatbot-gpt3-openai-facebook-google-safety-fix-racist-sexist-language-ai/>How to make a chatbot that isn&rsquo;t racist or sexist</a></li><li>Dave Gershgorn. 2020. <a href=https://onezero.medium.com/for-some-reason-im-covered-in-blood-gpt-3-contains-disturbing-bias-against-muslims-693d275552bf>‘For Some Reason I’m Covered in Blood’: GPT-3 Contains Disturbing Bias Against Muslims</a></li><li>Jonathan Vanian. 2020. <a href=https://fortune.com/2020/09/29/artificial-intelligence-openai-gpt3-toxic/>Your favorite A.I. language tool is toxic</a></li><li>Eliza Strickland. 2021. <a href=https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/open-ais-powerful-text-generating-tool-is-ready-for-business>OpenAI&rsquo;s GPT-3 Speaks! (Kindly Disregard Toxic Language)</a></li><li>Benjamin Bengfort, Rebecca Bilbro, Tony Ojeda. 2018. <a href=https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/>Applied Text Analysis with Python: Building Language-Aware Data Products</a></li></ul><h2 id=footnotes>Footnotes</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>In machine learning, bias is an error from erroneous assumptions in the learning algorithm.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About </span>This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Models trained on massive datasets using millions of parameters can both have low bias and also be very biased - what can we in the ML community do about this?</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/rebecca-bilbro><img src=img/team/rebecca-bilbro.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg">
</a><span class="flex flex-wrap"><a href=/authors/rebecca-bilbro class="lg:w-[20ch] mx-2">Rebecca Bilbro</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><div class="flex items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span class=text-[#1D65A6]>Recommended</span>
&nbsp;Rotations</h2></div><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><ul class="grid sm:grid-cols-2 lg:grid-cols-3 gap-6 sm:my-8"><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/how-to-build-ai-applications-in-minutes-with-transformersjs/><img loading=lazy src=/img/blog/2024-12-16-building-ai-applications-with-transformersjs/building-ai-applications-with-javascript_hu12426954862117539852.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/javascript>JavaScript</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/how-to-build-ai-applications-in-minutes-with-transformersjs/ class=block>How to Build AI Applications In Minutes With Transformers.js</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">Creating AI applications is easier than ever these days, especially in JavaScript. Discover how you can build your own in only a few minutes with Transformers.js!</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/danielle-maxwell_hu8220723638078271173.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a></li></ul></div><div class=font-extralight>Dec 16, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/product-development-in-the-ai-era/><img loading=lazy src=/img/blog/2024-11-27-product-development-in-the-ai-era/user_journey_hu16754287719509965427.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/strategy>Strategy</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/product-development-in-the-ai-era/ class=block>Product Development in the AI Era</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">Last month, we spoke to a panel of expert product managers who have successfully implemented AI solutions in their organizations. This post recaps some of the key strategies and insights they shared.</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/prema-roman_hu8516555698015783157.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>Nov 27, 2024</div></div></div></li><li class="mt-6 bg-[#ECF6FF] rounded-xl"><div class="flex flex-col h-full"><a href=https://rotational.io/blog/predicting-star-ratings/><img loading=lazy src=/img/blog/predicting-stars_hu1319351158746997782.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="px-4 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a></li></ul><div class="flex flex-col mt-4 h-full"><h3 class="text-xl font-extrabold sm:h-36"><a href=https://rotational.io/blog/predicting-star-ratings/ class=block>Predicting Star Ratings: Sentiment Analysis Built on MongoDB</a></h3><div class=mb-4><p class="my-4 sm:mt-auto">If you want to build a robust machine learning model, the most important ingredient is data &ndash; but keep in mind that tuning your model will rely on devising a systematic way to store and query that data! In this post, we explore a …</p></div></div></div><div class="flex justify-between mt-auto items-center border-t px-4 py-3 h-16"><div class="flex items-center"><img loading=lazy src=/img/team/nabiha-naqvie_hu15146363001864734448.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/nabiha-naqvie>Nabiha Naqvie</a></li></ul></div><div class=font-extralight>Nov 14, 2021</div></div></div></li></ul></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-8 px-12 md:px-16 text-white md:rounded-lg"><input type=hidden id=newsletterFormID value=8aeeb77b-a5e0-4772-b726-44e1fc2eb6e1><form action=newsletter method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><div class="bg-teal-100 border-t-4 border-teal-500 mt-3 rounded-b text-teal-900 p-4 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for joining the Rotational Labs newsletter!</p></div></div></div><div id=newsletter-error class="hidden mt-3 bg-red-200 border-t-4 border-red-600 text-red-900 rounded-b p-4 shadow-md" role=alert><div><p class=text-sm>Your request did not go through, please try again. If you need immediate assistance, please email support@rotational.io.</p></div></div><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start gap-x-2"><input type=checkbox id=checkbox required name=consent class="mt-1 w-4 h-4 block border-0">
<label for=checkbox><span id=consentText>I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="flex justify-center"><button id=newsletter-bttn type=submit data-sitekey=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk data-action=newsletter class="bg-[#192E5B] px-10 py-3 mt-8 rounded-lg text-sm text-white uppercase md:text-base hover:bg-[#192E5B]/80">
Submit</button></div></form></div></main><footer class="relative mt-40 md:mt-56 bg-[#192E5B]"><div class="relative w-full pt-36 md:pt-16 lg:pt-24 2xl:pt-20 font-extralight text-white"><div class="-mt-52 w-full mx-auto max-w-screen-xl px-4"><section class="bg-[#72A2C0] w-full p-6 md:py-20 md:px-16"><h2 class="my-4 text-2xl sm:text-3xl md:text-5xl text-white font-extrabold">LET'S ENVISION & BUILD THE FUTURE TOGETHER.</h2><div class=py-6><a href=/contact class="p-3 md:p-4 md:px-6 bg-[#2F4858] font-bold md:text-lg text-white text-center hover:bg-[#2F4858]/80">CONTACT US</a></div></section></div><div class="max-w-7xl mx-auto px-6"><div class="mt-12 flex flex-col md:flex-row lg:justify-between gap-x-8"><div class="my-4 max-w-xs"><h5 class="mb-3 font-extrabold">OUR PRESENCE</h5><p>We share because we care, about topics, tools, and technologies that we believe impact the AI economy.</p><div class=py-4><ul class="flex justify-between items-center gap-x-8"><li><a href=https://twitter.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-x-twitter"></i><p class=sr-only>Twitter</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-linkedin"></i><p class=sr-only>LinkedIn</p></a></li><li><a href=https://github.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-github"></i><p class=sr-only>GitHub</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-youtube"></i><p class=sr-only>YouTube</p></a></li><li><a href=https://www.twitch.tv/rotationallabs target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-twitch"></i><p class=sr-only>Twitch</p></a></li></ul></div></div><div class=my-4><h5 class="mb-3 font-extrabold">COMPANY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/about>About Us</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/case-studies>Case Studies</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/endeavor>Endeavor</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/blog>Blog</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">COMMUNITY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/learning>Learning</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/opensource>Open Source</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">CONTACT US</h5><ul><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-map-marker-alt text-[#757575]"></i>
St. Paul, MN & Washington, DC</li><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-envelope text-[#757575]"></i>
info@rotational.io</li></ul><div class=py-8><a href=/contact class="p-3 bg-[#ECF6FF] font-bold text-black text-center hover:bg-[#ECF6FF]/80">CONTACT US</a></div></div></div><div class="sm:flex justify-between py-6 border-t mt-4"><p>Copyright © Rotational Labs, Inc. 2021–2025 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex gap-x-8"><li><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li><li><button id=hs_show_banner_button type=button onclick='(()=>{const e=window._hsp=window._hsp||[];e.push(["showBanner"])})()'>
Manage Cookies</button></li></ul></div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.js></script><script src=https://rotational.io/js/blogSingle.js></script><script type=module src=https://rotational.io/js/newsletterForm.js></script></body></html>