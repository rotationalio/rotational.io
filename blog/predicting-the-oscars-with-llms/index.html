<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | Predicting the Oscars With LLMs</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Can LLMs predict the Oscars?"><meta name=keywords content="AI solutions for mid-market companies,AI-driven tools,Business automation solutions,AI-powered interfaces,Intelligent agents,Natural language processing (NLP),Computer vision AI,Streamline operations with AI,machine learning,Boost business performance with AI,AI for business growth,Tailored AI solutions,Trusted AI solutions,AI for operational efficiency,Secure AI tools,AI expertise for mid-market businesses,Endeavor"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Predicting the Oscars With LLMs"><meta property="og:description" content="Can LLMs predict the Oscars?"><meta property="og:image" content="https://rotational.io/img/blog/trophies.webp"><meta property="og:url" content="https://rotational.io/blog/predicting-the-oscars-with-llms/"><meta property="og:type" content="website"><meta name=twitter:title content="Predicting the Oscars With LLMs"><meta name=twitter:card content="summary"><meta name=twitter:description content="Can LLMs predict the Oscars?"><meta name=twitter:image content="https://rotational.io/img/blog/trophies.webp"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW" defer></script>
<script type=module>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());
  gtag('config', 'G-2FKX6CWJHW');
</script><script src=https://kit.fontawesome.com/fea17a4e21.js crossorigin=anonymous></script></head><body><div class="relative bg-[#1D65A6]"><nav class="w-full max-w-7xl mx-auto px-4 sm:px-6 py-5" aria-label=Global><div class="relative max-w-7xl w-full flex flex-wrap lg:flex-nowrap items-center justify-between mx-auto"><a href=/><img src=img/rototational-white-text-only.png alt=Rotational class="h-6 w-auto"></a>
<button data-collapse-toggle=navbar-dropdown type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200" aria-controls=navbar-dropdown aria-expanded=false>
<span class=sr-only>Open main menu</span>
<i class="fa fa-bars text-xl text-white"></i></button><div class="hidden absolute z-[9999] lg:static top-16 w-[92%] md:w-[96%] lg:w-auto lg:block bg-white lg:bg-transparent text-[#192E5B] lg:text-[#F2F2F2] py-2 rounded-md" id=navbar-dropdown><ul class="flex flex-col lg:gap-2 xl:gap-4 md:flex-row font-semibold w-full md:justify-between"><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/about/>About</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><button id=dropdownNavbarLink data-dropdown-toggle=dropdownNavbar class="uppercase flex items-center justify-between gap-x-2 w-full px-3 rounded md:border-0 md:p-0 md:w-auto hover:text-black">
Services
<i class="fa fa-angle-down pt-1"></i></button><div id=dropdownNavbar class="z-10 hidden font-normal bg-[#192E5B] divide-y divide-[#192E5B] rounded-lg shadow w-44"><ul class="py-2 text-sm text-[#F2F2F2]" aria-labelledby=dropdownLargeButton><li><a href=/services/ai-assessments/ class="block px-3 py-2 hover:font-bold">AI Assessments</a></li><li><a href=/services/ai-product-development/ class="block px-3 py-2 hover:font-bold">AI Product Development</a></li><li><a href=/services/ai-ops-and-data-foundations/ class="block px-3 py-2 hover:font-bold">AI Ops & Data Foundations</a></li></ul></div></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/case-studies>Case Studies</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/blog/>Blog</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/learning/>Learning</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/endeavor/>Endeavor</a></li><li class="py-2 uppercase text-sm lg:text-[15px] xl:text-[17px]"><a class="px-3 py-3.5 hover:text-black" href=/contact/>Contact</a></li></ul></div></div></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/trophies.webp alt="Predicting the Oscars With LLMs" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Predicting the Oscars With LLMs"><b class=text-[#1D65A6]>Predicting</b>
the Oscars With LLMs</h3><div class="flex flex-wrap justify-center items-center my-4"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span><a href=/authors/patrick-deziel>Patrick Deziel</a> | Friday, Mar 8, 2024 |&nbsp;</span>
<span><a href=/tags/llms>LLMs</a>,&nbsp;</span>
<a href=/tags/semantic-similarity>Semantic Similarity</a>,&nbsp;</span>
<a href=/tags/python>Python</a></span></div><article class="max-w-[800px] mx-auto prose"><p>Looking for a middle ground between custom LLMs and traditional ML? Please welcome semantic search to the stage! Let&rsquo;s use semantic search to predict which film will take home the &ldquo;Best Picture&rdquo; Oscar this year 🤩</p><p>Last year we all went to see &ldquo;Everything Everywhere All at Once&rdquo; at our team retreat, and it went on to take home several awards, including Best Picture. Let&rsquo;s see if we can predict the future again!</p><h2 id=data-ingestion>Data Ingestion</h2><p>To start, there is a nice dataset on <a href=https://www.kaggle.com/datasets/unanimad/the-oscar-award>Kaggle</a> which compiles all the Oscar nominees and winners since 1927. It turns out that the best picture award has changed names several times, so it took some manual data engineering to extract the labels.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> bp <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;BEST PICTURE&#39;</span>, <span style=color:#e6db74>&#39;BEST MOTION PICTURE&#39;</span>, <span style=color:#e6db74>&#39;OUTSTANDING PICTURE&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;OUTSTANDING PRODUCTION&#39;</span>, <span style=color:#e6db74>&#39;OUTSTANDING MOTION PICTURE&#39;</span>
</span></span><span style=display:flex><span>   ]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#39;category&#39;</span>]<span style=color:#f92672>.</span>isin(bp)]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> df[<span style=color:#e6db74>&#39;winner&#39;</span>]<span style=color:#f92672>.</span>value_counts()
</span></span><span style=display:flex><span>winner
</span></span><span style=display:flex><span><span style=color:#66d9ef>False</span>    <span style=color:#ae81ff>496</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>True</span>      <span style=color:#ae81ff>95</span>
</span></span><span style=display:flex><span>Name: count, dtype: int64
</span></span></code></pre></div><p>There have been 591 best picture nominees and 95 winners over the years. Not the largest data set, but at least the class imbalance isn&rsquo;t terrible. To do machine learning I needed features so I scraped text from Wikipedia. Most films have a corresponding Wikipedia in the format:</p><p><code>wikipedia.org/wiki/{film_title}_({year}_film)</code></p><p>However as you might imagine this is not 100% consistent; it really just depends on how unique the film title happens to be. It was guessable enough to eventually get all 591 film articles into the DataFrame. I used <code>beautifulsoup</code> to extract the text from the downloaded HTML.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;text&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;wiki&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: BeautifulSoup(x, <span style=color:#e6db74>&#39;html.parser&#39;</span>)<span style=color:#f92672>.</span>get_text())
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;text&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#e6db74>&#34; &#34;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#39;</span><span style=color:#e6db74>&#34;</span>, <span style=color:#e6db74>&#34;&#39;&#34;</span>))
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>iloc[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;The Racket is a 1928 American silent crime drama film directed by Lewis Milestone and starring Thomas Meighan, Marie Prevost, Louis Wolheim, and George E. Stone...&#39;</span>
</span></span></code></pre></div><p>A <a href=https://www.scikit-yb.org/en/latest/api/text/tsne.html>TSNE projection</a> is one way to visualize the high-dimensional data (e.g. encoded documents with TF-IDF). It shows that there are at least some interesting clusters in the Wikipedia text. The green dots are the winners.</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/tsne.webp alt="&ldquo;TSNE Projection&rdquo;"></p><h2 id=initial-models>Initial Models</h2><p>My first idea was to encode the article text with a tried-and-tested approach like TF-IDF and fit a binary classifier using the encoded vectors as features. The best model was pretty overfit due to the small size of the training set.</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/decision_tree.webp alt="&ldquo;Decision Tree&rdquo;"></p><p>The next idea was to train <code>distilbert</code> for sequence classification to take advantage of the massive amount of pre-training. I was able to train a &ldquo;will it win&rdquo; model but the inferences were still not useful. Everything looks like a winner this year!</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/distilbert_results.webp alt="&ldquo;distilbert results&rdquo;"></p><h2 id=semantic-similarity>Semantic Similarity</h2><p>Given that there is so little training data, perhaps a similarity approach makes more sense. If we make the assumption that films similar to other Oscar winners are more likely to win, then we have a well-defined methodology to select the most probable winner.</p><p>The first step to computing similarity is to encode the articles text into vector space. Here we can take advantage of pre-trained LLMs. There are particular models that have been trained to maximize performance for tasks like semantic search. In this case, we are looking for a sentence transformer model like <code>all-MiniLM-L6-v2</code> that&rsquo;s trained for symmetric search (e.g. the query and documents in the corpus are about the same length).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> SentenceTransformer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#34;all-MiniLM-L6-v2&#34;</span>)
</span></span><span style=display:flex><span>best_pictures[<span style=color:#e6db74>&#34;embeddings&#34;</span>] <span style=color:#f92672>=</span> best_pictures[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>apply(
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>lambda</span> x: model<span style=color:#f92672>.</span>encode(x)
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Now that we have the embeddings we can compute the similarity between an arbitrary bit of text and all the films in the corpus. Ranking by similarity gives us the &ldquo;nearest neighbors&rdquo; to a particular film.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> util
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_most_similar</span>(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>):
</span></span><span style=display:flex><span>    embeddings <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>encode(text)
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;sim_score&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;embeddings&#34;</span>]<span style=color:#f92672>.</span>apply(
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>lambda</span> x: util<span style=color:#f92672>.</span>cos_sim(embeddings, x)<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> df<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sim_score&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)<span style=color:#f92672>.</span>head(n)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>film <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;American Fiction&#34;</span>
</span></span><span style=display:flex><span>text <span style=color:#f92672>=</span> eval_df[eval_df[<span style=color:#e6db74>&#34;film&#34;</span>] <span style=color:#f92672>==</span> film][<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>iloc[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>get_most_similar(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)[[<span style=color:#e6db74>&#34;film&#34;</span>, <span style=color:#e6db74>&#34;sim_score&#34;</span>, <span style=color:#e6db74>&#34;winner&#34;</span>]]
</span></span></code></pre></div><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/ranking.webp alt="&ldquo;Similarity Ranking&rdquo;"></p><p>From here it&rsquo;s a matter of creating some algorithm to produce a final ranking for this year&rsquo;s nominees. One approach might be to take the top n similar films and multiply the proportion of winners of that group by the average of the similarity scores.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>win_score</span>(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>    sim <span style=color:#f92672>=</span> get_most_similar(text, n<span style=color:#f92672>=</span>n)
</span></span><span style=display:flex><span>    winners <span style=color:#f92672>=</span> len(sim[sim[<span style=color:#e6db74>&#34;winner&#34;</span>]]) <span style=color:#f92672>/</span> n
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> sim[<span style=color:#e6db74>&#34;winner&#34;</span>]<span style=color:#f92672>.</span>mean() <span style=color:#f92672>*</span> winners
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>eval_df[<span style=color:#e6db74>&#34;win_score&#34;</span>] <span style=color:#f92672>=</span> eval_df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: win_score(x, n<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>))
</span></span><span style=display:flex><span>eval_df<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;win_score&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)[[<span style=color:#e6db74>&#34;film&#34;</span>, <span style=color:#e6db74>&#34;win_score&#34;</span>]]
</span></span></code></pre></div><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/sim_rankings.webp alt="&ldquo;Final Rankings&rdquo;"></p><p>The similarity approach predicts that Oppenheimer will take it home. This is in line with the <a href=https://www.vegasinsider.com/awards/odds/oscars/>betting odds</a> as of Friday, March 8.</p><pre tabindex=0><code>Oppenheimer -5000
Poor Things +2000
The Zone of Interest +2000
The Holdovers +2500
Anatomy of a Fall +5000
Barbie +6600
American Fiction +8000
Killers of the Flower Moon +10000
Past Lives +15000
Maestro +15000
</code></pre><h2 id=conclusion>Conclusion</h2><p>When you need to boost the performance of your machine learning model, it usually comes down to improving the quality of the training dataset. In cases where you <em>don&rsquo;t</em> have access to more data or you can&rsquo;t afford to train custom LLMs, a similarity approach can be a cost-effective (and more explainable) solution. And just as with film, a bit of creativity goes a long way!</p><div class="border-t my-12"></div><p>Photo by <a href="https://unsplash.com/@tommaomaoer?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">tommao wang</a> on <a href="https://unsplash.com/photos/gold-and-silver-pendant-lamps-GjtqYFnQEY4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Can LLMs predict the Oscars?</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class="flex flex-wrap"><a href=/authors/patrick-deziel class="lg:w-[20ch] mx-2">Patrick Deziel</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><div class="flex items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span class=text-[#1D65A6]>Recommended</span>
&nbsp;Rotations</h2></div><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="grid lg:grid-cols-2 xl:grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/teaching-llms-with-human-feedback/><img loading=lazy src=https://rotational.io/img/blog/otter_teacher.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/fine-tuning>Fine-tuning</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/teaching-llms-with-human-feedback/>Teaching LLMs With Continuous Human Feedback</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">If you&rsquo;ve worked with generative AI models you know they can be fickle and sometimes fail to meet the expectations of users. How can we move towards models users trust and see clear value in? Let&rsquo;s engineer a user-feedback loop!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img loading=lazy src=img/team/patrick-deziel.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/patrick-deziel>Patrick Deziel</a></li></ul></div><div class=font-extralight>Sep 13, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/starting-simple-with-ai/><img loading=lazy src=https://rotational.io/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-2/cover-photo.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/starting-simple-with-ai/>To LLM or Not to LLM (Part 2): Starting Simple</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">Sick of hearing about hyped up AI solutions that sound like hot air? 🧐 Let&rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img loading=lazy src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 20, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/responsible-innovation/><img loading=lazy src=https://rotational.io/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-1/elena-mozhvilo-unsplash.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/responsible-innovation/>To LLM or Not to LLM: Tips for Responsible Innovation</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">We&rsquo;re seeing a proliferation of Large Language Models (LLMs) as companies seek to replicate OpenAI&rsquo;s success. In this post, two AI engineers respond to LLM FAQs and offer tips for responsible innovation.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img loading=lazy src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 8, 2024</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start gap-x-2"><input type=checkbox id=checkbox required class="mt-1 w-4 h-4 block border-0">
<label for=checkbox><span>I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><footer class="relative mt-40 md:mt-56 bg-[#192E5B]"><div class="relative w-full pt-36 md:pt-16 lg:pt-24 2xl:pt-20 font-extralight text-white"><div class="-mt-52 w-full mx-auto max-w-screen-xl px-4"><section class="bg-[#72A2C0] w-full p-6 md:py-20 md:px-16"><h2 class="my-4 text-2xl sm:text-3xl md:text-5xl text-white font-extrabold">LET'S ENVISION & BUILD THE FUTURE TOGETHER.</h2><div class=py-6><a href=/contact class="p-3 md:p-4 md:px-6 bg-[#2F4858] font-bold md:text-lg text-white text-center hover:bg-[#2F4858]/80">CONTACT US</a></div></section></div><div class="max-w-7xl mx-auto px-6"><div class="mt-12 flex flex-col md:flex-row lg:justify-between gap-x-8"><div class="my-4 max-w-xs"><h5 class="mb-3 font-extrabold">OUR PRESENCE</h5><p>We share because we care, about topics, tools, and technologies that we believe impact the AI economy.</p><div class=py-4><ul class="flex justify-between items-center gap-x-8"><li><a href=https://twitter.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-x-twitter"></i><p class=sr-only>Twitter</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-linkedin"></i><p class=sr-only>LinkedIn</p></a></li><li><a href=https://github.com/rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-github"></i><p class=sr-only>GitHub</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-youtube"></i><p class=sr-only>YouTube</p></a></li><li><a href=https://www.twitch.tv/rotationallabs target=_blank class=hover:text-[#1D65A6]><i class="text-2xl fa-brands fa-twitch"></i><p class=sr-only>Twitch</p></a></li></ul></div></div><div class=my-4><h5 class="mb-3 font-extrabold">COMPANY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/about>About Us</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/case-studies>Case Studies</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/endeavor>Endeavor</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/blog>Blog</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">COMMUNITY</h5><ul><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/learning>Learning</a></li><li class="pb-3 flex items-center gap-x-2"><i class="fa-solid fa-chevron-right text-[#757575] text-xs"></i>
<a href=/opensource>Open Source</a></li></ul></div><div class=my-4><h5 class="mb-3 font-extrabold">CONTACT US</h5><ul><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-map-marker-alt text-[#757575]"></i>
St. Paul, MN & Washington, DC</li><li class="flex items-baseline lg:items-center gap-x-2"><i class="fa-solid fa-envelope text-[#757575]"></i>
info@rotational.io</li></ul><div class=py-8><a href=/contact class="p-3 bg-[#ECF6FF] font-bold text-black text-center hover:bg-[#ECF6FF]/80">CONTACT US</a></div></div></div><div class="sm:flex justify-between py-6 border-t mt-4"><p>Copyright © Rotational Labs, Inc. 2021–2024 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex gap-x-8"><li><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></footer><script src=https://cdn.jsdelivr.net/npm/flowbite@2.5.2/dist/flowbite.min.js></script>
<script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://rotational.io/js/blogSingle.js></script></body></html>