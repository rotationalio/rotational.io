<!doctype html><html lang=en-us><head><meta charset=utf-8><title>Rotational Labs | Predicting the Oscars With LLMs</title><base href=https://rotational.io/ target=_self><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Rotational Labs, Inc."><meta name=description content="Can LLMs predict the Oscars?"><meta name=keywords content="Rotational Labs,Ensign,Cloud-native,Real-time data streaming platform,Data collaboration,Data automation,Rapid prototyping,Real-time machine learning,Real-time data analytics,Real-time applications,Data streams,Event streams,Event-sourcing databaseEvent log"><link type=text/plain rel=author href=https://rotational.io/humans.txt><meta property="og:title" content="Predicting the Oscars With LLMs"><meta property="og:description" content="Can LLMs predict the Oscars?"><meta property="og:image" content="https://rotational.io/img/blog/trophies.jpg"><meta property="og:url" content="https://rotational.io/blog/predicting-the-oscars-with-llms/"><meta property="og:type" content="website"><meta name=twitter:title content="Predicting the Oscars With LLMs"><meta name=twitter:card content="summary"><meta name=twitter:description content="Can LLMs predict the Oscars?"><meta name=twitter:image content="https://rotational.io/img/blog/trophies.jpg"><link rel="shortcut icon" href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=icon href=https://rotational.io/img/favicon.png type=image/x-icon><link rel=alternate type=application/rss+xml href=https://rotational.io//index.xml title="Recent Rotations of the Rotational Labs Blog"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.css><link rel=stylesheet href=https://unpkg.com/@highlightjs/cdn-assets/styles/default.min.css><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap" rel=stylesheet><link rel=stylesheet href=https://rotational.io/output.css media=screen><script async src="https://www.googletagmanager.com/gtag/js?id=G-2FKX6CWJHW"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-2FKX6CWJHW")</script><script src="https://www.google.com/recaptcha/enterprise.js?render=6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk"></script>
<script>grecaptcha.enterprise.ready(function(){grecaptcha.enterprise.execute("6Ld5O3kiAAAAAJU0z0h81X1RxEMHyoROe6KWe_vk",{action:"homepage"}).then(function(){})})</script><script src=https://unpkg.com/lunr/lunr.js></script></head><body class="bg-hexagon bg-center bg-contain"><div class="relative bg-[#1D65A6]"><nav class="relative max-w-7xl mx-auto flex items-center justify-between text-white px-4 sm:px-6 z-[9999] py-5" aria-label=Global><a href=/><img src=img/logo.png alt="Rotational Lab logo" class="h-14 w-auto sm:h-14"></a><ul class=topnav id=myTopnav><li><a href=/services/>Services</a></li><li><a href=/products/>Products</a></li><li><a href=/blog/>Blog</a></li><li><a href=/about/>About</a></li><li><a href=/contact/>Contact Us</a></li><a class=icon onclick=openMobNav()><i class="fa fa-bars"></i></a></ul></nav></div><main><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class=mt-14><div class=blog-img><img src=https://rotational.io/img/blog/trophies.jpg alt="Predicting the Oscars With LLMs" class="mx-auto object-cover"></div><div class=mt-8><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center" data-blog-title="Predicting the Oscars With LLMs"><b class=text-[#1D65A6]>Predicting</b>
the Oscars With LLMs</h3><div class="flex flex-wrap justify-center items-center my-4"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span><a href=/authors/patrick-deziel>Patrick Deziel</a> | Friday, Mar 8, 2024 |&nbsp;</span>
<span><a href=/tags/llms>LLMs</a>,&nbsp;</span>
<a href=/tags/semantic-similarity>Semantic Similarity</a>,&nbsp;</span>
<a href=/tags/python>Python</a></span></div><article class="max-w-[800px] mx-auto prose"><p>Looking for a middle ground between custom LLMs and traditional ML? Please welcome semantic search to the stage! Let&rsquo;s use semantic search to predict which film will take home the &ldquo;Best Picture&rdquo; Oscar this year 🤩</p><p>Last year we all went to see &ldquo;Everything Everywhere All at Once&rdquo; at our team retreat, and it went on to take home several awards, including Best Picture. Let&rsquo;s see if we can predict the future again!</p><h2 id=data-ingestion>Data Ingestion</h2><p>To start, there is a nice dataset on <a href=https://www.kaggle.com/datasets/unanimad/the-oscar-award>Kaggle</a> which compiles all the Oscar nominees and winners since 1927. It turns out that the best picture award has changed names several times, so it took some manual data engineering to extract the labels.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> bp <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;BEST PICTURE&#39;</span>, <span style=color:#e6db74>&#39;BEST MOTION PICTURE&#39;</span>, <span style=color:#e6db74>&#39;OUTSTANDING PICTURE&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;OUTSTANDING PRODUCTION&#39;</span>, <span style=color:#e6db74>&#39;OUTSTANDING MOTION PICTURE&#39;</span>
</span></span><span style=display:flex><span>   ]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> df <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#39;category&#39;</span>]<span style=color:#f92672>.</span>isin(bp)]
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> df[<span style=color:#e6db74>&#39;winner&#39;</span>]<span style=color:#f92672>.</span>value_counts()
</span></span><span style=display:flex><span>winner
</span></span><span style=display:flex><span><span style=color:#66d9ef>False</span>    <span style=color:#ae81ff>496</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>True</span>      <span style=color:#ae81ff>95</span>
</span></span><span style=display:flex><span>Name: count, dtype: int64
</span></span></code></pre></div><p>There have been 591 best picture nominees and 95 winners over the years. Not the largest data set, but at least the class imbalance isn&rsquo;t terrible. To do machine learning I needed features so I scraped text from Wikipedia. Most films have a corresponding Wikipedia in the format:</p><p><code>wikipedia.org/wiki/{film_title}_({year}_film)</code></p><p>However as you might imagine this is not 100% consistent; it really just depends on how unique the film title happens to be. It was guessable enough to eventually get all 591 film articles into the DataFrame. I used <code>beautifulsoup</code> to extract the text from the downloaded HTML.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;text&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;wiki&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: BeautifulSoup(x, <span style=color:#e6db74>&#39;html.parser&#39;</span>)<span style=color:#f92672>.</span>get_text())
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;text&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: x<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#34;</span>, <span style=color:#e6db74>&#34; &#34;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#39;</span><span style=color:#e6db74>&#34;</span>, <span style=color:#e6db74>&#34;&#39;&#34;</span>))
</span></span><span style=display:flex><span>df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>iloc[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span><span style=color:#e6db74>&#39;The Racket is a 1928 American silent crime drama film directed by Lewis Milestone and starring Thomas Meighan, Marie Prevost, Louis Wolheim, and George E. Stone...&#39;</span>
</span></span></code></pre></div><p>A <a href=https://www.scikit-yb.org/en/latest/api/text/tsne.html>TSNE projection</a> is one way to visualize the high-dimensional data (e.g. encoded documents with TF-IDF). It shows that there are at least some interesting clusters in the Wikipedia text. The green dots are the winners.</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/tsne.png alt="&ldquo;TSNE Projection&rdquo;"></p><h2 id=initial-models>Initial Models</h2><p>My first idea was to encode the article text with a tried-and-tested approach like TF-IDF and fit a binary classifier using the encoded vectors as features. The best model was pretty overfit due to the small size of the training set.</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/decision_tree.png alt="&ldquo;Decision Tree&rdquo;"></p><p>The next idea was to train <code>distilbert</code> for sequence classification to take advantage of the massive amount of pre-training. I was able to train a &ldquo;will it win&rdquo; model but the inferences were still not useful. Everything looks like a winner this year!</p><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/distilbert_results.png alt="&ldquo;distilbert results&rdquo;"></p><h2 id=semantic-similarity>Semantic Similarity</h2><p>Given that there is so little training data, perhaps a similarity approach makes more sense. If we make the assumption that films similar to other Oscar winners are more likely to win, then we have a well-defined methodology to select the most probable winner.</p><p>The first step to computing similarity is to encode the articles text into vector space. Here we can take advantage of pre-trained LLMs. There are particular models that have been trained to maximize performance for tasks like semantic search. In this case, we are looking for a sentence transformer model like <code>all-MiniLM-L6-v2</code> that&rsquo;s trained for symmetric search (e.g. the query and documents in the corpus are about the same length).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> SentenceTransformer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> SentenceTransformer(<span style=color:#e6db74>&#34;all-MiniLM-L6-v2&#34;</span>)
</span></span><span style=display:flex><span>best_pictures[<span style=color:#e6db74>&#34;embeddings&#34;</span>] <span style=color:#f92672>=</span> best_pictures[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>apply(
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>lambda</span> x: model<span style=color:#f92672>.</span>encode(x)
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Now that we have the embeddings we can compute the similarity between an arbitrary bit of text and all the films in the corpus. Ranking by similarity gives us the &ldquo;nearest neighbors&rdquo; to a particular film.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> sentence_transformers <span style=color:#f92672>import</span> util
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_most_similar</span>(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>):
</span></span><span style=display:flex><span>    embeddings <span style=color:#f92672>=</span> model<span style=color:#f92672>.</span>encode(text)
</span></span><span style=display:flex><span>    df[<span style=color:#e6db74>&#34;sim_score&#34;</span>] <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;embeddings&#34;</span>]<span style=color:#f92672>.</span>apply(
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>lambda</span> x: util<span style=color:#f92672>.</span>cos_sim(embeddings, x)<span style=color:#f92672>.</span>item()
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> df<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sim_score&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)<span style=color:#f92672>.</span>head(n)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>film <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;American Fiction&#34;</span>
</span></span><span style=display:flex><span>text <span style=color:#f92672>=</span> eval_df[eval_df[<span style=color:#e6db74>&#34;film&#34;</span>] <span style=color:#f92672>==</span> film][<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>iloc[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>get_most_similar(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>)[[<span style=color:#e6db74>&#34;film&#34;</span>, <span style=color:#e6db74>&#34;sim_score&#34;</span>, <span style=color:#e6db74>&#34;winner&#34;</span>]]
</span></span></code></pre></div><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/ranking.png alt="&ldquo;Similarity Ranking&rdquo;"></p><p>From here it&rsquo;s a matter of creating some algorithm to produce a final ranking for this year&rsquo;s nominees. One approach might be to take the top n similar films and multiply the proportion of winners of that group by the average of the similarity scores.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>win_score</span>(text, n<span style=color:#f92672>=</span><span style=color:#ae81ff>10</span>):
</span></span><span style=display:flex><span>    sim <span style=color:#f92672>=</span> get_most_similar(text, n<span style=color:#f92672>=</span>n)
</span></span><span style=display:flex><span>    winners <span style=color:#f92672>=</span> len(sim[sim[<span style=color:#e6db74>&#34;winner&#34;</span>]]) <span style=color:#f92672>/</span> n
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> sim[<span style=color:#e6db74>&#34;winner&#34;</span>]<span style=color:#f92672>.</span>mean() <span style=color:#f92672>*</span> winners
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>eval_df[<span style=color:#e6db74>&#34;win_score&#34;</span>] <span style=color:#f92672>=</span> eval_df[<span style=color:#e6db74>&#34;cleaned_text&#34;</span>]<span style=color:#f92672>.</span>apply(<span style=color:#66d9ef>lambda</span> x: win_score(x, n<span style=color:#f92672>=</span><span style=color:#ae81ff>100</span>))
</span></span><span style=display:flex><span>eval_df<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;win_score&#34;</span>, ascending<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)[[<span style=color:#e6db74>&#34;film&#34;</span>, <span style=color:#e6db74>&#34;win_score&#34;</span>]]
</span></span></code></pre></div><p><img src=/img/blog/2024-03-08-predicting-the-oscars-with-llms/sim_rankings.png alt="&ldquo;Final Rankings&rdquo;"></p><p>The similarity approach predicts that Oppenheimer will take it home. This is in line with the <a href=https://www.vegasinsider.com/awards/odds/oscars/>betting odds</a> as of Friday, March 8.</p><pre tabindex=0><code>Oppenheimer -5000
Poor Things +2000
The Zone of Interest +2000
The Holdovers +2500
Anatomy of a Fall +5000
Barbie +6600
American Fiction +8000
Killers of the Flower Moon +10000
Past Lives +15000
Maestro +15000
</code></pre><h2 id=conclusion>Conclusion</h2><p>When you need to boost the performance of your machine learning model, it usually comes down to improving the quality of the training dataset. In cases where you <em>don&rsquo;t</em> have access to more data or you can&rsquo;t afford to train custom LLMs, a similarity approach can be a cost-effective (and more explainable) solution. And just as with film, a bit of creativity goes a long way!</p><div class="border-t my-12"></div><p>Photo by <a href="https://unsplash.com/@tommaomaoer?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">tommao wang</a> on <a href="https://unsplash.com/photos/gold-and-silver-pendant-lamps-GjtqYFnQEY4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a></p></article></div></div><div class="bg-[#E8EFF6] max-w-[800px] mx-auto mt-9 p-8 rounded-lg"><h3 class="font-bold text-xl sm:text-2xl lg:text-3xl text-center mb-3"><span class="text-[#1D65A6] font-bold">About</span>
This Post</h3><p class="text-base mx-auto px-2 text-center lg:text-base">Can LLMs predict the Oscars?</p><div class="flex flex-col md:flex-row text-center mx-auto border-t pt-6 mt-6 align-center justify-between gap-10"><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Written by:</h2><div class="flex items-center"><a href=/authors/patrick-deziel><img src=img/team/patrick-deziel.png alt class="mr-3 border-4 border-white rounded-full h-11 drop-shadow-lg"></a>
<span class="flex flex-wrap"><a href=/authors/patrick-deziel class="lg:w-[20ch] mx-2">Patrick Deziel</a></span></div></div><div class=lg:w-1/2><h2 class="text-lg text-[#1D65A6] font-bold mb-3">Share this post:</h2><ul class="flex items-center justify-center gap-6 mt-4"><li><a onclick=shareByEmail() class=cursor-pointer><img src=img/email.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnTwitterWithTitle() class=cursor-pointer><img src=img/twitter.png alt class="rounded-lg bg-white p-3"></a></li><li><a onclick=shareOnLinkedIn() class=cursor-pointer><img src=img/linkedin.png alt class="rounded-lg bg-white p-3"></a></li></ul></div></div></div><div class="relative max-w-7xl mx-auto px-4 sm:px-6"><div class="flex justify-between mt-12 sm:mt-24 items-center"><h2 class="font-bold text-2xl sm:text-4xl flex"><span><b class=text-[#1D65A6]>Recent</b>
Rotations</span>
<img src=img/butterfly.png alt=butterfly class="ml-4 h-6 sm:h-8 relative top-1"></h2><div><a href=/blog class="flex text-base sm:text-lg items-center font-bold text-[#1D65A6]"><span>View all</span>
<img src=img/arr-right.png alt class="h-4 ml-2"></a></div></div><div><div class="grid lg:grid-cols-2 xl:grid-cols-3 gap-8 sm:mt-16"><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/nlp-with-javascript-using-winkjs/><img src=https://rotational.io/img/blog/2024-06-10-nlp-with-javascript-using-winkJS/machine-learning-robot.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/javascript>JavaScript</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/nlp>NLP</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/nlp-with-javascript-using-winkjs/>NLP with Javascript Using winkJS</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">winkJS is a collection of open source libraries, created by <a href=https://graype.in/>Graype Systems</a>, designed to make Natural Language Processing (NLP), machine learning, and statistical analysis accessible in JavaScript. Let&rsquo;s take an in-depth look into …</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><a href=/authors/danielle-maxwell class="flex items-center"><img src=img/team/danielle-maxwell.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Danielle Maxwell</span></a></div><div class=font-extralight>Jun 10, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/text-to-sql-llm-app/><img src=https://rotational.io/img/blog/2024-06-07-text-to-sql-llm-app/dashboard.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llm>LLM</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/text-to-sql-llm-app/>How to build a text-to-sql LLM application</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">As industry races for use cases of Large Language Models, software devs have emerged as early adopters. Can LLMs help us translate between tech and talk? Let&rsquo;s build a text-to-SQL application with Vanna and Streamlit!</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><a href=/authors/prema-roman class="flex items-center"><img src=img/team/prema-roman.png alt class="rounded-full h-10 w-10">
<span class="ml-4 font-extralight">Prema Roman</span></a></div><div class=font-extralight>Jun 7, 2024</div></div></div></div></div><div class=mt-6><div class=article><a class=block href=https://rotational.io/blog/starting-simple-with-ai/><img src=https://rotational.io/img/blog/2024-05-08-to-llm-or-not-to-llm-that-is-the-question-part-2/cover-photo.webp alt class="rounded-t-xl object-cover" style=height:212px;width:100%></a><div class="bg-[#ECF6FF] rounded-b-xl"><div class="px-6 pt-4"><ul class="flex flex-wrap"><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/llms>LLMs</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ai>AI</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/ml>ML</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/python>Python</a>,&nbsp;</li><li class="text-base font-bold text-[#1D65A6]"><a href=/tags/data>Data</a></li></ul><h3 class="text-xl font-extrabold mt-3 md:mt-4 pb-2"><a class="block h-auto lg:h-24" href=https://rotational.io/blog/starting-simple-with-ai/>To LLM or Not to LLM (Part 2): Starting Simple</a></h3><div class='h-auto lg:h-36'><p class="mt-3 md:mt-4 text-base">Sick of hearing about hyped up AI solutions that sound like hot air? 🧐 Let&rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.</p></div></div><div class="flex justify-between items-center px-6 py-3 border-t mt-6 xl:mt-8"><div class="flex items-center"><img src=img/butterfly.png alt class="rounded-full h-10 w-10"><ul class="flex flex-wrap ml-4"><li class=font-extralight><a href=/authors/danielle-maxwell>Danielle Maxwell</a>,&nbsp;</li><li class=font-extralight><a href=/authors/prema-roman>Prema Roman</a></li></ul></div><div class=font-extralight>May 20, 2024</div></div></div></div></div></div></div></div></div><div class="bg-[#1D65A6] max-w-[800px] mx-auto mt-20 py-14 px-12 md:px-16 text-white md:rounded-lg"><form action=blog method=post id=newsletterForm><h6 class="font-bold text-center">Enter Your Email To Subscribe</h6><label for=email class=hidden>Email</label>
<input type=text name=email id=email required placeholder class="w-full px-4 py-2.5 rounded-lg mt-6 text-black" style=color:#000><div class="flex mt-6 items-start"><input type=checkbox id=checkbox required class="w-6 h-6 block border-0">
<label for=checkbox><span class="ml-2 text-left">I want to receive the monthly newsletter and other updates from Rotational. You agree to our Privacy Policy. You may unsubscribe at any time.*</span></label></div><div class="bg-teal-100 border-t-4 border-teal-500 mt-10 rounded-b text-teal-900 px-4 py-3 shadow-md hidden" id=newsletter-alert role=alert><div class=flex><div><p class=text-sm>Thank you for your interest!</p></div></div></div><div class="flex justify-center"><button type=submit class="bg-[#192E5B] px-14 py-4 mt-10 rounded-lg text-sm text-white uppercase md:text-base">
Submit</button></div></form></div></main><div id=footerBackground><footer class="bg-hero-footer bg-cover"><div class="pt-[350px] font-extralight text-white"><div class="max-w-7xl mx-auto px-6"><div class="max-[650px]:text-center sm:grid grid-cols-3"><div class="my-10 sm:my-0"><h5 class=mb-3>PRODUCT</h5><ul><li class=pb-3><a href=https://rotational.app target=_blank class=font-bold>Ensign</a></li><li class=pb-3><a href=/ensign-pricing target=_blank class=font-bold>Pricing</a></li><li class=pb-3><a href=https://ensign.rotational.dev/getting-started/ target=_blank class=font-bold>Docs</a></li><li class=pb-3><a href=https://ensign.rotational.dev/sdk/ target=_blank class=font-bold>SDKs</a></li><li class=pb-3><a href=https://status.rotational.dev/ target=_blank class=font-bold>Status</a></li></ul></div><div class="mb-10 sm:mb-0"><h5 class=mb-3>COMPANY</h5><ul><li class=pb-3><a href=/services class=font-bold>Services</a></li><li class=pb-3><a href=/blog class=font-bold>Blog</a></li><li class=pb-3><a href=/about class=font-bold>About</a></li></ul></div><div><h5 class=mb-3>COMMUNITY</h5><ul><li class=pb-3><a href=/ensign-u class=font-bold>Ensign U</a></li><li class=pb-3><a href=/data-playground class=font-bold>Data Playground</a></li><li class=pb-3><a href=/opensource class=font-bold>Open Source</a></li><li class=pb-3><a href=/resources class=font-bold>Resources</a></li></ul></div></div><div class="max-w-7xl sm:flex justify-center border-t py-6 mt-12 sm:mt-32"><div class="mx-auto xl:ml-5"><div><ul class="grid gap-8 sm:flex justify-center lg:gap-28 xl:gap-36"><li><a href=https://twitter.com/rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-twitter"></i><p>Twitter</p></a></li><li><a href=https://github.com/rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-github"></i><p>GitHub</p></a></li><li><a href=https://www.linkedin.com/company/rotational target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-linkedin"></i><p>LinkedIn</p></a></li><li><a href=https://www.youtube.com/@rotationalio target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa-brands fa-youtube"></i><p>YouTube</p></a></li><li><a href=mailto:info@rotational.io target=_blank class="flex items-center gap-2 hover:text-[#1D65A6]"><i class="text-2xl fa fa-envelope"></i><p>Email</p></a></li></ul></div></div></div><div class="sm:flex justify-between py-6"><p>Copyright © Rotational Labs, Inc. 2021–2024 · All Rights Reserved</p><div><ul class="sm:mt-0 mt-4 flex"><li class="border-r pr-4 mr-4"><a href=/privacy/>Privacy Policy</a></li><li><a href=/terms/>Terms of Use</a></li></ul></div></div></div></div></div></footer></div><script src=https://rotational.io/js/app.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/flowbite/1.6.5/flowbite.min.js></script>
<script src=https://unpkg.com/@highlightjs/cdn-assets/highlight.min.js></script></body></html>