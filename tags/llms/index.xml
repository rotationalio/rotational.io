<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLMs on Rotational Labs</title><link>https://rotational.io/tags/llms/</link><description>Recent content in LLMs on Rotational Labs</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 02 Oct 2025 09:45:00 -0400</lastBuildDate><atom:link href="https://rotational.io/tags/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>AI Agents and Tools: Unlocking Business Impact</title><link>https://rotational.io/blog/ai-agents-and-tools/</link><pubDate>Thu, 02 Oct 2025 09:45:00 -0400</pubDate><guid>https://rotational.io/blog/ai-agents-and-tools/</guid><description>&lt;h1 id="tools-how-ai-agents-get-real-work-done"&gt;Tools: How AI Agents Get Real Work Done&lt;/h1&gt;
&lt;p&gt;Now that we‚Äôve covered &lt;a href="https://rotational.io/blog/ai-agents-defined/"&gt;AI agents&lt;/a&gt; in general, and &lt;a href="https://rotational.io/blog/prompt-engineering-overview-key-to-steering-agents/"&gt;prompts&lt;/a&gt; and &lt;a href="https://rotational.io/blog/making-sense-of-llms/"&gt;LLMs&lt;/a&gt; specifically, let‚Äôs move on to &lt;strong&gt;tools&lt;/strong&gt;.&lt;/p&gt;</description></item><item><title>Making Sense of LLMs</title><link>https://rotational.io/blog/making-sense-of-llms/</link><pubDate>Wed, 27 Aug 2025 09:45:00 -0400</pubDate><guid>https://rotational.io/blog/making-sense-of-llms/</guid><description>&lt;p&gt;Now that we‚Äôve covered &lt;a href="https://rotational.io/blog/ai-agents-defined/"&gt;agents at a high level&lt;/a&gt; and &lt;a href="https://rotational.io/tags/prompt-engineering/"&gt;prompts&lt;/a&gt; specifically, let‚Äôs move to the next component in our series: &lt;strong&gt;Large Language Models (LLMs)&lt;/strong&gt;, a key subset of generative AI. In an agentic framework, LLMs serve as the ‚Äúbrain‚Äù or decision-execution component of the agent.&lt;/p&gt;</description></item><item><title>Let The Right One In: Model Selection for the AI Era</title><link>https://rotational.io/blog/pick-the-best-ai/</link><pubDate>Mon, 05 May 2025 09:48:50 -0400</pubDate><guid>https://rotational.io/blog/pick-the-best-ai/</guid><description>&lt;p&gt;There&amp;rsquo;s no &amp;ldquo;best AI model for all use cases.&amp;rdquo; You have to do the science each time. If you&amp;rsquo;re new to experimental design for AI/ML, here&amp;rsquo;s a quick and dirty intro to the &lt;strong&gt;Model Selection Triple&lt;/strong&gt; methodology.&lt;/p&gt;</description></item><item><title>Recapping PyTorch: Key Takeaways from the 2024 Conference</title><link>https://rotational.io/blog/pytorch-conference-2024/</link><pubDate>Tue, 24 Sep 2024 14:25:57 -0400</pubDate><guid>https://rotational.io/blog/pytorch-conference-2024/</guid><description>&lt;p&gt;I spent last week in San Francisco meeting up with the Rotational team to attend &lt;a href="https://events.linuxfoundation.org/pytorch-conference/"&gt;PyTorch Conference&lt;/a&gt;. If you&amp;rsquo;re an LLM developer and didn&amp;rsquo;t make it this year, here are some of my key highlights and takeaways.&lt;/p&gt;</description></item><item><title>Teaching LLMs With Continuous Human Feedback</title><link>https://rotational.io/blog/teaching-llms-with-human-feedback/</link><pubDate>Fri, 13 Sep 2024 13:38:26 -0500</pubDate><guid>https://rotational.io/blog/teaching-llms-with-human-feedback/</guid><description>&lt;p&gt;If you&amp;rsquo;ve worked with generative AI models you know they can be fickle and sometimes fail to meet the expectations of users. How can we move towards models users trust and see clear value in? Let&amp;rsquo;s engineer a user-feedback loop!&lt;/p&gt;</description></item><item><title>To LLM or Not to LLM (Part 2): Starting Simple</title><link>https://rotational.io/blog/starting-simple-with-ai/</link><pubDate>Mon, 20 May 2024 09:00:00 -0500</pubDate><guid>https://rotational.io/blog/starting-simple-with-ai/</guid><description>&lt;p&gt;Sick of hearing about hyped up AI solutions that sound like hot air? üßê Let&amp;rsquo;s use boring old ML to detect hype in AI marketing text and see why starting with a simple ML approach is still your best bet 90% of the time.&lt;/p&gt;</description></item><item><title>To LLM or Not to LLM: Tips for Responsible Innovation</title><link>https://rotational.io/blog/responsible-innovation/</link><pubDate>Wed, 08 May 2024 09:33:34 -0400</pubDate><guid>https://rotational.io/blog/responsible-innovation/</guid><description>&lt;p&gt;We&amp;rsquo;re seeing a proliferation of Large Language Models (LLMs) as companies seek to replicate OpenAI&amp;rsquo;s success. In this post, two AI engineers respond to LLM FAQs and offer tips for responsible innovation.&lt;/p&gt;</description></item><item><title>Predicting the Oscars With LLMs</title><link>https://rotational.io/blog/predicting-the-oscars-with-llms/</link><pubDate>Fri, 08 Mar 2024 15:17:58 -0600</pubDate><guid>https://rotational.io/blog/predicting-the-oscars-with-llms/</guid><description>&lt;p&gt;Looking for a middle ground between custom LLMs and traditional ML? Please welcome semantic search to the stage! Let&amp;rsquo;s use semantic search to predict which film will take home the &amp;ldquo;Best Picture&amp;rdquo; Oscar this year ü§©&lt;/p&gt;</description></item></channel></rss>